{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net model\n",
    "This Neural Net model predicts superconductor critical temperatures. The first model uses default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0                   4         88.944468             57.862692   \n",
       "1                   5         92.729214             58.518416   \n",
       "2                   4         88.944468             57.885242   \n",
       "3                   4         88.944468             57.873967   \n",
       "4                   4         88.944468             57.840143   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0          66.361592              36.116612             1.181795   \n",
       "1          73.132787              36.396602             1.449309   \n",
       "2          66.361592              36.122509             1.181795   \n",
       "3          66.361592              36.119560             1.181795   \n",
       "4          66.361592              36.110716             1.181795   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                 1.062396          122.90607              31.794921   \n",
       "1                 1.057755          122.90607              36.161939   \n",
       "2                 0.975980          122.90607              35.741099   \n",
       "3                 1.022291          122.90607              33.768010   \n",
       "4                 1.129224          122.90607              27.848743   \n",
       "\n",
       "   std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  wtd_gmean_Valence  \\\n",
       "0        51.968828  ...          2.257143       2.213364           2.219783   \n",
       "1        47.094633  ...          2.257143       1.888175           2.210679   \n",
       "2        51.968828  ...          2.271429       2.213364           2.232679   \n",
       "3        51.968828  ...          2.264286       2.213364           2.226222   \n",
       "4        51.968828  ...          2.242857       2.213364           2.206963   \n",
       "\n",
       "   entropy_Valence  wtd_entropy_Valence  range_Valence  wtd_range_Valence  \\\n",
       "0         1.368922             1.066221              1           1.085714   \n",
       "1         1.557113             1.047221              2           1.128571   \n",
       "2         1.368922             1.029175              1           1.114286   \n",
       "3         1.368922             1.048834              1           1.100000   \n",
       "4         1.368922             1.096052              1           1.057143   \n",
       "\n",
       "   std_Valence  wtd_std_Valence  critical_temp  \n",
       "0     0.433013         0.437059           29.0  \n",
       "1     0.632456         0.468606           26.0  \n",
       "2     0.433013         0.444697           19.0  \n",
       "3     0.433013         0.440952           22.0  \n",
       "4     0.433013         0.428809           23.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superconductor_df = pd.read_csv('../datasets/train.csv')\n",
    "\n",
    "superconductor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.115224</td>\n",
       "      <td>87.557631</td>\n",
       "      <td>72.988310</td>\n",
       "      <td>71.290627</td>\n",
       "      <td>58.539916</td>\n",
       "      <td>1.165608</td>\n",
       "      <td>1.063884</td>\n",
       "      <td>115.601251</td>\n",
       "      <td>33.225218</td>\n",
       "      <td>44.391893</td>\n",
       "      <td>...</td>\n",
       "      <td>3.153127</td>\n",
       "      <td>3.056536</td>\n",
       "      <td>3.055885</td>\n",
       "      <td>1.295682</td>\n",
       "      <td>1.052841</td>\n",
       "      <td>2.041010</td>\n",
       "      <td>1.483007</td>\n",
       "      <td>0.839342</td>\n",
       "      <td>0.673987</td>\n",
       "      <td>34.421219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.439295</td>\n",
       "      <td>29.676497</td>\n",
       "      <td>33.490406</td>\n",
       "      <td>31.030272</td>\n",
       "      <td>36.651067</td>\n",
       "      <td>0.364930</td>\n",
       "      <td>0.401423</td>\n",
       "      <td>54.626887</td>\n",
       "      <td>26.967752</td>\n",
       "      <td>20.035430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.191249</td>\n",
       "      <td>1.046257</td>\n",
       "      <td>1.174815</td>\n",
       "      <td>0.393155</td>\n",
       "      <td>0.380291</td>\n",
       "      <td>1.242345</td>\n",
       "      <td>0.978176</td>\n",
       "      <td>0.484676</td>\n",
       "      <td>0.455580</td>\n",
       "      <td>34.254362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.941000</td>\n",
       "      <td>6.423452</td>\n",
       "      <td>5.320573</td>\n",
       "      <td>1.960849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>72.458076</td>\n",
       "      <td>52.143839</td>\n",
       "      <td>58.041225</td>\n",
       "      <td>35.248990</td>\n",
       "      <td>0.966676</td>\n",
       "      <td>0.775363</td>\n",
       "      <td>78.512902</td>\n",
       "      <td>16.824174</td>\n",
       "      <td>32.890369</td>\n",
       "      <td>...</td>\n",
       "      <td>2.116732</td>\n",
       "      <td>2.279705</td>\n",
       "      <td>2.091251</td>\n",
       "      <td>1.060857</td>\n",
       "      <td>0.775678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921454</td>\n",
       "      <td>0.451754</td>\n",
       "      <td>0.306892</td>\n",
       "      <td>5.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>84.922750</td>\n",
       "      <td>60.696571</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>39.918385</td>\n",
       "      <td>1.199541</td>\n",
       "      <td>1.146783</td>\n",
       "      <td>122.906070</td>\n",
       "      <td>26.636008</td>\n",
       "      <td>45.123500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.618182</td>\n",
       "      <td>2.615321</td>\n",
       "      <td>2.434057</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.166532</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.063077</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>100.404410</td>\n",
       "      <td>86.103540</td>\n",
       "      <td>78.116681</td>\n",
       "      <td>73.113234</td>\n",
       "      <td>1.444537</td>\n",
       "      <td>1.359418</td>\n",
       "      <td>154.119320</td>\n",
       "      <td>38.356908</td>\n",
       "      <td>59.322812</td>\n",
       "      <td>...</td>\n",
       "      <td>4.026201</td>\n",
       "      <td>3.727919</td>\n",
       "      <td>3.914868</td>\n",
       "      <td>1.589027</td>\n",
       "      <td>1.330801</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.918400</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.020436</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>1.983797</td>\n",
       "      <td>1.958203</td>\n",
       "      <td>207.972460</td>\n",
       "      <td>205.589910</td>\n",
       "      <td>101.019700</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.141963</td>\n",
       "      <td>1.949739</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.992200</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "count        21263.000000      21263.000000          21263.000000   \n",
       "mean             4.115224         87.557631             72.988310   \n",
       "std              1.439295         29.676497             33.490406   \n",
       "min              1.000000          6.941000              6.423452   \n",
       "25%              3.000000         72.458076             52.143839   \n",
       "50%              4.000000         84.922750             60.696571   \n",
       "75%              5.000000        100.404410             86.103540   \n",
       "max              9.000000        208.980400            208.980400   \n",
       "\n",
       "       gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "count       21263.000000           21263.000000         21263.000000   \n",
       "mean           71.290627              58.539916             1.165608   \n",
       "std            31.030272              36.651067             0.364930   \n",
       "min             5.320573               1.960849             0.000000   \n",
       "25%            58.041225              35.248990             0.966676   \n",
       "50%            66.361592              39.918385             1.199541   \n",
       "75%            78.116681              73.113234             1.444537   \n",
       "max           208.980400             208.980400             1.983797   \n",
       "\n",
       "       wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "count             21263.000000       21263.000000           21263.000000   \n",
       "mean                  1.063884         115.601251              33.225218   \n",
       "std                   0.401423          54.626887              26.967752   \n",
       "min                   0.000000           0.000000               0.000000   \n",
       "25%                   0.775363          78.512902              16.824174   \n",
       "50%                   1.146783         122.906070              26.636008   \n",
       "75%                   1.359418         154.119320              38.356908   \n",
       "max                   1.958203         207.972460             205.589910   \n",
       "\n",
       "       std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  \\\n",
       "count     21263.000000  ...      21263.000000   21263.000000   \n",
       "mean         44.391893  ...          3.153127       3.056536   \n",
       "std          20.035430  ...          1.191249       1.046257   \n",
       "min           0.000000  ...          1.000000       1.000000   \n",
       "25%          32.890369  ...          2.116732       2.279705   \n",
       "50%          45.123500  ...          2.618182       2.615321   \n",
       "75%          59.322812  ...          4.026201       3.727919   \n",
       "max         101.019700  ...          7.000000       7.000000   \n",
       "\n",
       "       wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  range_Valence  \\\n",
       "count       21263.000000     21263.000000         21263.000000   21263.000000   \n",
       "mean            3.055885         1.295682             1.052841       2.041010   \n",
       "std             1.174815         0.393155             0.380291       1.242345   \n",
       "min             1.000000         0.000000             0.000000       0.000000   \n",
       "25%             2.091251         1.060857             0.775678       1.000000   \n",
       "50%             2.434057         1.368922             1.166532       2.000000   \n",
       "75%             3.914868         1.589027             1.330801       3.000000   \n",
       "max             7.000000         2.141963             1.949739       6.000000   \n",
       "\n",
       "       wtd_range_Valence   std_Valence  wtd_std_Valence  critical_temp  \n",
       "count       21263.000000  21263.000000     21263.000000   21263.000000  \n",
       "mean            1.483007      0.839342         0.673987      34.421219  \n",
       "std             0.978176      0.484676         0.455580      34.254362  \n",
       "min             0.000000      0.000000         0.000000       0.000210  \n",
       "25%             0.921454      0.451754         0.306892       5.365000  \n",
       "50%             1.063077      0.800000         0.500000      20.000000  \n",
       "75%             1.918400      1.200000         1.020436      63.000000  \n",
       "max             6.992200      3.000000         3.000000     185.000000  \n",
       "\n",
       "[8 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superconductor_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21263 entries, 0 to 21262\n",
      "Data columns (total 82 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   number_of_elements               21263 non-null  int64  \n",
      " 1   mean_atomic_mass                 21263 non-null  float64\n",
      " 2   wtd_mean_atomic_mass             21263 non-null  float64\n",
      " 3   gmean_atomic_mass                21263 non-null  float64\n",
      " 4   wtd_gmean_atomic_mass            21263 non-null  float64\n",
      " 5   entropy_atomic_mass              21263 non-null  float64\n",
      " 6   wtd_entropy_atomic_mass          21263 non-null  float64\n",
      " 7   range_atomic_mass                21263 non-null  float64\n",
      " 8   wtd_range_atomic_mass            21263 non-null  float64\n",
      " 9   std_atomic_mass                  21263 non-null  float64\n",
      " 10  wtd_std_atomic_mass              21263 non-null  float64\n",
      " 11  mean_fie                         21263 non-null  float64\n",
      " 12  wtd_mean_fie                     21263 non-null  float64\n",
      " 13  gmean_fie                        21263 non-null  float64\n",
      " 14  wtd_gmean_fie                    21263 non-null  float64\n",
      " 15  entropy_fie                      21263 non-null  float64\n",
      " 16  wtd_entropy_fie                  21263 non-null  float64\n",
      " 17  range_fie                        21263 non-null  float64\n",
      " 18  wtd_range_fie                    21263 non-null  float64\n",
      " 19  std_fie                          21263 non-null  float64\n",
      " 20  wtd_std_fie                      21263 non-null  float64\n",
      " 21  mean_atomic_radius               21263 non-null  float64\n",
      " 22  wtd_mean_atomic_radius           21263 non-null  float64\n",
      " 23  gmean_atomic_radius              21263 non-null  float64\n",
      " 24  wtd_gmean_atomic_radius          21263 non-null  float64\n",
      " 25  entropy_atomic_radius            21263 non-null  float64\n",
      " 26  wtd_entropy_atomic_radius        21263 non-null  float64\n",
      " 27  range_atomic_radius              21263 non-null  int64  \n",
      " 28  wtd_range_atomic_radius          21263 non-null  float64\n",
      " 29  std_atomic_radius                21263 non-null  float64\n",
      " 30  wtd_std_atomic_radius            21263 non-null  float64\n",
      " 31  mean_Density                     21263 non-null  float64\n",
      " 32  wtd_mean_Density                 21263 non-null  float64\n",
      " 33  gmean_Density                    21263 non-null  float64\n",
      " 34  wtd_gmean_Density                21263 non-null  float64\n",
      " 35  entropy_Density                  21263 non-null  float64\n",
      " 36  wtd_entropy_Density              21263 non-null  float64\n",
      " 37  range_Density                    21263 non-null  float64\n",
      " 38  wtd_range_Density                21263 non-null  float64\n",
      " 39  std_Density                      21263 non-null  float64\n",
      " 40  wtd_std_Density                  21263 non-null  float64\n",
      " 41  mean_ElectronAffinity            21263 non-null  float64\n",
      " 42  wtd_mean_ElectronAffinity        21263 non-null  float64\n",
      " 43  gmean_ElectronAffinity           21263 non-null  float64\n",
      " 44  wtd_gmean_ElectronAffinity       21263 non-null  float64\n",
      " 45  entropy_ElectronAffinity         21263 non-null  float64\n",
      " 46  wtd_entropy_ElectronAffinity     21263 non-null  float64\n",
      " 47  range_ElectronAffinity           21263 non-null  float64\n",
      " 48  wtd_range_ElectronAffinity       21263 non-null  float64\n",
      " 49  std_ElectronAffinity             21263 non-null  float64\n",
      " 50  wtd_std_ElectronAffinity         21263 non-null  float64\n",
      " 51  mean_FusionHeat                  21263 non-null  float64\n",
      " 52  wtd_mean_FusionHeat              21263 non-null  float64\n",
      " 53  gmean_FusionHeat                 21263 non-null  float64\n",
      " 54  wtd_gmean_FusionHeat             21263 non-null  float64\n",
      " 55  entropy_FusionHeat               21263 non-null  float64\n",
      " 56  wtd_entropy_FusionHeat           21263 non-null  float64\n",
      " 57  range_FusionHeat                 21263 non-null  float64\n",
      " 58  wtd_range_FusionHeat             21263 non-null  float64\n",
      " 59  std_FusionHeat                   21263 non-null  float64\n",
      " 60  wtd_std_FusionHeat               21263 non-null  float64\n",
      " 61  mean_ThermalConductivity         21263 non-null  float64\n",
      " 62  wtd_mean_ThermalConductivity     21263 non-null  float64\n",
      " 63  gmean_ThermalConductivity        21263 non-null  float64\n",
      " 64  wtd_gmean_ThermalConductivity    21263 non-null  float64\n",
      " 65  entropy_ThermalConductivity      21263 non-null  float64\n",
      " 66  wtd_entropy_ThermalConductivity  21263 non-null  float64\n",
      " 67  range_ThermalConductivity        21263 non-null  float64\n",
      " 68  wtd_range_ThermalConductivity    21263 non-null  float64\n",
      " 69  std_ThermalConductivity          21263 non-null  float64\n",
      " 70  wtd_std_ThermalConductivity      21263 non-null  float64\n",
      " 71  mean_Valence                     21263 non-null  float64\n",
      " 72  wtd_mean_Valence                 21263 non-null  float64\n",
      " 73  gmean_Valence                    21263 non-null  float64\n",
      " 74  wtd_gmean_Valence                21263 non-null  float64\n",
      " 75  entropy_Valence                  21263 non-null  float64\n",
      " 76  wtd_entropy_Valence              21263 non-null  float64\n",
      " 77  range_Valence                    21263 non-null  int64  \n",
      " 78  wtd_range_Valence                21263 non-null  float64\n",
      " 79  std_Valence                      21263 non-null  float64\n",
      " 80  wtd_std_Valence                  21263 non-null  float64\n",
      " 81  critical_temp                    21263 non-null  float64\n",
      "dtypes: float64(79), int64(3)\n",
      "memory usage: 13.3 MB\n"
     ]
    }
   ],
   "source": [
    "superconductor_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression part 1\n",
    "#### Create the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up X and y\n",
    "X = superconductor_df.drop(columns=['critical_temp'])\n",
    "y = superconductor_df['critical_temp'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate scaler and scale data\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2624      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,169\n",
      "Trainable params: 3,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_dim = X_train_sc.shape[1], activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "745/745 - 1s - loss: 115.9251 - mse: 115.9251 - mae: 7.0618 - val_loss: 136.1500 - val_mse: 136.1500 - val_mae: 7.8615\n",
      "Epoch 2/250\n",
      "745/745 - 1s - loss: 115.3444 - mse: 115.3444 - mae: 7.0530 - val_loss: 141.7504 - val_mse: 141.7504 - val_mae: 7.6063\n",
      "Epoch 3/250\n",
      "745/745 - 1s - loss: 115.2197 - mse: 115.2197 - mae: 7.0400 - val_loss: 137.1133 - val_mse: 137.1133 - val_mae: 7.5637\n",
      "Epoch 4/250\n",
      "745/745 - 1s - loss: 116.2476 - mse: 116.2476 - mae: 7.0643 - val_loss: 130.6195 - val_mse: 130.6195 - val_mae: 7.4996\n",
      "Epoch 5/250\n",
      "745/745 - 1s - loss: 114.7339 - mse: 114.7339 - mae: 7.0187 - val_loss: 134.6736 - val_mse: 134.6736 - val_mae: 7.4763\n",
      "Epoch 6/250\n",
      "745/745 - 1s - loss: 115.5403 - mse: 115.5403 - mae: 7.0773 - val_loss: 142.2337 - val_mse: 142.2337 - val_mae: 8.0948\n",
      "Epoch 7/250\n",
      "745/745 - 1s - loss: 114.7412 - mse: 114.7412 - mae: 7.0439 - val_loss: 147.6324 - val_mse: 147.6324 - val_mae: 7.6136\n",
      "Epoch 8/250\n",
      "745/745 - 1s - loss: 114.4389 - mse: 114.4389 - mae: 7.0354 - val_loss: 131.6650 - val_mse: 131.6650 - val_mae: 7.5461\n",
      "Epoch 9/250\n",
      "745/745 - 1s - loss: 114.3094 - mse: 114.3094 - mae: 6.9941 - val_loss: 135.8615 - val_mse: 135.8615 - val_mae: 7.7404\n",
      "Epoch 10/250\n",
      "745/745 - 1s - loss: 115.5139 - mse: 115.5139 - mae: 7.0403 - val_loss: 145.7516 - val_mse: 145.7516 - val_mae: 8.0085\n",
      "Epoch 11/250\n",
      "745/745 - 1s - loss: 115.3757 - mse: 115.3757 - mae: 7.0296 - val_loss: 139.2751 - val_mse: 139.2751 - val_mae: 7.5236\n",
      "Epoch 12/250\n",
      "745/745 - 1s - loss: 114.7425 - mse: 114.7425 - mae: 7.0247 - val_loss: 148.2089 - val_mse: 148.2089 - val_mae: 7.8909\n",
      "Epoch 13/250\n",
      "745/745 - 1s - loss: 114.0938 - mse: 114.0938 - mae: 7.0106 - val_loss: 139.7542 - val_mse: 139.7542 - val_mae: 7.7305\n",
      "Epoch 14/250\n",
      "745/745 - 1s - loss: 113.9373 - mse: 113.9373 - mae: 6.9992 - val_loss: 141.3291 - val_mse: 141.3291 - val_mae: 7.5352\n",
      "Epoch 15/250\n",
      "745/745 - 1s - loss: 112.6011 - mse: 112.6011 - mae: 6.9867 - val_loss: 137.3087 - val_mse: 137.3087 - val_mae: 7.7356\n",
      "Epoch 16/250\n",
      "745/745 - 1s - loss: 114.2698 - mse: 114.2698 - mae: 7.0528 - val_loss: 141.9647 - val_mse: 141.9647 - val_mae: 7.9744\n",
      "Epoch 17/250\n",
      "745/745 - 1s - loss: 114.4937 - mse: 114.4937 - mae: 7.0306 - val_loss: 136.8104 - val_mse: 136.8104 - val_mae: 7.6267\n",
      "Epoch 18/250\n",
      "745/745 - 1s - loss: 113.5146 - mse: 113.5146 - mae: 6.9913 - val_loss: 135.5521 - val_mse: 135.5521 - val_mae: 7.6073\n",
      "Epoch 19/250\n",
      "745/745 - 1s - loss: 114.9202 - mse: 114.9202 - mae: 7.0341 - val_loss: 135.8122 - val_mse: 135.8122 - val_mae: 7.7940\n",
      "Epoch 20/250\n",
      "745/745 - 1s - loss: 113.0056 - mse: 113.0056 - mae: 6.9743 - val_loss: 133.3315 - val_mse: 133.3315 - val_mae: 7.8145\n",
      "Epoch 21/250\n",
      "745/745 - 1s - loss: 113.7583 - mse: 113.7583 - mae: 6.9877 - val_loss: 141.6575 - val_mse: 141.6575 - val_mae: 7.6279\n",
      "Epoch 22/250\n",
      "745/745 - 1s - loss: 112.9589 - mse: 112.9589 - mae: 6.9980 - val_loss: 131.4530 - val_mse: 131.4530 - val_mae: 7.4842\n",
      "Epoch 23/250\n",
      "745/745 - 1s - loss: 113.6153 - mse: 113.6153 - mae: 7.0145 - val_loss: 135.3658 - val_mse: 135.3658 - val_mae: 7.5788\n",
      "Epoch 24/250\n",
      "745/745 - 1s - loss: 112.4780 - mse: 112.4780 - mae: 6.9379 - val_loss: 135.2456 - val_mse: 135.2456 - val_mae: 7.7674\n",
      "Epoch 25/250\n",
      "745/745 - 1s - loss: 113.8599 - mse: 113.8599 - mae: 6.9710 - val_loss: 130.6051 - val_mse: 130.6051 - val_mae: 7.5431\n",
      "Epoch 26/250\n",
      "745/745 - 1s - loss: 111.5980 - mse: 111.5980 - mae: 6.9367 - val_loss: 129.8240 - val_mse: 129.8240 - val_mae: 7.3318\n",
      "Epoch 27/250\n",
      "745/745 - 1s - loss: 112.4091 - mse: 112.4091 - mae: 6.9537 - val_loss: 133.5584 - val_mse: 133.5584 - val_mae: 7.4282\n",
      "Epoch 28/250\n",
      "745/745 - 1s - loss: 112.2197 - mse: 112.2197 - mae: 6.9392 - val_loss: 136.1742 - val_mse: 136.1742 - val_mae: 7.6584\n",
      "Epoch 29/250\n",
      "745/745 - 1s - loss: 112.9225 - mse: 112.9225 - mae: 6.9839 - val_loss: 132.1625 - val_mse: 132.1625 - val_mae: 7.4511\n",
      "Epoch 30/250\n",
      "745/745 - 1s - loss: 111.6412 - mse: 111.6412 - mae: 6.9592 - val_loss: 131.1343 - val_mse: 131.1343 - val_mae: 7.3765\n",
      "Epoch 31/250\n",
      "745/745 - 1s - loss: 111.7780 - mse: 111.7780 - mae: 6.9464 - val_loss: 137.6735 - val_mse: 137.6735 - val_mae: 7.6707\n",
      "Epoch 32/250\n",
      "745/745 - 1s - loss: 112.8247 - mse: 112.8247 - mae: 6.9544 - val_loss: 130.7578 - val_mse: 130.7578 - val_mae: 7.4208\n",
      "Epoch 33/250\n",
      "745/745 - 1s - loss: 111.9350 - mse: 111.9350 - mae: 6.9251 - val_loss: 135.7223 - val_mse: 135.7223 - val_mae: 7.7339\n",
      "Epoch 34/250\n",
      "745/745 - 1s - loss: 111.8072 - mse: 111.8072 - mae: 6.9628 - val_loss: 133.6284 - val_mse: 133.6284 - val_mae: 7.5441\n",
      "Epoch 35/250\n",
      "745/745 - 1s - loss: 112.2365 - mse: 112.2365 - mae: 6.9183 - val_loss: 131.7843 - val_mse: 131.7843 - val_mae: 7.4190\n",
      "Epoch 36/250\n",
      "745/745 - 1s - loss: 111.6021 - mse: 111.6021 - mae: 6.9130 - val_loss: 138.1586 - val_mse: 138.1586 - val_mae: 7.6722\n",
      "Epoch 37/250\n",
      "745/745 - 1s - loss: 112.2415 - mse: 112.2415 - mae: 6.9401 - val_loss: 135.3897 - val_mse: 135.3897 - val_mae: 7.4769\n",
      "Epoch 38/250\n",
      "745/745 - 1s - loss: 114.0389 - mse: 114.0389 - mae: 6.9807 - val_loss: 132.5300 - val_mse: 132.5300 - val_mae: 7.3771\n",
      "Epoch 39/250\n",
      "745/745 - 1s - loss: 110.5008 - mse: 110.5008 - mae: 6.8633 - val_loss: 140.2406 - val_mse: 140.2406 - val_mae: 7.9784\n",
      "Epoch 40/250\n",
      "745/745 - 1s - loss: 111.3858 - mse: 111.3858 - mae: 6.9329 - val_loss: 143.8466 - val_mse: 143.8466 - val_mae: 8.0177\n",
      "Epoch 41/250\n",
      "745/745 - 1s - loss: 112.2577 - mse: 112.2577 - mae: 6.9617 - val_loss: 139.1408 - val_mse: 139.1408 - val_mae: 7.4374\n",
      "Epoch 42/250\n",
      "745/745 - 1s - loss: 110.7198 - mse: 110.7198 - mae: 6.9014 - val_loss: 129.9816 - val_mse: 129.9816 - val_mae: 7.4118\n",
      "Epoch 43/250\n",
      "745/745 - 1s - loss: 111.5607 - mse: 111.5607 - mae: 6.9307 - val_loss: 141.4498 - val_mse: 141.4498 - val_mae: 7.9006\n",
      "Epoch 44/250\n",
      "745/745 - 1s - loss: 112.2785 - mse: 112.2785 - mae: 6.9329 - val_loss: 129.8406 - val_mse: 129.8406 - val_mae: 7.4265\n",
      "Epoch 45/250\n",
      "745/745 - 1s - loss: 111.4032 - mse: 111.4032 - mae: 6.9289 - val_loss: 134.1003 - val_mse: 134.1003 - val_mae: 7.4349\n",
      "Epoch 46/250\n",
      "745/745 - 1s - loss: 112.3353 - mse: 112.3353 - mae: 6.9230 - val_loss: 129.3088 - val_mse: 129.3088 - val_mae: 7.4943\n",
      "Epoch 47/250\n",
      "745/745 - 1s - loss: 111.5113 - mse: 111.5113 - mae: 6.9384 - val_loss: 142.5381 - val_mse: 142.5381 - val_mae: 7.6799\n",
      "Epoch 48/250\n",
      "745/745 - 1s - loss: 113.1436 - mse: 113.1436 - mae: 6.9771 - val_loss: 167.7622 - val_mse: 167.7622 - val_mae: 8.0991\n",
      "Epoch 49/250\n",
      "745/745 - 1s - loss: 112.4969 - mse: 112.4969 - mae: 6.9525 - val_loss: 139.0070 - val_mse: 139.0070 - val_mae: 7.5786\n",
      "Epoch 50/250\n",
      "745/745 - 1s - loss: 110.1247 - mse: 110.1247 - mae: 6.8859 - val_loss: 142.0834 - val_mse: 142.0834 - val_mae: 7.7227\n",
      "Epoch 51/250\n",
      "745/745 - 1s - loss: 110.4140 - mse: 110.4140 - mae: 6.8961 - val_loss: 137.2353 - val_mse: 137.2353 - val_mae: 7.6535\n",
      "Epoch 52/250\n",
      "745/745 - 1s - loss: 110.1739 - mse: 110.1739 - mae: 6.8860 - val_loss: 137.9893 - val_mse: 137.9893 - val_mae: 7.8731\n",
      "Epoch 53/250\n",
      "745/745 - 1s - loss: 109.5361 - mse: 109.5361 - mae: 6.8809 - val_loss: 146.2427 - val_mse: 146.2427 - val_mae: 8.3030\n",
      "Epoch 54/250\n",
      "745/745 - 1s - loss: 110.8558 - mse: 110.8558 - mae: 6.9240 - val_loss: 135.2053 - val_mse: 135.2053 - val_mae: 7.6782\n",
      "Epoch 55/250\n",
      "745/745 - 1s - loss: 110.6125 - mse: 110.6125 - mae: 6.9049 - val_loss: 132.2999 - val_mse: 132.2999 - val_mae: 7.4255\n",
      "Epoch 56/250\n",
      "745/745 - 1s - loss: 111.1081 - mse: 111.1081 - mae: 6.9029 - val_loss: 133.4657 - val_mse: 133.4657 - val_mae: 7.3727\n",
      "Epoch 57/250\n",
      "745/745 - 1s - loss: 109.3957 - mse: 109.3957 - mae: 6.8436 - val_loss: 135.2137 - val_mse: 135.2137 - val_mae: 7.6790\n",
      "Epoch 58/250\n",
      "745/745 - 1s - loss: 110.9071 - mse: 110.9071 - mae: 6.9048 - val_loss: 131.6966 - val_mse: 131.6966 - val_mae: 7.4018\n",
      "Epoch 59/250\n",
      "745/745 - 1s - loss: 111.3166 - mse: 111.3166 - mae: 6.8988 - val_loss: 129.0976 - val_mse: 129.0976 - val_mae: 7.4214\n",
      "Epoch 60/250\n",
      "745/745 - 1s - loss: 109.0831 - mse: 109.0831 - mae: 6.8593 - val_loss: 130.5309 - val_mse: 130.5309 - val_mae: 7.4208\n",
      "Epoch 61/250\n",
      "745/745 - 1s - loss: 111.5963 - mse: 111.5963 - mae: 6.9201 - val_loss: 134.1710 - val_mse: 134.1710 - val_mae: 7.3936\n",
      "Epoch 62/250\n",
      "745/745 - 1s - loss: 109.2533 - mse: 109.2533 - mae: 6.8696 - val_loss: 134.1312 - val_mse: 134.1312 - val_mae: 7.4741\n",
      "Epoch 63/250\n",
      "745/745 - 1s - loss: 109.3619 - mse: 109.3619 - mae: 6.8638 - val_loss: 130.5542 - val_mse: 130.5542 - val_mae: 7.5154\n",
      "Epoch 64/250\n",
      "745/745 - 1s - loss: 109.3448 - mse: 109.3448 - mae: 6.8583 - val_loss: 130.4925 - val_mse: 130.4925 - val_mae: 7.4784\n",
      "Epoch 65/250\n",
      "745/745 - 1s - loss: 108.8426 - mse: 108.8426 - mae: 6.8558 - val_loss: 131.2214 - val_mse: 131.2214 - val_mae: 7.4692\n",
      "Epoch 66/250\n",
      "745/745 - 1s - loss: 111.0903 - mse: 111.0903 - mae: 6.9046 - val_loss: 140.8307 - val_mse: 140.8307 - val_mae: 7.8766\n",
      "Epoch 67/250\n",
      "745/745 - 1s - loss: 109.8621 - mse: 109.8621 - mae: 6.8557 - val_loss: 137.9067 - val_mse: 137.9067 - val_mae: 7.5170\n",
      "Epoch 68/250\n",
      "745/745 - 1s - loss: 109.3462 - mse: 109.3462 - mae: 6.8705 - val_loss: 131.6098 - val_mse: 131.6098 - val_mae: 7.5760\n",
      "Epoch 69/250\n",
      "745/745 - 1s - loss: 108.9637 - mse: 108.9637 - mae: 6.8471 - val_loss: 132.8850 - val_mse: 132.8850 - val_mae: 7.4629\n",
      "Epoch 70/250\n",
      "745/745 - 1s - loss: 108.4242 - mse: 108.4242 - mae: 6.8363 - val_loss: 133.3762 - val_mse: 133.3762 - val_mae: 7.8084\n",
      "Epoch 71/250\n",
      "745/745 - 1s - loss: 109.0163 - mse: 109.0163 - mae: 6.8166 - val_loss: 137.9318 - val_mse: 137.9318 - val_mae: 7.8153\n",
      "Epoch 72/250\n",
      "745/745 - 1s - loss: 109.9940 - mse: 109.9940 - mae: 6.8693 - val_loss: 133.2080 - val_mse: 133.2080 - val_mae: 7.4723\n",
      "Epoch 73/250\n",
      "745/745 - 1s - loss: 109.3256 - mse: 109.3256 - mae: 6.8442 - val_loss: 142.6478 - val_mse: 142.6478 - val_mae: 8.0060\n",
      "Epoch 74/250\n",
      "745/745 - 1s - loss: 108.3616 - mse: 108.3616 - mae: 6.8189 - val_loss: 130.1149 - val_mse: 130.1149 - val_mae: 7.4756\n",
      "Epoch 75/250\n",
      "745/745 - 1s - loss: 108.8460 - mse: 108.8460 - mae: 6.8423 - val_loss: 133.0578 - val_mse: 133.0578 - val_mae: 7.5226\n",
      "Epoch 76/250\n",
      "745/745 - 1s - loss: 108.0545 - mse: 108.0545 - mae: 6.8038 - val_loss: 129.8721 - val_mse: 129.8721 - val_mae: 7.5022\n",
      "Epoch 77/250\n",
      "745/745 - 1s - loss: 109.6894 - mse: 109.6894 - mae: 6.8465 - val_loss: 132.3133 - val_mse: 132.3133 - val_mae: 7.4210\n",
      "Epoch 78/250\n",
      "745/745 - 1s - loss: 108.7960 - mse: 108.7960 - mae: 6.8459 - val_loss: 137.8355 - val_mse: 137.8355 - val_mae: 7.3599\n",
      "Epoch 79/250\n",
      "745/745 - 1s - loss: 108.6749 - mse: 108.6749 - mae: 6.8320 - val_loss: 145.6282 - val_mse: 145.6282 - val_mae: 8.0405\n",
      "Epoch 80/250\n",
      "745/745 - 1s - loss: 108.5890 - mse: 108.5890 - mae: 6.8340 - val_loss: 130.6197 - val_mse: 130.6197 - val_mae: 7.5830\n",
      "Epoch 81/250\n",
      "745/745 - 1s - loss: 108.3920 - mse: 108.3920 - mae: 6.8283 - val_loss: 133.7614 - val_mse: 133.7614 - val_mae: 7.4708\n",
      "Epoch 82/250\n",
      "745/745 - 1s - loss: 108.1681 - mse: 108.1681 - mae: 6.8251 - val_loss: 131.0532 - val_mse: 131.0532 - val_mae: 7.3612\n",
      "Epoch 83/250\n",
      "745/745 - 1s - loss: 109.2512 - mse: 109.2512 - mae: 6.8322 - val_loss: 128.3463 - val_mse: 128.3463 - val_mae: 7.4190\n",
      "Epoch 84/250\n",
      "745/745 - 1s - loss: 108.3505 - mse: 108.3505 - mae: 6.7793 - val_loss: 143.4978 - val_mse: 143.4978 - val_mae: 8.0393\n",
      "Epoch 85/250\n",
      "745/745 - 1s - loss: 109.6274 - mse: 109.6274 - mae: 6.8453 - val_loss: 130.7657 - val_mse: 130.7657 - val_mae: 7.3583\n",
      "Epoch 86/250\n",
      "745/745 - 1s - loss: 108.3813 - mse: 108.3813 - mae: 6.8204 - val_loss: 135.2654 - val_mse: 135.2654 - val_mae: 7.5889\n",
      "Epoch 87/250\n",
      "745/745 - 1s - loss: 108.4398 - mse: 108.4398 - mae: 6.8267 - val_loss: 134.8573 - val_mse: 134.8573 - val_mae: 7.5059\n",
      "Epoch 88/250\n",
      "745/745 - 1s - loss: 108.7683 - mse: 108.7683 - mae: 6.8083 - val_loss: 129.4003 - val_mse: 129.4003 - val_mae: 7.4066\n",
      "Epoch 89/250\n",
      "745/745 - 1s - loss: 108.3946 - mse: 108.3946 - mae: 6.8116 - val_loss: 131.6602 - val_mse: 131.6602 - val_mae: 7.4422\n",
      "Epoch 90/250\n",
      "745/745 - 1s - loss: 107.6698 - mse: 107.6698 - mae: 6.8035 - val_loss: 135.4993 - val_mse: 135.4993 - val_mae: 7.4542\n",
      "Epoch 91/250\n",
      "745/745 - 1s - loss: 108.4147 - mse: 108.4147 - mae: 6.8333 - val_loss: 130.6016 - val_mse: 130.6016 - val_mae: 7.2712\n",
      "Epoch 92/250\n",
      "745/745 - 1s - loss: 107.1475 - mse: 107.1475 - mae: 6.8157 - val_loss: 134.2221 - val_mse: 134.2221 - val_mae: 7.5749\n",
      "Epoch 93/250\n",
      "745/745 - 1s - loss: 108.6089 - mse: 108.6089 - mae: 6.8155 - val_loss: 130.3947 - val_mse: 130.3947 - val_mae: 7.3248\n",
      "Epoch 94/250\n",
      "745/745 - 1s - loss: 108.3572 - mse: 108.3572 - mae: 6.8059 - val_loss: 133.8526 - val_mse: 133.8526 - val_mae: 7.4259\n",
      "Epoch 95/250\n",
      "745/745 - 1s - loss: 107.6812 - mse: 107.6812 - mae: 6.7871 - val_loss: 136.3836 - val_mse: 136.3836 - val_mae: 7.7141\n",
      "Epoch 96/250\n",
      "745/745 - 1s - loss: 109.4351 - mse: 109.4351 - mae: 6.8358 - val_loss: 140.7402 - val_mse: 140.7402 - val_mae: 7.5756\n",
      "Epoch 97/250\n",
      "745/745 - 1s - loss: 108.1182 - mse: 108.1182 - mae: 6.8045 - val_loss: 134.1258 - val_mse: 134.1258 - val_mae: 7.4595\n",
      "Epoch 98/250\n",
      "745/745 - 1s - loss: 107.5053 - mse: 107.5053 - mae: 6.7843 - val_loss: 135.1893 - val_mse: 135.1893 - val_mae: 7.5020\n",
      "Epoch 99/250\n",
      "745/745 - 1s - loss: 106.9745 - mse: 106.9745 - mae: 6.7783 - val_loss: 136.8150 - val_mse: 136.8150 - val_mae: 7.7316\n",
      "Epoch 100/250\n",
      "745/745 - 1s - loss: 106.5664 - mse: 106.5664 - mae: 6.7582 - val_loss: 133.3158 - val_mse: 133.3158 - val_mae: 7.5592\n",
      "Epoch 101/250\n",
      "745/745 - 1s - loss: 106.4399 - mse: 106.4399 - mae: 6.7517 - val_loss: 136.8128 - val_mse: 136.8128 - val_mae: 7.6380\n",
      "Epoch 102/250\n",
      "745/745 - 1s - loss: 107.8717 - mse: 107.8717 - mae: 6.7992 - val_loss: 125.5284 - val_mse: 125.5284 - val_mae: 7.1817\n",
      "Epoch 103/250\n",
      "745/745 - 1s - loss: 106.5239 - mse: 106.5239 - mae: 6.7633 - val_loss: 130.2979 - val_mse: 130.2979 - val_mae: 7.4820\n",
      "Epoch 104/250\n",
      "745/745 - 1s - loss: 107.3592 - mse: 107.3592 - mae: 6.7908 - val_loss: 138.3873 - val_mse: 138.3873 - val_mae: 7.4640\n",
      "Epoch 105/250\n",
      "745/745 - 1s - loss: 107.2413 - mse: 107.2413 - mae: 6.7585 - val_loss: 138.2061 - val_mse: 138.2061 - val_mae: 7.7713\n",
      "Epoch 106/250\n",
      "745/745 - 1s - loss: 105.4517 - mse: 105.4517 - mae: 6.7359 - val_loss: 139.0832 - val_mse: 139.0832 - val_mae: 7.5244\n",
      "Epoch 107/250\n",
      "745/745 - 1s - loss: 107.6324 - mse: 107.6324 - mae: 6.7915 - val_loss: 139.5266 - val_mse: 139.5266 - val_mae: 7.9333\n",
      "Epoch 108/250\n",
      "745/745 - 1s - loss: 106.8064 - mse: 106.8064 - mae: 6.7673 - val_loss: 132.1568 - val_mse: 132.1568 - val_mae: 7.5809\n",
      "Epoch 109/250\n",
      "745/745 - 1s - loss: 106.5576 - mse: 106.5576 - mae: 6.7547 - val_loss: 128.6041 - val_mse: 128.6041 - val_mae: 7.3130\n",
      "Epoch 110/250\n",
      "745/745 - 1s - loss: 105.8123 - mse: 105.8123 - mae: 6.7230 - val_loss: 138.0622 - val_mse: 138.0622 - val_mae: 7.7485\n",
      "Epoch 111/250\n",
      "745/745 - 1s - loss: 106.5894 - mse: 106.5894 - mae: 6.7426 - val_loss: 134.6898 - val_mse: 134.6898 - val_mae: 7.5567\n",
      "Epoch 112/250\n",
      "745/745 - 1s - loss: 105.7460 - mse: 105.7460 - mae: 6.7473 - val_loss: 127.3334 - val_mse: 127.3334 - val_mae: 7.2683\n",
      "Epoch 113/250\n",
      "745/745 - 1s - loss: 106.5720 - mse: 106.5720 - mae: 6.7424 - val_loss: 133.6357 - val_mse: 133.6357 - val_mae: 7.7587\n",
      "Epoch 114/250\n",
      "745/745 - 1s - loss: 107.6153 - mse: 107.6153 - mae: 6.7897 - val_loss: 137.9733 - val_mse: 137.9733 - val_mae: 7.4868\n",
      "Epoch 115/250\n",
      "745/745 - 1s - loss: 106.0128 - mse: 106.0128 - mae: 6.7089 - val_loss: 126.9394 - val_mse: 126.9394 - val_mae: 7.4103\n",
      "Epoch 116/250\n",
      "745/745 - 1s - loss: 106.0819 - mse: 106.0819 - mae: 6.7454 - val_loss: 130.7288 - val_mse: 130.7288 - val_mae: 7.4720\n",
      "Epoch 117/250\n",
      "745/745 - 1s - loss: 106.6491 - mse: 106.6491 - mae: 6.7872 - val_loss: 131.9651 - val_mse: 131.9651 - val_mae: 7.2736\n",
      "Epoch 118/250\n",
      "745/745 - 1s - loss: 105.8085 - mse: 105.8085 - mae: 6.7212 - val_loss: 131.9615 - val_mse: 131.9615 - val_mae: 7.3469\n",
      "Epoch 119/250\n",
      "745/745 - 1s - loss: 106.3316 - mse: 106.3316 - mae: 6.7562 - val_loss: 129.2934 - val_mse: 129.2934 - val_mae: 7.3293\n",
      "Epoch 120/250\n",
      "745/745 - 1s - loss: 106.3284 - mse: 106.3284 - mae: 6.7544 - val_loss: 139.8959 - val_mse: 139.8959 - val_mae: 7.7706\n",
      "Epoch 121/250\n",
      "745/745 - 1s - loss: 107.7739 - mse: 107.7739 - mae: 6.7993 - val_loss: 129.2414 - val_mse: 129.2414 - val_mae: 7.4056\n",
      "Epoch 122/250\n",
      "745/745 - 1s - loss: 105.7835 - mse: 105.7835 - mae: 6.7047 - val_loss: 133.8115 - val_mse: 133.8115 - val_mae: 7.6628\n",
      "Epoch 123/250\n",
      "745/745 - 1s - loss: 106.9069 - mse: 106.9069 - mae: 6.7631 - val_loss: 140.7729 - val_mse: 140.7729 - val_mae: 7.5092\n",
      "Epoch 124/250\n",
      "745/745 - 1s - loss: 106.7476 - mse: 106.7476 - mae: 6.7355 - val_loss: 130.3804 - val_mse: 130.3804 - val_mae: 7.5283\n",
      "Epoch 125/250\n",
      "745/745 - 1s - loss: 106.1774 - mse: 106.1774 - mae: 6.7443 - val_loss: 132.2145 - val_mse: 132.2145 - val_mae: 7.4956\n",
      "Epoch 126/250\n",
      "745/745 - 1s - loss: 105.0730 - mse: 105.0730 - mae: 6.7352 - val_loss: 129.8422 - val_mse: 129.8422 - val_mae: 7.3473\n",
      "Epoch 127/250\n",
      "745/745 - 1s - loss: 106.4110 - mse: 106.4110 - mae: 6.7509 - val_loss: 130.9893 - val_mse: 130.9893 - val_mae: 7.5199\n",
      "Epoch 128/250\n",
      "745/745 - 1s - loss: 104.6284 - mse: 104.6284 - mae: 6.6820 - val_loss: 131.4331 - val_mse: 131.4331 - val_mae: 7.4173\n",
      "Epoch 129/250\n",
      "745/745 - 1s - loss: 105.6354 - mse: 105.6354 - mae: 6.7324 - val_loss: 134.7795 - val_mse: 134.7795 - val_mae: 7.3970\n",
      "Epoch 130/250\n",
      "745/745 - 1s - loss: 105.4296 - mse: 105.4296 - mae: 6.7137 - val_loss: 135.2468 - val_mse: 135.2468 - val_mae: 7.5508\n",
      "Epoch 131/250\n",
      "745/745 - 1s - loss: 104.5564 - mse: 104.5564 - mae: 6.6726 - val_loss: 141.4036 - val_mse: 141.4036 - val_mae: 7.5976\n",
      "Epoch 132/250\n",
      "745/745 - 1s - loss: 104.6275 - mse: 104.6275 - mae: 6.7119 - val_loss: 137.0241 - val_mse: 137.0241 - val_mae: 7.5069\n",
      "Epoch 133/250\n",
      "745/745 - 1s - loss: 105.9537 - mse: 105.9537 - mae: 6.7182 - val_loss: 128.3786 - val_mse: 128.3786 - val_mae: 7.4648\n",
      "Epoch 134/250\n",
      "745/745 - 1s - loss: 105.0775 - mse: 105.0775 - mae: 6.7126 - val_loss: 134.6693 - val_mse: 134.6693 - val_mae: 7.6838\n",
      "Epoch 135/250\n",
      "745/745 - 1s - loss: 105.1709 - mse: 105.1709 - mae: 6.7019 - val_loss: 129.3765 - val_mse: 129.3765 - val_mae: 7.3614\n",
      "Epoch 136/250\n",
      "745/745 - 1s - loss: 105.9203 - mse: 105.9203 - mae: 6.7466 - val_loss: 138.7488 - val_mse: 138.7488 - val_mae: 7.4632\n",
      "Epoch 137/250\n",
      "745/745 - 1s - loss: 105.9359 - mse: 105.9359 - mae: 6.7297 - val_loss: 132.7270 - val_mse: 132.7270 - val_mae: 7.4512\n",
      "Epoch 138/250\n",
      "745/745 - 1s - loss: 105.7464 - mse: 105.7464 - mae: 6.7259 - val_loss: 139.0486 - val_mse: 139.0486 - val_mae: 7.8631\n",
      "Epoch 139/250\n",
      "745/745 - 1s - loss: 104.6450 - mse: 104.6450 - mae: 6.6833 - val_loss: 128.7649 - val_mse: 128.7649 - val_mae: 7.2183\n",
      "Epoch 140/250\n",
      "745/745 - 1s - loss: 105.1901 - mse: 105.1901 - mae: 6.7367 - val_loss: 129.7240 - val_mse: 129.7240 - val_mae: 7.2566\n",
      "Epoch 141/250\n",
      "745/745 - 1s - loss: 106.4655 - mse: 106.4655 - mae: 6.7365 - val_loss: 127.6404 - val_mse: 127.6404 - val_mae: 7.3162\n",
      "Epoch 142/250\n",
      "745/745 - 1s - loss: 104.5333 - mse: 104.5333 - mae: 6.6848 - val_loss: 143.7417 - val_mse: 143.7417 - val_mae: 7.7116\n",
      "Epoch 143/250\n",
      "745/745 - 1s - loss: 104.3793 - mse: 104.3793 - mae: 6.7159 - val_loss: 135.2952 - val_mse: 135.2952 - val_mae: 7.3008\n",
      "Epoch 144/250\n",
      "745/745 - 1s - loss: 105.5663 - mse: 105.5663 - mae: 6.7321 - val_loss: 131.6082 - val_mse: 131.6082 - val_mae: 7.2865\n",
      "Epoch 145/250\n",
      "745/745 - 1s - loss: 104.9025 - mse: 104.9025 - mae: 6.6934 - val_loss: 151.7003 - val_mse: 151.7003 - val_mae: 8.1106\n",
      "Epoch 146/250\n",
      "745/745 - 1s - loss: 104.3218 - mse: 104.3218 - mae: 6.6846 - val_loss: 133.7781 - val_mse: 133.7781 - val_mae: 7.7037\n",
      "Epoch 147/250\n",
      "745/745 - 1s - loss: 105.1801 - mse: 105.1801 - mae: 6.7007 - val_loss: 130.1176 - val_mse: 130.1176 - val_mae: 7.4079\n",
      "Epoch 148/250\n",
      "745/745 - 1s - loss: 104.7809 - mse: 104.7809 - mae: 6.7010 - val_loss: 136.1599 - val_mse: 136.1599 - val_mae: 7.5279\n",
      "Epoch 149/250\n",
      "745/745 - 1s - loss: 104.2644 - mse: 104.2644 - mae: 6.6671 - val_loss: 131.4688 - val_mse: 131.4688 - val_mae: 7.4441\n",
      "Epoch 150/250\n",
      "745/745 - 1s - loss: 104.3292 - mse: 104.3292 - mae: 6.6995 - val_loss: 130.9748 - val_mse: 130.9748 - val_mae: 7.3061\n",
      "Epoch 151/250\n",
      "745/745 - 1s - loss: 103.4635 - mse: 103.4635 - mae: 6.6387 - val_loss: 129.0124 - val_mse: 129.0124 - val_mae: 7.2982\n",
      "Epoch 152/250\n",
      "745/745 - 1s - loss: 104.8997 - mse: 104.8997 - mae: 6.7282 - val_loss: 131.6684 - val_mse: 131.6684 - val_mae: 7.2835\n",
      "Epoch 153/250\n",
      "745/745 - 1s - loss: 105.2807 - mse: 105.2807 - mae: 6.7171 - val_loss: 130.7562 - val_mse: 130.7562 - val_mae: 7.3196\n",
      "Epoch 154/250\n",
      "745/745 - 1s - loss: 104.1134 - mse: 104.1134 - mae: 6.6902 - val_loss: 130.5334 - val_mse: 130.5334 - val_mae: 7.3041\n",
      "Epoch 155/250\n",
      "745/745 - 1s - loss: 105.0005 - mse: 105.0005 - mae: 6.6815 - val_loss: 134.1173 - val_mse: 134.1173 - val_mae: 7.4875\n",
      "Epoch 156/250\n",
      "745/745 - 1s - loss: 103.1348 - mse: 103.1348 - mae: 6.6502 - val_loss: 134.1234 - val_mse: 134.1234 - val_mae: 7.4566\n",
      "Epoch 157/250\n",
      "745/745 - 1s - loss: 105.3508 - mse: 105.3508 - mae: 6.7230 - val_loss: 138.2331 - val_mse: 138.2331 - val_mae: 7.4553\n",
      "Epoch 158/250\n",
      "745/745 - 1s - loss: 104.6352 - mse: 104.6352 - mae: 6.7085 - val_loss: 137.5148 - val_mse: 137.5148 - val_mae: 7.5188\n",
      "Epoch 159/250\n",
      "745/745 - 1s - loss: 104.5876 - mse: 104.5876 - mae: 6.6995 - val_loss: 140.9106 - val_mse: 140.9106 - val_mae: 7.4523\n",
      "Epoch 160/250\n",
      "745/745 - 1s - loss: 104.6791 - mse: 104.6791 - mae: 6.7231 - val_loss: 131.9972 - val_mse: 131.9972 - val_mae: 7.5280\n",
      "Epoch 161/250\n",
      "745/745 - 1s - loss: 104.6929 - mse: 104.6929 - mae: 6.6783 - val_loss: 132.5472 - val_mse: 132.5472 - val_mae: 7.4219\n",
      "Epoch 162/250\n",
      "745/745 - 1s - loss: 103.3568 - mse: 103.3568 - mae: 6.6785 - val_loss: 142.2474 - val_mse: 142.2474 - val_mae: 7.6416\n",
      "Epoch 163/250\n",
      "745/745 - 1s - loss: 104.5368 - mse: 104.5368 - mae: 6.6955 - val_loss: 131.2144 - val_mse: 131.2144 - val_mae: 7.5355\n",
      "Epoch 164/250\n",
      "745/745 - 1s - loss: 105.3670 - mse: 105.3670 - mae: 6.7045 - val_loss: 129.6251 - val_mse: 129.6251 - val_mae: 7.4255\n",
      "Epoch 165/250\n",
      "745/745 - 1s - loss: 104.4599 - mse: 104.4599 - mae: 6.6638 - val_loss: 130.0924 - val_mse: 130.0924 - val_mae: 7.2261\n",
      "Epoch 166/250\n",
      "745/745 - 1s - loss: 102.8805 - mse: 102.8805 - mae: 6.6168 - val_loss: 134.1223 - val_mse: 134.1223 - val_mae: 7.4143\n",
      "Epoch 167/250\n",
      "745/745 - 1s - loss: 103.4375 - mse: 103.4375 - mae: 6.6658 - val_loss: 133.5653 - val_mse: 133.5653 - val_mae: 7.4031\n",
      "Epoch 168/250\n",
      "745/745 - 1s - loss: 103.0668 - mse: 103.0668 - mae: 6.6470 - val_loss: 130.5316 - val_mse: 130.5316 - val_mae: 7.4896\n",
      "Epoch 169/250\n",
      "745/745 - 1s - loss: 102.6606 - mse: 102.6606 - mae: 6.6248 - val_loss: 131.2018 - val_mse: 131.2018 - val_mae: 7.4391\n",
      "Epoch 170/250\n",
      "745/745 - 1s - loss: 103.2505 - mse: 103.2505 - mae: 6.6370 - val_loss: 131.7876 - val_mse: 131.7876 - val_mae: 7.3160\n",
      "Epoch 171/250\n",
      "745/745 - 1s - loss: 103.8746 - mse: 103.8746 - mae: 6.6554 - val_loss: 129.2105 - val_mse: 129.2105 - val_mae: 7.3988\n",
      "Epoch 172/250\n",
      "745/745 - 1s - loss: 103.0317 - mse: 103.0317 - mae: 6.6521 - val_loss: 130.8315 - val_mse: 130.8315 - val_mae: 7.3445\n",
      "Epoch 173/250\n",
      "745/745 - 1s - loss: 102.9962 - mse: 102.9962 - mae: 6.6406 - val_loss: 127.1811 - val_mse: 127.1811 - val_mae: 7.3571\n",
      "Epoch 174/250\n",
      "745/745 - 1s - loss: 103.5228 - mse: 103.5228 - mae: 6.6771 - val_loss: 138.3165 - val_mse: 138.3165 - val_mae: 7.4787\n",
      "Epoch 175/250\n",
      "745/745 - 1s - loss: 104.4539 - mse: 104.4539 - mae: 6.6833 - val_loss: 137.6293 - val_mse: 137.6293 - val_mae: 7.3701\n",
      "Epoch 176/250\n",
      "745/745 - 1s - loss: 102.4674 - mse: 102.4674 - mae: 6.6051 - val_loss: 127.3503 - val_mse: 127.3503 - val_mae: 7.3293\n",
      "Epoch 177/250\n",
      "745/745 - 1s - loss: 103.0804 - mse: 103.0804 - mae: 6.6391 - val_loss: 140.6722 - val_mse: 140.6722 - val_mae: 7.8504\n",
      "Epoch 178/250\n",
      "745/745 - 1s - loss: 104.0852 - mse: 104.0852 - mae: 6.6699 - val_loss: 127.1843 - val_mse: 127.1843 - val_mae: 7.2724\n",
      "Epoch 179/250\n",
      "745/745 - 1s - loss: 102.2761 - mse: 102.2761 - mae: 6.6136 - val_loss: 130.4741 - val_mse: 130.4741 - val_mae: 7.2594\n",
      "Epoch 180/250\n",
      "745/745 - 1s - loss: 102.9827 - mse: 102.9827 - mae: 6.6639 - val_loss: 130.9066 - val_mse: 130.9066 - val_mae: 7.2608\n",
      "Epoch 181/250\n",
      "745/745 - 1s - loss: 103.6543 - mse: 103.6543 - mae: 6.6790 - val_loss: 129.6043 - val_mse: 129.6043 - val_mae: 7.2956\n",
      "Epoch 182/250\n",
      "745/745 - 1s - loss: 102.2254 - mse: 102.2254 - mae: 6.6185 - val_loss: 135.8018 - val_mse: 135.8018 - val_mae: 7.6297\n",
      "Epoch 183/250\n",
      "745/745 - 1s - loss: 101.9603 - mse: 101.9603 - mae: 6.6385 - val_loss: 129.5163 - val_mse: 129.5163 - val_mae: 7.2969\n",
      "Epoch 184/250\n",
      "745/745 - 1s - loss: 102.8994 - mse: 102.8994 - mae: 6.6398 - val_loss: 130.5647 - val_mse: 130.5647 - val_mae: 7.3677\n",
      "Epoch 185/250\n",
      "745/745 - 1s - loss: 102.7179 - mse: 102.7179 - mae: 6.6164 - val_loss: 133.1859 - val_mse: 133.1859 - val_mae: 7.4323\n",
      "Epoch 186/250\n",
      "745/745 - 1s - loss: 103.7199 - mse: 103.7199 - mae: 6.6653 - val_loss: 130.3399 - val_mse: 130.3399 - val_mae: 7.3089\n",
      "Epoch 187/250\n",
      "745/745 - 1s - loss: 102.4965 - mse: 102.4965 - mae: 6.5983 - val_loss: 131.3348 - val_mse: 131.3348 - val_mae: 7.3519\n",
      "Epoch 188/250\n",
      "745/745 - 1s - loss: 103.0991 - mse: 103.0991 - mae: 6.6468 - val_loss: 134.6643 - val_mse: 134.6643 - val_mae: 7.4589\n",
      "Epoch 189/250\n",
      "745/745 - 1s - loss: 102.6181 - mse: 102.6181 - mae: 6.6117 - val_loss: 134.4299 - val_mse: 134.4299 - val_mae: 7.4880\n",
      "Epoch 190/250\n",
      "745/745 - 1s - loss: 102.4504 - mse: 102.4504 - mae: 6.6265 - val_loss: 129.9596 - val_mse: 129.9596 - val_mae: 7.2689\n",
      "Epoch 191/250\n",
      "745/745 - 1s - loss: 103.3779 - mse: 103.3779 - mae: 6.6387 - val_loss: 137.2685 - val_mse: 137.2685 - val_mae: 7.5351\n",
      "Epoch 192/250\n",
      "745/745 - 1s - loss: 103.3222 - mse: 103.3222 - mae: 6.6392 - val_loss: 128.5265 - val_mse: 128.5265 - val_mae: 7.4404\n",
      "Epoch 193/250\n",
      "745/745 - 1s - loss: 101.9973 - mse: 101.9973 - mae: 6.6195 - val_loss: 130.2897 - val_mse: 130.2897 - val_mae: 7.3431\n",
      "Epoch 194/250\n",
      "745/745 - 1s - loss: 102.8664 - mse: 102.8664 - mae: 6.6370 - val_loss: 128.7946 - val_mse: 128.7946 - val_mae: 7.3637\n",
      "Epoch 195/250\n",
      "745/745 - 1s - loss: 102.1517 - mse: 102.1517 - mae: 6.6282 - val_loss: 131.6702 - val_mse: 131.6702 - val_mae: 7.3733\n",
      "Epoch 196/250\n",
      "745/745 - 1s - loss: 101.2019 - mse: 101.2019 - mae: 6.5719 - val_loss: 137.4883 - val_mse: 137.4883 - val_mae: 7.5050\n",
      "Epoch 197/250\n",
      "745/745 - 1s - loss: 102.0042 - mse: 102.0042 - mae: 6.5944 - val_loss: 130.9739 - val_mse: 130.9739 - val_mae: 7.3999\n",
      "Epoch 198/250\n",
      "745/745 - 1s - loss: 102.4348 - mse: 102.4348 - mae: 6.6267 - val_loss: 132.8755 - val_mse: 132.8755 - val_mae: 7.4699\n",
      "Epoch 199/250\n",
      "745/745 - 1s - loss: 102.4702 - mse: 102.4702 - mae: 6.6003 - val_loss: 131.6278 - val_mse: 131.6278 - val_mae: 7.4795\n",
      "Epoch 200/250\n",
      "745/745 - 1s - loss: 100.4442 - mse: 100.4442 - mae: 6.5835 - val_loss: 125.5068 - val_mse: 125.5068 - val_mae: 7.1778\n",
      "Epoch 201/250\n",
      "745/745 - 1s - loss: 101.6376 - mse: 101.6376 - mae: 6.5875 - val_loss: 133.9853 - val_mse: 133.9853 - val_mae: 7.3949\n",
      "Epoch 202/250\n",
      "745/745 - 1s - loss: 102.4103 - mse: 102.4103 - mae: 6.6171 - val_loss: 135.9222 - val_mse: 135.9222 - val_mae: 7.4652\n",
      "Epoch 203/250\n",
      "745/745 - 1s - loss: 102.7917 - mse: 102.7917 - mae: 6.6278 - val_loss: 130.9648 - val_mse: 130.9648 - val_mae: 7.4293\n",
      "Epoch 204/250\n",
      "745/745 - 1s - loss: 101.9201 - mse: 101.9201 - mae: 6.6151 - val_loss: 132.6966 - val_mse: 132.6966 - val_mae: 7.4218\n",
      "Epoch 205/250\n",
      "745/745 - 1s - loss: 102.0090 - mse: 102.0090 - mae: 6.6150 - val_loss: 131.3251 - val_mse: 131.3251 - val_mae: 7.2926\n",
      "Epoch 206/250\n",
      "745/745 - 1s - loss: 100.9636 - mse: 100.9636 - mae: 6.5843 - val_loss: 135.0440 - val_mse: 135.0440 - val_mae: 7.6035\n",
      "Epoch 207/250\n",
      "745/745 - 1s - loss: 102.4358 - mse: 102.4358 - mae: 6.6299 - val_loss: 129.2226 - val_mse: 129.2226 - val_mae: 7.3257\n",
      "Epoch 208/250\n",
      "745/745 - 1s - loss: 102.2818 - mse: 102.2818 - mae: 6.6283 - val_loss: 133.4572 - val_mse: 133.4572 - val_mae: 7.3082\n",
      "Epoch 209/250\n",
      "745/745 - 1s - loss: 100.9933 - mse: 100.9933 - mae: 6.5886 - val_loss: 131.6828 - val_mse: 131.6828 - val_mae: 7.3111\n",
      "Epoch 210/250\n",
      "745/745 - 1s - loss: 102.2140 - mse: 102.2140 - mae: 6.5923 - val_loss: 135.7094 - val_mse: 135.7094 - val_mae: 7.4365\n",
      "Epoch 211/250\n",
      "745/745 - 1s - loss: 101.9555 - mse: 101.9555 - mae: 6.6245 - val_loss: 132.9191 - val_mse: 132.9191 - val_mae: 7.3518\n",
      "Epoch 212/250\n",
      "745/745 - 1s - loss: 101.0173 - mse: 101.0173 - mae: 6.5886 - val_loss: 128.1488 - val_mse: 128.1488 - val_mae: 7.3026\n",
      "Epoch 213/250\n",
      "745/745 - 1s - loss: 101.7738 - mse: 101.7738 - mae: 6.5812 - val_loss: 129.5206 - val_mse: 129.5206 - val_mae: 7.3591\n",
      "Epoch 214/250\n",
      "745/745 - 1s - loss: 101.9135 - mse: 101.9135 - mae: 6.5958 - val_loss: 136.1196 - val_mse: 136.1196 - val_mae: 7.6280\n",
      "Epoch 215/250\n",
      "745/745 - 1s - loss: 101.8997 - mse: 101.8997 - mae: 6.6029 - val_loss: 128.2840 - val_mse: 128.2840 - val_mae: 7.2548\n",
      "Epoch 216/250\n",
      "745/745 - 1s - loss: 100.2225 - mse: 100.2225 - mae: 6.5301 - val_loss: 130.2054 - val_mse: 130.2054 - val_mae: 7.3731\n",
      "Epoch 217/250\n",
      "745/745 - 1s - loss: 101.8102 - mse: 101.8102 - mae: 6.5852 - val_loss: 129.7850 - val_mse: 129.7850 - val_mae: 7.2103\n",
      "Epoch 218/250\n",
      "745/745 - 1s - loss: 100.7870 - mse: 100.7870 - mae: 6.5877 - val_loss: 142.1450 - val_mse: 142.1450 - val_mae: 7.4698\n",
      "Epoch 219/250\n",
      "745/745 - 1s - loss: 102.0936 - mse: 102.0936 - mae: 6.6135 - val_loss: 134.2247 - val_mse: 134.2247 - val_mae: 7.3833\n",
      "Epoch 220/250\n",
      "745/745 - 1s - loss: 102.9430 - mse: 102.9430 - mae: 6.6192 - val_loss: 128.9193 - val_mse: 128.9193 - val_mae: 7.4707\n",
      "Epoch 221/250\n",
      "745/745 - 1s - loss: 100.6710 - mse: 100.6710 - mae: 6.5593 - val_loss: 135.4614 - val_mse: 135.4614 - val_mae: 7.5671\n",
      "Epoch 222/250\n",
      "745/745 - 1s - loss: 100.3234 - mse: 100.3234 - mae: 6.5487 - val_loss: 130.4083 - val_mse: 130.4083 - val_mae: 7.4094\n",
      "Epoch 223/250\n",
      "745/745 - 1s - loss: 101.3071 - mse: 101.3071 - mae: 6.5819 - val_loss: 141.8643 - val_mse: 141.8643 - val_mae: 7.5855\n",
      "Epoch 224/250\n",
      "745/745 - 1s - loss: 101.3281 - mse: 101.3281 - mae: 6.5797 - val_loss: 134.7944 - val_mse: 134.7944 - val_mae: 7.4907\n",
      "Epoch 225/250\n",
      "745/745 - 1s - loss: 102.0279 - mse: 102.0279 - mae: 6.6195 - val_loss: 136.8684 - val_mse: 136.8684 - val_mae: 7.6476\n",
      "Epoch 226/250\n",
      "745/745 - 1s - loss: 100.5648 - mse: 100.5648 - mae: 6.5469 - val_loss: 132.1264 - val_mse: 132.1264 - val_mae: 7.3848\n",
      "Epoch 227/250\n",
      "745/745 - 1s - loss: 100.8194 - mse: 100.8194 - mae: 6.5866 - val_loss: 129.9396 - val_mse: 129.9396 - val_mae: 7.3943\n",
      "Epoch 228/250\n",
      "745/745 - 1s - loss: 101.2868 - mse: 101.2868 - mae: 6.5834 - val_loss: 135.3798 - val_mse: 135.3798 - val_mae: 7.5087\n",
      "Epoch 229/250\n",
      "745/745 - 1s - loss: 101.5887 - mse: 101.5887 - mae: 6.5754 - val_loss: 130.3740 - val_mse: 130.3740 - val_mae: 7.2598\n",
      "Epoch 230/250\n",
      "745/745 - 1s - loss: 100.3956 - mse: 100.3956 - mae: 6.5598 - val_loss: 132.7876 - val_mse: 132.7876 - val_mae: 7.5226\n",
      "Epoch 231/250\n",
      "745/745 - 1s - loss: 100.6108 - mse: 100.6108 - mae: 6.5893 - val_loss: 130.8680 - val_mse: 130.8680 - val_mae: 7.3996\n",
      "Epoch 232/250\n",
      "745/745 - 1s - loss: 102.5565 - mse: 102.5565 - mae: 6.6040 - val_loss: 135.4716 - val_mse: 135.4716 - val_mae: 7.5544\n",
      "Epoch 233/250\n",
      "745/745 - 1s - loss: 101.4738 - mse: 101.4738 - mae: 6.5885 - val_loss: 133.9991 - val_mse: 133.9991 - val_mae: 7.3713\n",
      "Epoch 234/250\n",
      "745/745 - 1s - loss: 101.0315 - mse: 101.0315 - mae: 6.5658 - val_loss: 128.1641 - val_mse: 128.1641 - val_mae: 7.4416\n",
      "Epoch 235/250\n",
      "745/745 - 1s - loss: 100.5695 - mse: 100.5695 - mae: 6.5505 - val_loss: 130.3520 - val_mse: 130.3520 - val_mae: 7.3371\n",
      "Epoch 236/250\n",
      "745/745 - 1s - loss: 99.0918 - mse: 99.0918 - mae: 6.5335 - val_loss: 129.4499 - val_mse: 129.4499 - val_mae: 7.4366\n",
      "Epoch 237/250\n",
      "745/745 - 1s - loss: 100.6731 - mse: 100.6731 - mae: 6.5706 - val_loss: 132.2323 - val_mse: 132.2323 - val_mae: 7.3700\n",
      "Epoch 238/250\n",
      "745/745 - 1s - loss: 100.3081 - mse: 100.3081 - mae: 6.5222 - val_loss: 131.1087 - val_mse: 131.1087 - val_mae: 7.3313\n",
      "Epoch 239/250\n",
      "745/745 - 1s - loss: 100.9280 - mse: 100.9280 - mae: 6.5685 - val_loss: 127.8884 - val_mse: 127.8884 - val_mae: 7.3623\n",
      "Epoch 240/250\n",
      "745/745 - 1s - loss: 101.1679 - mse: 101.1679 - mae: 6.5806 - val_loss: 135.4022 - val_mse: 135.4022 - val_mae: 7.7375\n",
      "Epoch 241/250\n",
      "745/745 - 1s - loss: 100.0343 - mse: 100.0343 - mae: 6.5229 - val_loss: 131.6387 - val_mse: 131.6387 - val_mae: 7.3788\n",
      "Epoch 242/250\n",
      "745/745 - 1s - loss: 99.5545 - mse: 99.5545 - mae: 6.5359 - val_loss: 135.1407 - val_mse: 135.1407 - val_mae: 7.6673\n",
      "Epoch 243/250\n",
      "745/745 - 1s - loss: 100.6180 - mse: 100.6180 - mae: 6.5599 - val_loss: 132.0866 - val_mse: 132.0866 - val_mae: 7.3730\n",
      "Epoch 244/250\n",
      "745/745 - 1s - loss: 99.1792 - mse: 99.1792 - mae: 6.4732 - val_loss: 133.5611 - val_mse: 133.5611 - val_mae: 7.4282\n",
      "Epoch 245/250\n",
      "745/745 - 1s - loss: 99.9919 - mse: 99.9919 - mae: 6.5381 - val_loss: 130.2479 - val_mse: 130.2479 - val_mae: 7.3272\n",
      "Epoch 246/250\n",
      "745/745 - 1s - loss: 100.6113 - mse: 100.6113 - mae: 6.5491 - val_loss: 130.4564 - val_mse: 130.4564 - val_mae: 7.2094\n",
      "Epoch 247/250\n",
      "745/745 - 1s - loss: 99.7644 - mse: 99.7644 - mae: 6.5097 - val_loss: 133.5207 - val_mse: 133.5207 - val_mae: 7.2674\n",
      "Epoch 248/250\n",
      "745/745 - 1s - loss: 101.3518 - mse: 101.3518 - mae: 6.6210 - val_loss: 134.4061 - val_mse: 134.4061 - val_mae: 7.5521\n",
      "Epoch 249/250\n",
      "745/745 - 1s - loss: 98.8545 - mse: 98.8545 - mae: 6.4974 - val_loss: 132.6790 - val_mse: 132.6790 - val_mae: 7.3805\n",
      "Epoch 250/250\n",
      "745/745 - 1s - loss: 99.9553 - mse: 99.9553 - mae: 6.5505 - val_loss: 129.8404 - val_mse: 129.8404 - val_mae: 7.2157\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_sc, y_train, epochs = 250, batch_size = 16, verbose = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cc29601730>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6379, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6379,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(metrics.mean_squared_error(y_test,y_preds))\n",
    "mae = metrics.mean_absolute_error(y_test,y_preds)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test,y_preds)\n",
    "ex_var = metrics.explained_variance_score(y_test,y_preds)\n",
    "r2_score = metrics.r2_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error:\t11.55 Kelvins\n",
      "Mean Absolute Error:\t\t7.2 Kelvins\n",
      "Mean Abs. Percent Error:\t6.71%\n",
      "Explained Variance Score:\t0.8845\n",
      "R2 Score:\t\t\t0.8842\n"
     ]
    }
   ],
   "source": [
    "print(f\"Root Mean Squared Error:\t{np.round(rmse,2)} Kelvins\")\n",
    "print(f\"Mean Absolute Error:\t\t{np.round(mae,2)} Kelvins\")\n",
    "print(f\"Mean Abs. Percent Error:\t{np.round(mape,2)}%\")\n",
    "print(f\"Explained Variance Score:\t{np.round(ex_var,4)}\")\n",
    "print(f\"R2 Score:\t\t\t{np.round(r2_score,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "##### (still part 1)\n",
    "\n",
    "Let's reduce the number of dimensions and see what effect it has on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.95)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate PCA with enough dimensions to capture 95% of explained variance\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features is reduced from 81 to 17\n"
     ]
    }
   ],
   "source": [
    "X_train_pca = pca.transform(X_train_sc)\n",
    "X_test_pca = pca.transform(X_test_sc)\n",
    "\n",
    "print(f\"The number of features is reduced from {X_train_sc.shape[1]} to {X_train_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14884, 17)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_dim = X_train_pca.shape[1], activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "745/745 - 1s - loss: 704.6340 - mse: 704.6340 - mae: 17.6300 - val_loss: 336.0803 - val_mse: 336.0803 - val_mae: 13.3411\n",
      "Epoch 2/250\n",
      "745/745 - 1s - loss: 326.0791 - mse: 326.0791 - mae: 12.8393 - val_loss: 300.5837 - val_mse: 300.5837 - val_mae: 12.2428\n",
      "Epoch 3/250\n",
      "745/745 - 1s - loss: 297.0361 - mse: 297.0361 - mae: 12.0070 - val_loss: 278.7152 - val_mse: 278.7152 - val_mae: 11.6757\n",
      "Epoch 4/250\n",
      "745/745 - 1s - loss: 279.6574 - mse: 279.6574 - mae: 11.5048 - val_loss: 266.8719 - val_mse: 266.8719 - val_mae: 11.3392\n",
      "Epoch 5/250\n",
      "745/745 - 1s - loss: 268.4810 - mse: 268.4810 - mae: 11.1937 - val_loss: 266.4774 - val_mse: 266.4774 - val_mae: 11.3776\n",
      "Epoch 6/250\n",
      "745/745 - 1s - loss: 261.0764 - mse: 261.0764 - mae: 10.9924 - val_loss: 256.9066 - val_mse: 256.9066 - val_mae: 10.9036\n",
      "Epoch 7/250\n",
      "745/745 - 1s - loss: 255.0618 - mse: 255.0618 - mae: 10.8439 - val_loss: 251.4913 - val_mse: 251.4913 - val_mae: 10.8035\n",
      "Epoch 8/250\n",
      "745/745 - 1s - loss: 251.3345 - mse: 251.3345 - mae: 10.7407 - val_loss: 253.1575 - val_mse: 253.1575 - val_mae: 10.9831\n",
      "Epoch 9/250\n",
      "745/745 - 1s - loss: 246.6189 - mse: 246.6189 - mae: 10.6264 - val_loss: 244.1849 - val_mse: 244.1849 - val_mae: 10.5528\n",
      "Epoch 10/250\n",
      "745/745 - 1s - loss: 243.8919 - mse: 243.8919 - mae: 10.5576 - val_loss: 242.8967 - val_mse: 242.8967 - val_mae: 10.5783\n",
      "Epoch 11/250\n",
      "745/745 - 1s - loss: 240.2849 - mse: 240.2849 - mae: 10.4691 - val_loss: 240.2399 - val_mse: 240.2399 - val_mae: 10.4957\n",
      "Epoch 12/250\n",
      "745/745 - 1s - loss: 237.0335 - mse: 237.0335 - mae: 10.3908 - val_loss: 241.4596 - val_mse: 241.4596 - val_mae: 10.6936\n",
      "Epoch 13/250\n",
      "745/745 - 1s - loss: 234.0099 - mse: 234.0099 - mae: 10.3365 - val_loss: 235.6288 - val_mse: 235.6288 - val_mae: 10.4311\n",
      "Epoch 14/250\n",
      "745/745 - 1s - loss: 230.5576 - mse: 230.5576 - mae: 10.2470 - val_loss: 234.5661 - val_mse: 234.5661 - val_mae: 10.3939\n",
      "Epoch 15/250\n",
      "745/745 - 1s - loss: 229.0932 - mse: 229.0932 - mae: 10.2288 - val_loss: 231.6478 - val_mse: 231.6478 - val_mae: 10.2153\n",
      "Epoch 16/250\n",
      "745/745 - 1s - loss: 227.3327 - mse: 227.3327 - mae: 10.1702 - val_loss: 228.8622 - val_mse: 228.8622 - val_mae: 10.1407\n",
      "Epoch 17/250\n",
      "745/745 - 1s - loss: 223.4909 - mse: 223.4909 - mae: 10.0878 - val_loss: 236.0484 - val_mse: 236.0484 - val_mae: 10.2186\n",
      "Epoch 18/250\n",
      "745/745 - 1s - loss: 221.8076 - mse: 221.8076 - mae: 10.0214 - val_loss: 228.2126 - val_mse: 228.2126 - val_mae: 10.2168\n",
      "Epoch 19/250\n",
      "745/745 - 1s - loss: 219.0157 - mse: 219.0157 - mae: 9.9758 - val_loss: 229.3524 - val_mse: 229.3524 - val_mae: 10.4203\n",
      "Epoch 20/250\n",
      "745/745 - 1s - loss: 216.4437 - mse: 216.4437 - mae: 9.9103 - val_loss: 225.0759 - val_mse: 225.0759 - val_mae: 10.1568\n",
      "Epoch 21/250\n",
      "745/745 - 1s - loss: 214.9706 - mse: 214.9706 - mae: 9.8605 - val_loss: 224.5551 - val_mse: 224.5551 - val_mae: 10.0944\n",
      "Epoch 22/250\n",
      "745/745 - 1s - loss: 213.0590 - mse: 213.0590 - mae: 9.8263 - val_loss: 223.1377 - val_mse: 223.1377 - val_mae: 9.8818\n",
      "Epoch 23/250\n",
      "745/745 - 1s - loss: 211.2563 - mse: 211.2563 - mae: 9.7883 - val_loss: 219.9516 - val_mse: 219.9516 - val_mae: 9.9462\n",
      "Epoch 24/250\n",
      "745/745 - 1s - loss: 209.4898 - mse: 209.4898 - mae: 9.7412 - val_loss: 218.5666 - val_mse: 218.5666 - val_mae: 9.9301\n",
      "Epoch 25/250\n",
      "745/745 - 1s - loss: 208.1403 - mse: 208.1403 - mae: 9.7112 - val_loss: 216.7645 - val_mse: 216.7645 - val_mae: 9.9701\n",
      "Epoch 26/250\n",
      "745/745 - 1s - loss: 206.6645 - mse: 206.6645 - mae: 9.6819 - val_loss: 220.3897 - val_mse: 220.3897 - val_mae: 9.8075\n",
      "Epoch 27/250\n",
      "745/745 - 1s - loss: 205.1077 - mse: 205.1077 - mae: 9.6623 - val_loss: 213.7470 - val_mse: 213.7470 - val_mae: 9.7676\n",
      "Epoch 28/250\n",
      "745/745 - 1s - loss: 203.8810 - mse: 203.8810 - mae: 9.6365 - val_loss: 213.3086 - val_mse: 213.3086 - val_mae: 9.8340\n",
      "Epoch 29/250\n",
      "745/745 - 1s - loss: 202.1472 - mse: 202.1472 - mae: 9.6014 - val_loss: 214.5738 - val_mse: 214.5738 - val_mae: 9.8112\n",
      "Epoch 30/250\n",
      "745/745 - 1s - loss: 200.1305 - mse: 200.1305 - mae: 9.5405 - val_loss: 215.6790 - val_mse: 215.6790 - val_mae: 9.9232\n",
      "Epoch 31/250\n",
      "745/745 - 1s - loss: 199.6278 - mse: 199.6278 - mae: 9.5403 - val_loss: 217.7390 - val_mse: 217.7390 - val_mae: 9.6618\n",
      "Epoch 32/250\n",
      "745/745 - 1s - loss: 197.7418 - mse: 197.7418 - mae: 9.4650 - val_loss: 212.1747 - val_mse: 212.1747 - val_mae: 9.9304\n",
      "Epoch 33/250\n",
      "745/745 - 1s - loss: 196.9248 - mse: 196.9248 - mae: 9.4868 - val_loss: 216.0042 - val_mse: 216.0042 - val_mae: 10.1018\n",
      "Epoch 34/250\n",
      "745/745 - 1s - loss: 195.7992 - mse: 195.7992 - mae: 9.4324 - val_loss: 212.3432 - val_mse: 212.3432 - val_mae: 9.6164\n",
      "Epoch 35/250\n",
      "745/745 - 1s - loss: 195.2073 - mse: 195.2073 - mae: 9.4442 - val_loss: 206.3802 - val_mse: 206.3802 - val_mae: 9.6683\n",
      "Epoch 36/250\n",
      "745/745 - 1s - loss: 194.1178 - mse: 194.1178 - mae: 9.3893 - val_loss: 206.2915 - val_mse: 206.2915 - val_mae: 9.6383\n",
      "Epoch 37/250\n",
      "745/745 - 1s - loss: 192.3250 - mse: 192.3250 - mae: 9.3540 - val_loss: 209.1059 - val_mse: 209.1059 - val_mae: 9.9025\n",
      "Epoch 38/250\n",
      "745/745 - 1s - loss: 192.5554 - mse: 192.5554 - mae: 9.4003 - val_loss: 207.8974 - val_mse: 207.8974 - val_mae: 9.6280\n",
      "Epoch 39/250\n",
      "745/745 - 1s - loss: 191.2719 - mse: 191.2719 - mae: 9.3355 - val_loss: 207.2276 - val_mse: 207.2276 - val_mae: 9.6060\n",
      "Epoch 40/250\n",
      "745/745 - 1s - loss: 190.3107 - mse: 190.3107 - mae: 9.3243 - val_loss: 203.5036 - val_mse: 203.5036 - val_mae: 9.6309\n",
      "Epoch 41/250\n",
      "745/745 - 1s - loss: 190.0944 - mse: 190.0944 - mae: 9.2955 - val_loss: 202.9668 - val_mse: 202.9668 - val_mae: 9.6019\n",
      "Epoch 42/250\n",
      "745/745 - 1s - loss: 188.0397 - mse: 188.0397 - mae: 9.2624 - val_loss: 203.4949 - val_mse: 203.4949 - val_mae: 9.5600\n",
      "Epoch 43/250\n",
      "745/745 - 1s - loss: 188.3422 - mse: 188.3422 - mae: 9.2884 - val_loss: 202.3565 - val_mse: 202.3565 - val_mae: 9.5523\n",
      "Epoch 44/250\n",
      "745/745 - 1s - loss: 186.2134 - mse: 186.2134 - mae: 9.2184 - val_loss: 206.9909 - val_mse: 206.9909 - val_mae: 9.8452\n",
      "Epoch 45/250\n",
      "745/745 - 1s - loss: 186.4336 - mse: 186.4336 - mae: 9.2457 - val_loss: 200.7860 - val_mse: 200.7860 - val_mae: 9.4975\n",
      "Epoch 46/250\n",
      "745/745 - 1s - loss: 185.8553 - mse: 185.8553 - mae: 9.2197 - val_loss: 206.2593 - val_mse: 206.2593 - val_mae: 9.5054\n",
      "Epoch 47/250\n",
      "745/745 - 1s - loss: 185.0816 - mse: 185.0816 - mae: 9.1844 - val_loss: 200.7233 - val_mse: 200.7233 - val_mae: 9.4905\n",
      "Epoch 48/250\n",
      "745/745 - 1s - loss: 183.9539 - mse: 183.9539 - mae: 9.1804 - val_loss: 214.5884 - val_mse: 214.5884 - val_mae: 9.4795\n",
      "Epoch 49/250\n",
      "745/745 - 1s - loss: 184.2300 - mse: 184.2300 - mae: 9.1592 - val_loss: 202.7113 - val_mse: 202.7113 - val_mae: 9.4391\n",
      "Epoch 50/250\n",
      "745/745 - 1s - loss: 183.2874 - mse: 183.2874 - mae: 9.1609 - val_loss: 199.7440 - val_mse: 199.7440 - val_mae: 9.4926\n",
      "Epoch 51/250\n",
      "745/745 - 1s - loss: 182.4404 - mse: 182.4404 - mae: 9.1022 - val_loss: 202.4659 - val_mse: 202.4659 - val_mae: 9.7599\n",
      "Epoch 52/250\n",
      "745/745 - 1s - loss: 181.6351 - mse: 181.6351 - mae: 9.0813 - val_loss: 199.6041 - val_mse: 199.6041 - val_mae: 9.5388\n",
      "Epoch 53/250\n",
      "745/745 - 1s - loss: 180.4830 - mse: 180.4830 - mae: 9.0795 - val_loss: 199.6832 - val_mse: 199.6832 - val_mae: 9.5421\n",
      "Epoch 54/250\n",
      "745/745 - 1s - loss: 181.1209 - mse: 181.1209 - mae: 9.0802 - val_loss: 200.9351 - val_mse: 200.9351 - val_mae: 9.6454\n",
      "Epoch 55/250\n",
      "745/745 - 1s - loss: 180.0438 - mse: 180.0438 - mae: 9.0493 - val_loss: 200.4717 - val_mse: 200.4717 - val_mae: 9.5648\n",
      "Epoch 56/250\n",
      "745/745 - 1s - loss: 179.0443 - mse: 179.0443 - mae: 9.0163 - val_loss: 201.5066 - val_mse: 201.5066 - val_mae: 9.5396\n",
      "Epoch 57/250\n",
      "745/745 - 1s - loss: 178.9231 - mse: 178.9231 - mae: 9.0166 - val_loss: 197.7329 - val_mse: 197.7329 - val_mae: 9.4971\n",
      "Epoch 58/250\n",
      "745/745 - 1s - loss: 178.4790 - mse: 178.4790 - mae: 9.0107 - val_loss: 198.7426 - val_mse: 198.7426 - val_mae: 9.5307\n",
      "Epoch 59/250\n",
      "745/745 - 1s - loss: 178.5903 - mse: 178.5903 - mae: 9.0108 - val_loss: 200.7703 - val_mse: 200.7703 - val_mae: 9.6247\n",
      "Epoch 60/250\n",
      "745/745 - 1s - loss: 178.3684 - mse: 178.3684 - mae: 8.9999 - val_loss: 200.9559 - val_mse: 200.9559 - val_mae: 9.3695\n",
      "Epoch 61/250\n",
      "745/745 - 1s - loss: 177.6707 - mse: 177.6707 - mae: 8.9762 - val_loss: 195.6338 - val_mse: 195.6338 - val_mae: 9.4532\n",
      "Epoch 62/250\n",
      "745/745 - 1s - loss: 177.3895 - mse: 177.3895 - mae: 8.9895 - val_loss: 197.9911 - val_mse: 197.9911 - val_mae: 9.3746\n",
      "Epoch 63/250\n",
      "745/745 - 1s - loss: 176.6997 - mse: 176.6997 - mae: 8.9548 - val_loss: 196.7236 - val_mse: 196.7236 - val_mae: 9.2442\n",
      "Epoch 64/250\n",
      "745/745 - 1s - loss: 176.2361 - mse: 176.2361 - mae: 8.9492 - val_loss: 197.4726 - val_mse: 197.4726 - val_mae: 9.4340\n",
      "Epoch 65/250\n",
      "745/745 - 1s - loss: 175.4756 - mse: 175.4756 - mae: 8.9135 - val_loss: 198.6628 - val_mse: 198.6628 - val_mae: 9.3821\n",
      "Epoch 66/250\n",
      "745/745 - 1s - loss: 175.6209 - mse: 175.6209 - mae: 8.9039 - val_loss: 195.7331 - val_mse: 195.7331 - val_mae: 9.4164\n",
      "Epoch 67/250\n",
      "745/745 - 1s - loss: 176.3190 - mse: 176.3190 - mae: 8.9784 - val_loss: 194.4701 - val_mse: 194.4701 - val_mae: 9.3337\n",
      "Epoch 68/250\n",
      "745/745 - 1s - loss: 174.9503 - mse: 174.9503 - mae: 8.9222 - val_loss: 196.3282 - val_mse: 196.3282 - val_mae: 9.4168\n",
      "Epoch 69/250\n",
      "745/745 - 1s - loss: 174.3833 - mse: 174.3833 - mae: 8.8910 - val_loss: 192.7557 - val_mse: 192.7557 - val_mae: 9.2776\n",
      "Epoch 70/250\n",
      "745/745 - 1s - loss: 173.7138 - mse: 173.7138 - mae: 8.8888 - val_loss: 202.1972 - val_mse: 202.1972 - val_mae: 9.2872\n",
      "Epoch 71/250\n",
      "745/745 - 1s - loss: 173.2491 - mse: 173.2491 - mae: 8.8783 - val_loss: 199.0238 - val_mse: 199.0238 - val_mae: 9.3561\n",
      "Epoch 72/250\n",
      "745/745 - 1s - loss: 173.4729 - mse: 173.4729 - mae: 8.8835 - val_loss: 197.3003 - val_mse: 197.3003 - val_mae: 9.3272\n",
      "Epoch 73/250\n",
      "745/745 - 1s - loss: 172.9049 - mse: 172.9049 - mae: 8.8600 - val_loss: 194.6306 - val_mse: 194.6306 - val_mae: 9.3112\n",
      "Epoch 74/250\n",
      "745/745 - 1s - loss: 172.5317 - mse: 172.5317 - mae: 8.8338 - val_loss: 198.3236 - val_mse: 198.3236 - val_mae: 9.5889\n",
      "Epoch 75/250\n",
      "745/745 - 1s - loss: 171.8306 - mse: 171.8306 - mae: 8.8434 - val_loss: 197.3972 - val_mse: 197.3972 - val_mae: 9.2075\n",
      "Epoch 76/250\n",
      "745/745 - 1s - loss: 171.4635 - mse: 171.4635 - mae: 8.8336 - val_loss: 203.4035 - val_mse: 203.4035 - val_mae: 9.2743\n",
      "Epoch 77/250\n",
      "745/745 - 1s - loss: 170.8657 - mse: 170.8657 - mae: 8.7958 - val_loss: 201.5837 - val_mse: 201.5837 - val_mae: 9.7301\n",
      "Epoch 78/250\n",
      "745/745 - 1s - loss: 171.6060 - mse: 171.6060 - mae: 8.8304 - val_loss: 194.0823 - val_mse: 194.0823 - val_mae: 9.4059\n",
      "Epoch 79/250\n",
      "745/745 - 1s - loss: 170.2136 - mse: 170.2136 - mae: 8.7846 - val_loss: 192.1674 - val_mse: 192.1674 - val_mae: 9.2223\n",
      "Epoch 80/250\n",
      "745/745 - 1s - loss: 170.0048 - mse: 170.0048 - mae: 8.7721 - val_loss: 198.6460 - val_mse: 198.6460 - val_mae: 9.4613\n",
      "Epoch 81/250\n",
      "745/745 - 1s - loss: 170.0500 - mse: 170.0500 - mae: 8.7870 - val_loss: 194.9678 - val_mse: 194.9678 - val_mae: 9.3201\n",
      "Epoch 82/250\n",
      "745/745 - 1s - loss: 169.8975 - mse: 169.8975 - mae: 8.7767 - val_loss: 202.0582 - val_mse: 202.0582 - val_mae: 9.3173\n",
      "Epoch 83/250\n",
      "745/745 - 1s - loss: 168.9289 - mse: 168.9289 - mae: 8.7370 - val_loss: 193.5747 - val_mse: 193.5747 - val_mae: 9.4383\n",
      "Epoch 84/250\n",
      "745/745 - 1s - loss: 168.7986 - mse: 168.7986 - mae: 8.7401 - val_loss: 190.9308 - val_mse: 190.9308 - val_mae: 9.2211\n",
      "Epoch 85/250\n",
      "745/745 - 1s - loss: 168.6107 - mse: 168.6107 - mae: 8.7412 - val_loss: 194.8374 - val_mse: 194.8374 - val_mae: 9.1278\n",
      "Epoch 86/250\n",
      "745/745 - 1s - loss: 168.1552 - mse: 168.1552 - mae: 8.7234 - val_loss: 192.3417 - val_mse: 192.3417 - val_mae: 9.2910\n",
      "Epoch 87/250\n",
      "745/745 - 1s - loss: 167.5764 - mse: 167.5764 - mae: 8.6760 - val_loss: 194.5678 - val_mse: 194.5678 - val_mae: 9.2275\n",
      "Epoch 88/250\n",
      "745/745 - 1s - loss: 167.8761 - mse: 167.8761 - mae: 8.6957 - val_loss: 191.4801 - val_mse: 191.4801 - val_mae: 9.2740\n",
      "Epoch 89/250\n",
      "745/745 - 1s - loss: 167.3513 - mse: 167.3513 - mae: 8.7170 - val_loss: 194.3819 - val_mse: 194.3819 - val_mae: 9.4000\n",
      "Epoch 90/250\n",
      "745/745 - 1s - loss: 166.5893 - mse: 166.5893 - mae: 8.6832 - val_loss: 191.5197 - val_mse: 191.5197 - val_mae: 9.1311\n",
      "Epoch 91/250\n",
      "745/745 - 1s - loss: 165.7926 - mse: 165.7926 - mae: 8.6621 - val_loss: 191.0548 - val_mse: 191.0548 - val_mae: 9.2694\n",
      "Epoch 92/250\n",
      "745/745 - 1s - loss: 165.4188 - mse: 165.4188 - mae: 8.6342 - val_loss: 193.4061 - val_mse: 193.4061 - val_mae: 9.3655\n",
      "Epoch 93/250\n",
      "745/745 - 1s - loss: 165.7343 - mse: 165.7343 - mae: 8.6519 - val_loss: 192.8418 - val_mse: 192.8418 - val_mae: 9.3328\n",
      "Epoch 94/250\n",
      "745/745 - 1s - loss: 165.8833 - mse: 165.8833 - mae: 8.6378 - val_loss: 188.8167 - val_mse: 188.8167 - val_mae: 9.1261\n",
      "Epoch 95/250\n",
      "745/745 - 1s - loss: 165.0709 - mse: 165.0709 - mae: 8.6267 - val_loss: 187.2999 - val_mse: 187.2999 - val_mae: 9.2475\n",
      "Epoch 96/250\n",
      "745/745 - 1s - loss: 165.3633 - mse: 165.3633 - mae: 8.6283 - val_loss: 189.8154 - val_mse: 189.8154 - val_mae: 9.0481\n",
      "Epoch 97/250\n",
      "745/745 - 1s - loss: 164.0269 - mse: 164.0269 - mae: 8.5748 - val_loss: 188.7065 - val_mse: 188.7065 - val_mae: 9.2369\n",
      "Epoch 98/250\n",
      "745/745 - 1s - loss: 164.4662 - mse: 164.4662 - mae: 8.6150 - val_loss: 190.1415 - val_mse: 190.1415 - val_mae: 9.3416\n",
      "Epoch 99/250\n",
      "745/745 - 1s - loss: 164.2573 - mse: 164.2573 - mae: 8.5935 - val_loss: 186.4767 - val_mse: 186.4767 - val_mae: 9.0363\n",
      "Epoch 100/250\n",
      "745/745 - 1s - loss: 163.2981 - mse: 163.2981 - mae: 8.5825 - val_loss: 189.2071 - val_mse: 189.2071 - val_mae: 9.2592\n",
      "Epoch 101/250\n",
      "745/745 - 1s - loss: 163.9333 - mse: 163.9333 - mae: 8.6124 - val_loss: 192.4658 - val_mse: 192.4658 - val_mae: 9.2875\n",
      "Epoch 102/250\n",
      "745/745 - 1s - loss: 164.5226 - mse: 164.5226 - mae: 8.6069 - val_loss: 191.9997 - val_mse: 191.9997 - val_mae: 9.1307\n",
      "Epoch 103/250\n",
      "745/745 - 1s - loss: 163.5837 - mse: 163.5837 - mae: 8.5916 - val_loss: 190.8526 - val_mse: 190.8526 - val_mae: 9.1210\n",
      "Epoch 104/250\n",
      "745/745 - 1s - loss: 162.9548 - mse: 162.9548 - mae: 8.5703 - val_loss: 188.4239 - val_mse: 188.4239 - val_mae: 9.1544\n",
      "Epoch 105/250\n",
      "745/745 - 1s - loss: 163.2742 - mse: 163.2742 - mae: 8.5772 - val_loss: 188.0655 - val_mse: 188.0655 - val_mae: 9.0099\n",
      "Epoch 106/250\n",
      "745/745 - 1s - loss: 162.9175 - mse: 162.9175 - mae: 8.5662 - val_loss: 186.1475 - val_mse: 186.1475 - val_mae: 9.1039\n",
      "Epoch 107/250\n",
      "745/745 - 1s - loss: 162.9938 - mse: 162.9938 - mae: 8.5849 - val_loss: 189.0999 - val_mse: 189.0999 - val_mae: 9.2357\n",
      "Epoch 108/250\n",
      "745/745 - 1s - loss: 161.8531 - mse: 161.8531 - mae: 8.5293 - val_loss: 187.3295 - val_mse: 187.3295 - val_mae: 9.1389\n",
      "Epoch 109/250\n",
      "745/745 - 1s - loss: 162.2365 - mse: 162.2365 - mae: 8.5539 - val_loss: 190.9900 - val_mse: 190.9900 - val_mae: 9.3371\n",
      "Epoch 110/250\n",
      "745/745 - 1s - loss: 162.0518 - mse: 162.0518 - mae: 8.5283 - val_loss: 187.3286 - val_mse: 187.3286 - val_mae: 9.1521\n",
      "Epoch 111/250\n",
      "745/745 - 1s - loss: 160.9670 - mse: 160.9670 - mae: 8.5065 - val_loss: 187.8026 - val_mse: 187.8026 - val_mae: 9.0564\n",
      "Epoch 112/250\n",
      "745/745 - 1s - loss: 161.4215 - mse: 161.4215 - mae: 8.5008 - val_loss: 193.4940 - val_mse: 193.4940 - val_mae: 9.4471\n",
      "Epoch 113/250\n",
      "745/745 - 1s - loss: 161.5781 - mse: 161.5781 - mae: 8.5286 - val_loss: 185.9453 - val_mse: 185.9453 - val_mae: 9.0967\n",
      "Epoch 114/250\n",
      "745/745 - 1s - loss: 162.0487 - mse: 162.0487 - mae: 8.5391 - val_loss: 187.8055 - val_mse: 187.8055 - val_mae: 9.1869\n",
      "Epoch 115/250\n",
      "745/745 - 1s - loss: 161.4198 - mse: 161.4198 - mae: 8.5400 - val_loss: 188.0412 - val_mse: 188.0412 - val_mae: 9.0423\n",
      "Epoch 116/250\n",
      "745/745 - 1s - loss: 160.5817 - mse: 160.5817 - mae: 8.4897 - val_loss: 185.0593 - val_mse: 185.0593 - val_mae: 8.9821\n",
      "Epoch 117/250\n",
      "745/745 - 1s - loss: 160.4465 - mse: 160.4465 - mae: 8.4846 - val_loss: 185.2092 - val_mse: 185.2092 - val_mae: 9.0875\n",
      "Epoch 118/250\n",
      "745/745 - 1s - loss: 160.4748 - mse: 160.4748 - mae: 8.4933 - val_loss: 185.3284 - val_mse: 185.3284 - val_mae: 9.0130\n",
      "Epoch 119/250\n",
      "745/745 - 1s - loss: 159.5645 - mse: 159.5645 - mae: 8.4656 - val_loss: 188.0709 - val_mse: 188.0709 - val_mae: 9.2051\n",
      "Epoch 120/250\n",
      "745/745 - 1s - loss: 160.9236 - mse: 160.9236 - mae: 8.5089 - val_loss: 185.4220 - val_mse: 185.4220 - val_mae: 8.9506\n",
      "Epoch 121/250\n",
      "745/745 - 1s - loss: 159.8809 - mse: 159.8809 - mae: 8.4912 - val_loss: 188.3967 - val_mse: 188.3967 - val_mae: 9.1856\n",
      "Epoch 122/250\n",
      "745/745 - 1s - loss: 159.6761 - mse: 159.6761 - mae: 8.4707 - val_loss: 186.0463 - val_mse: 186.0463 - val_mae: 8.9661\n",
      "Epoch 123/250\n",
      "745/745 - 1s - loss: 159.0482 - mse: 159.0482 - mae: 8.4388 - val_loss: 188.1439 - val_mse: 188.1439 - val_mae: 9.0379\n",
      "Epoch 124/250\n",
      "745/745 - 1s - loss: 159.1045 - mse: 159.1045 - mae: 8.4584 - val_loss: 186.0929 - val_mse: 186.0929 - val_mae: 9.1299\n",
      "Epoch 125/250\n",
      "745/745 - 1s - loss: 159.5618 - mse: 159.5618 - mae: 8.4605 - val_loss: 188.8838 - val_mse: 188.8838 - val_mae: 9.0327\n",
      "Epoch 126/250\n",
      "745/745 - 1s - loss: 158.9037 - mse: 158.9037 - mae: 8.4565 - val_loss: 188.0840 - val_mse: 188.0840 - val_mae: 9.1951\n",
      "Epoch 127/250\n",
      "745/745 - 1s - loss: 158.3837 - mse: 158.3837 - mae: 8.4329 - val_loss: 184.9529 - val_mse: 184.9529 - val_mae: 9.1785\n",
      "Epoch 128/250\n",
      "745/745 - 1s - loss: 158.6160 - mse: 158.6160 - mae: 8.4491 - val_loss: 184.4018 - val_mse: 184.4018 - val_mae: 9.1370\n",
      "Epoch 129/250\n",
      "745/745 - 1s - loss: 157.9646 - mse: 157.9646 - mae: 8.4147 - val_loss: 185.5586 - val_mse: 185.5586 - val_mae: 9.1196\n",
      "Epoch 130/250\n",
      "745/745 - 1s - loss: 158.8385 - mse: 158.8385 - mae: 8.4427 - val_loss: 188.0334 - val_mse: 188.0334 - val_mae: 8.9645\n",
      "Epoch 131/250\n",
      "745/745 - 1s - loss: 156.7057 - mse: 156.7057 - mae: 8.4025 - val_loss: 189.9591 - val_mse: 189.9591 - val_mae: 9.3497\n",
      "Epoch 132/250\n",
      "745/745 - 1s - loss: 157.6470 - mse: 157.6470 - mae: 8.4210 - val_loss: 182.6936 - val_mse: 182.6936 - val_mae: 8.9530\n",
      "Epoch 133/250\n",
      "745/745 - 1s - loss: 157.8416 - mse: 157.8416 - mae: 8.4077 - val_loss: 186.8851 - val_mse: 186.8851 - val_mae: 8.8860\n",
      "Epoch 134/250\n",
      "745/745 - 1s - loss: 157.4485 - mse: 157.4485 - mae: 8.4221 - val_loss: 183.9917 - val_mse: 183.9917 - val_mae: 9.0218\n",
      "Epoch 135/250\n",
      "745/745 - 1s - loss: 157.3931 - mse: 157.3931 - mae: 8.4122 - val_loss: 182.6498 - val_mse: 182.6498 - val_mae: 8.9602\n",
      "Epoch 136/250\n",
      "745/745 - 1s - loss: 156.8381 - mse: 156.8381 - mae: 8.3899 - val_loss: 183.3283 - val_mse: 183.3283 - val_mae: 9.0381\n",
      "Epoch 137/250\n",
      "745/745 - 1s - loss: 156.9485 - mse: 156.9485 - mae: 8.3973 - val_loss: 199.0355 - val_mse: 199.0355 - val_mae: 9.6529\n",
      "Epoch 138/250\n",
      "745/745 - 1s - loss: 156.6242 - mse: 156.6242 - mae: 8.3993 - val_loss: 184.8170 - val_mse: 184.8170 - val_mae: 9.1882\n",
      "Epoch 139/250\n",
      "745/745 - 1s - loss: 156.5929 - mse: 156.5929 - mae: 8.3757 - val_loss: 182.0277 - val_mse: 182.0277 - val_mae: 9.0055\n",
      "Epoch 140/250\n",
      "745/745 - 1s - loss: 156.1334 - mse: 156.1334 - mae: 8.3736 - val_loss: 184.3263 - val_mse: 184.3263 - val_mae: 8.8292\n",
      "Epoch 141/250\n",
      "745/745 - 1s - loss: 156.1749 - mse: 156.1749 - mae: 8.3576 - val_loss: 184.0798 - val_mse: 184.0798 - val_mae: 9.0439\n",
      "Epoch 142/250\n",
      "745/745 - 1s - loss: 155.7990 - mse: 155.7990 - mae: 8.3468 - val_loss: 185.8642 - val_mse: 185.8642 - val_mae: 9.2050\n",
      "Epoch 143/250\n",
      "745/745 - 1s - loss: 156.3557 - mse: 156.3557 - mae: 8.3752 - val_loss: 183.3617 - val_mse: 183.3617 - val_mae: 8.9485\n",
      "Epoch 144/250\n",
      "745/745 - 1s - loss: 154.8994 - mse: 154.8994 - mae: 8.3389 - val_loss: 187.7294 - val_mse: 187.7294 - val_mae: 9.1788\n",
      "Epoch 145/250\n",
      "745/745 - 1s - loss: 155.3368 - mse: 155.3368 - mae: 8.3494 - val_loss: 189.7206 - val_mse: 189.7206 - val_mae: 8.9298\n",
      "Epoch 146/250\n",
      "745/745 - 1s - loss: 155.5684 - mse: 155.5684 - mae: 8.3694 - val_loss: 184.6762 - val_mse: 184.6762 - val_mae: 8.9335\n",
      "Epoch 147/250\n",
      "745/745 - 1s - loss: 154.9808 - mse: 154.9808 - mae: 8.3275 - val_loss: 184.3427 - val_mse: 184.3427 - val_mae: 8.8065\n",
      "Epoch 148/250\n",
      "745/745 - 1s - loss: 154.5446 - mse: 154.5446 - mae: 8.3329 - val_loss: 183.6152 - val_mse: 183.6152 - val_mae: 8.8703\n",
      "Epoch 149/250\n",
      "745/745 - 1s - loss: 154.5895 - mse: 154.5895 - mae: 8.3274 - val_loss: 183.4540 - val_mse: 183.4540 - val_mae: 8.8764\n",
      "Epoch 150/250\n",
      "745/745 - 1s - loss: 154.2263 - mse: 154.2263 - mae: 8.2993 - val_loss: 179.6152 - val_mse: 179.6152 - val_mae: 8.8880\n",
      "Epoch 151/250\n",
      "745/745 - 1s - loss: 154.3877 - mse: 154.3877 - mae: 8.3397 - val_loss: 181.5457 - val_mse: 181.5457 - val_mae: 8.9982\n",
      "Epoch 152/250\n",
      "745/745 - 1s - loss: 154.0098 - mse: 154.0098 - mae: 8.2828 - val_loss: 187.3114 - val_mse: 187.3114 - val_mae: 9.3169\n",
      "Epoch 153/250\n",
      "745/745 - 1s - loss: 153.8469 - mse: 153.8469 - mae: 8.2953 - val_loss: 184.4310 - val_mse: 184.4310 - val_mae: 9.1114\n",
      "Epoch 154/250\n",
      "745/745 - 1s - loss: 153.9414 - mse: 153.9414 - mae: 8.3058 - val_loss: 180.1824 - val_mse: 180.1824 - val_mae: 8.9544\n",
      "Epoch 155/250\n",
      "745/745 - 1s - loss: 153.8932 - mse: 153.8932 - mae: 8.3077 - val_loss: 181.9540 - val_mse: 181.9540 - val_mae: 8.9073\n",
      "Epoch 156/250\n",
      "745/745 - 1s - loss: 153.0965 - mse: 153.0965 - mae: 8.2558 - val_loss: 186.9731 - val_mse: 186.9731 - val_mae: 9.2348\n",
      "Epoch 157/250\n",
      "745/745 - 1s - loss: 154.2519 - mse: 154.2519 - mae: 8.3006 - val_loss: 183.9155 - val_mse: 183.9155 - val_mae: 8.9351\n",
      "Epoch 158/250\n",
      "745/745 - 1s - loss: 152.1792 - mse: 152.1792 - mae: 8.2625 - val_loss: 183.0896 - val_mse: 183.0896 - val_mae: 8.8924\n",
      "Epoch 159/250\n",
      "745/745 - 1s - loss: 153.6570 - mse: 153.6570 - mae: 8.2959 - val_loss: 183.6617 - val_mse: 183.6617 - val_mae: 9.0405\n",
      "Epoch 160/250\n",
      "745/745 - 1s - loss: 152.6316 - mse: 152.6316 - mae: 8.2595 - val_loss: 183.3522 - val_mse: 183.3522 - val_mae: 9.1679\n",
      "Epoch 161/250\n",
      "745/745 - 1s - loss: 152.5432 - mse: 152.5432 - mae: 8.2571 - val_loss: 183.5804 - val_mse: 183.5804 - val_mae: 8.8557\n",
      "Epoch 162/250\n",
      "745/745 - 1s - loss: 152.2130 - mse: 152.2130 - mae: 8.2400 - val_loss: 184.3387 - val_mse: 184.3387 - val_mae: 9.0653\n",
      "Epoch 163/250\n",
      "745/745 - 1s - loss: 152.3727 - mse: 152.3727 - mae: 8.2416 - val_loss: 178.7802 - val_mse: 178.7802 - val_mae: 8.9249\n",
      "Epoch 164/250\n",
      "745/745 - 1s - loss: 152.4304 - mse: 152.4304 - mae: 8.2544 - val_loss: 179.2329 - val_mse: 179.2329 - val_mae: 8.7939\n",
      "Epoch 165/250\n",
      "745/745 - 1s - loss: 152.6340 - mse: 152.6340 - mae: 8.2739 - val_loss: 188.6459 - val_mse: 188.6459 - val_mae: 8.8801\n",
      "Epoch 166/250\n",
      "745/745 - 1s - loss: 152.4428 - mse: 152.4428 - mae: 8.2443 - val_loss: 180.1008 - val_mse: 180.1008 - val_mae: 8.9228\n",
      "Epoch 167/250\n",
      "745/745 - 1s - loss: 151.3257 - mse: 151.3257 - mae: 8.2254 - val_loss: 188.7048 - val_mse: 188.7048 - val_mae: 9.2606\n",
      "Epoch 168/250\n",
      "745/745 - 1s - loss: 151.6255 - mse: 151.6255 - mae: 8.2184 - val_loss: 189.4342 - val_mse: 189.4342 - val_mae: 9.2159\n",
      "Epoch 169/250\n",
      "745/745 - 1s - loss: 151.3897 - mse: 151.3897 - mae: 8.2258 - val_loss: 180.8757 - val_mse: 180.8757 - val_mae: 8.9579\n",
      "Epoch 170/250\n",
      "745/745 - 1s - loss: 151.3524 - mse: 151.3524 - mae: 8.2108 - val_loss: 188.2054 - val_mse: 188.2054 - val_mae: 8.7894\n",
      "Epoch 171/250\n",
      "745/745 - 1s - loss: 150.7752 - mse: 150.7752 - mae: 8.2020 - val_loss: 183.8151 - val_mse: 183.8151 - val_mae: 9.1374\n",
      "Epoch 172/250\n",
      "745/745 - 1s - loss: 150.6532 - mse: 150.6532 - mae: 8.2066 - val_loss: 180.5575 - val_mse: 180.5575 - val_mae: 8.8073\n",
      "Epoch 173/250\n",
      "745/745 - 1s - loss: 150.8635 - mse: 150.8635 - mae: 8.1977 - val_loss: 182.8121 - val_mse: 182.8121 - val_mae: 8.7468\n",
      "Epoch 174/250\n",
      "745/745 - 1s - loss: 151.2275 - mse: 151.2275 - mae: 8.2176 - val_loss: 178.2303 - val_mse: 178.2303 - val_mae: 8.7536\n",
      "Epoch 175/250\n",
      "745/745 - 1s - loss: 150.7955 - mse: 150.7955 - mae: 8.1806 - val_loss: 182.2367 - val_mse: 182.2367 - val_mae: 8.9974\n",
      "Epoch 176/250\n",
      "745/745 - 1s - loss: 150.6837 - mse: 150.6837 - mae: 8.1782 - val_loss: 180.3412 - val_mse: 180.3412 - val_mae: 8.7508\n",
      "Epoch 177/250\n",
      "745/745 - 1s - loss: 150.3483 - mse: 150.3483 - mae: 8.1749 - val_loss: 184.0307 - val_mse: 184.0307 - val_mae: 8.9199\n",
      "Epoch 178/250\n",
      "745/745 - 1s - loss: 150.4052 - mse: 150.4052 - mae: 8.1919 - val_loss: 186.5054 - val_mse: 186.5054 - val_mae: 9.2803\n",
      "Epoch 179/250\n",
      "745/745 - 1s - loss: 149.9681 - mse: 149.9681 - mae: 8.1698 - val_loss: 182.8899 - val_mse: 182.8899 - val_mae: 8.9184\n",
      "Epoch 180/250\n",
      "745/745 - 1s - loss: 150.2156 - mse: 150.2156 - mae: 8.1767 - val_loss: 187.1971 - val_mse: 187.1971 - val_mae: 9.1261\n",
      "Epoch 181/250\n",
      "745/745 - 1s - loss: 150.0800 - mse: 150.0800 - mae: 8.1659 - val_loss: 178.4368 - val_mse: 178.4368 - val_mae: 8.7357\n",
      "Epoch 182/250\n",
      "745/745 - 1s - loss: 150.3015 - mse: 150.3015 - mae: 8.1627 - val_loss: 178.3578 - val_mse: 178.3578 - val_mae: 8.7782\n",
      "Epoch 183/250\n",
      "745/745 - 1s - loss: 149.0398 - mse: 149.0398 - mae: 8.1357 - val_loss: 176.8948 - val_mse: 176.8948 - val_mae: 8.7755\n",
      "Epoch 184/250\n",
      "745/745 - 1s - loss: 149.0470 - mse: 149.0470 - mae: 8.1150 - val_loss: 179.1164 - val_mse: 179.1164 - val_mae: 8.7342\n",
      "Epoch 185/250\n",
      "745/745 - 1s - loss: 149.5274 - mse: 149.5274 - mae: 8.1618 - val_loss: 181.2787 - val_mse: 181.2787 - val_mae: 8.7634\n",
      "Epoch 186/250\n",
      "745/745 - 1s - loss: 148.9434 - mse: 148.9434 - mae: 8.0974 - val_loss: 184.6227 - val_mse: 184.6227 - val_mae: 9.0234\n",
      "Epoch 187/250\n",
      "745/745 - 1s - loss: 149.5560 - mse: 149.5560 - mae: 8.1600 - val_loss: 179.3147 - val_mse: 179.3147 - val_mae: 8.9359\n",
      "Epoch 188/250\n",
      "745/745 - 1s - loss: 148.5835 - mse: 148.5835 - mae: 8.1122 - val_loss: 182.8709 - val_mse: 182.8709 - val_mae: 8.7928\n",
      "Epoch 189/250\n",
      "745/745 - 1s - loss: 148.8827 - mse: 148.8827 - mae: 8.1433 - val_loss: 176.2338 - val_mse: 176.2338 - val_mae: 8.7692\n",
      "Epoch 190/250\n",
      "745/745 - 1s - loss: 148.5390 - mse: 148.5390 - mae: 8.1204 - val_loss: 180.8373 - val_mse: 180.8373 - val_mae: 8.8239\n",
      "Epoch 191/250\n",
      "745/745 - 1s - loss: 148.1681 - mse: 148.1681 - mae: 8.1140 - val_loss: 184.7104 - val_mse: 184.7104 - val_mae: 9.0041\n",
      "Epoch 192/250\n",
      "745/745 - 1s - loss: 147.8389 - mse: 147.8389 - mae: 8.0736 - val_loss: 183.2126 - val_mse: 183.2126 - val_mae: 8.8987\n",
      "Epoch 193/250\n",
      "745/745 - 1s - loss: 148.2075 - mse: 148.2075 - mae: 8.0998 - val_loss: 184.3786 - val_mse: 184.3786 - val_mae: 8.9394\n",
      "Epoch 194/250\n",
      "745/745 - 1s - loss: 148.0040 - mse: 148.0040 - mae: 8.0985 - val_loss: 186.2750 - val_mse: 186.2750 - val_mae: 9.2056\n",
      "Epoch 195/250\n",
      "745/745 - 1s - loss: 147.3455 - mse: 147.3455 - mae: 8.0960 - val_loss: 176.7495 - val_mse: 176.7495 - val_mae: 8.6680\n",
      "Epoch 196/250\n",
      "745/745 - 1s - loss: 147.6994 - mse: 147.6994 - mae: 8.0929 - val_loss: 181.3706 - val_mse: 181.3706 - val_mae: 8.7571\n",
      "Epoch 197/250\n",
      "745/745 - 1s - loss: 148.5844 - mse: 148.5844 - mae: 8.1105 - val_loss: 180.1132 - val_mse: 180.1132 - val_mae: 8.8435\n",
      "Epoch 198/250\n",
      "745/745 - 1s - loss: 148.4272 - mse: 148.4272 - mae: 8.1201 - val_loss: 180.2073 - val_mse: 180.2073 - val_mae: 8.8916\n",
      "Epoch 199/250\n",
      "745/745 - 1s - loss: 146.9239 - mse: 146.9239 - mae: 8.0589 - val_loss: 176.9339 - val_mse: 176.9339 - val_mae: 8.7637\n",
      "Epoch 200/250\n",
      "745/745 - 1s - loss: 147.1792 - mse: 147.1792 - mae: 8.0501 - val_loss: 183.5805 - val_mse: 183.5805 - val_mae: 8.7339\n",
      "Epoch 201/250\n",
      "745/745 - 1s - loss: 147.3965 - mse: 147.3965 - mae: 8.0725 - val_loss: 180.3906 - val_mse: 180.3906 - val_mae: 8.6961\n",
      "Epoch 202/250\n",
      "745/745 - 1s - loss: 146.7953 - mse: 146.7953 - mae: 8.0525 - val_loss: 181.0086 - val_mse: 181.0086 - val_mae: 8.9620\n",
      "Epoch 203/250\n",
      "745/745 - 1s - loss: 147.1098 - mse: 147.1098 - mae: 8.0888 - val_loss: 181.9402 - val_mse: 181.9402 - val_mae: 8.6397\n",
      "Epoch 204/250\n",
      "745/745 - 1s - loss: 147.4147 - mse: 147.4147 - mae: 8.0599 - val_loss: 176.1382 - val_mse: 176.1382 - val_mae: 8.8075\n",
      "Epoch 205/250\n",
      "745/745 - 1s - loss: 146.2864 - mse: 146.2864 - mae: 8.0259 - val_loss: 182.5541 - val_mse: 182.5541 - val_mae: 9.0460\n",
      "Epoch 206/250\n",
      "745/745 - 1s - loss: 146.1659 - mse: 146.1659 - mae: 8.0474 - val_loss: 178.8662 - val_mse: 178.8662 - val_mae: 8.8220\n",
      "Epoch 207/250\n",
      "745/745 - 1s - loss: 147.0157 - mse: 147.0157 - mae: 8.0620 - val_loss: 176.5156 - val_mse: 176.5156 - val_mae: 8.6617\n",
      "Epoch 208/250\n",
      "745/745 - 1s - loss: 145.8400 - mse: 145.8400 - mae: 8.0255 - val_loss: 184.2160 - val_mse: 184.2160 - val_mae: 9.0787\n",
      "Epoch 209/250\n",
      "745/745 - 1s - loss: 145.4981 - mse: 145.4981 - mae: 8.0186 - val_loss: 176.4147 - val_mse: 176.4147 - val_mae: 8.7372\n",
      "Epoch 210/250\n",
      "745/745 - 1s - loss: 145.7487 - mse: 145.7487 - mae: 8.0049 - val_loss: 182.3063 - val_mse: 182.3063 - val_mae: 8.7005\n",
      "Epoch 211/250\n",
      "745/745 - 1s - loss: 145.9333 - mse: 145.9333 - mae: 8.0410 - val_loss: 177.2251 - val_mse: 177.2251 - val_mae: 8.6853\n",
      "Epoch 212/250\n",
      "745/745 - 1s - loss: 145.7882 - mse: 145.7882 - mae: 8.0255 - val_loss: 180.4629 - val_mse: 180.4629 - val_mae: 8.8866\n",
      "Epoch 213/250\n",
      "745/745 - 1s - loss: 146.2075 - mse: 146.2075 - mae: 7.9992 - val_loss: 178.5953 - val_mse: 178.5953 - val_mae: 8.8901\n",
      "Epoch 214/250\n",
      "745/745 - 1s - loss: 145.7602 - mse: 145.7602 - mae: 8.0239 - val_loss: 179.0284 - val_mse: 179.0284 - val_mae: 8.8506\n",
      "Epoch 215/250\n",
      "745/745 - 1s - loss: 146.2081 - mse: 146.2081 - mae: 8.0287 - val_loss: 177.2822 - val_mse: 177.2822 - val_mae: 8.7189\n",
      "Epoch 216/250\n",
      "745/745 - 1s - loss: 146.1317 - mse: 146.1317 - mae: 8.0316 - val_loss: 180.9115 - val_mse: 180.9115 - val_mae: 8.6479\n",
      "Epoch 217/250\n",
      "745/745 - 1s - loss: 146.2063 - mse: 146.2063 - mae: 8.0284 - val_loss: 181.9343 - val_mse: 181.9343 - val_mae: 8.7987\n",
      "Epoch 218/250\n",
      "745/745 - 1s - loss: 145.1986 - mse: 145.1986 - mae: 8.0134 - val_loss: 176.3206 - val_mse: 176.3206 - val_mae: 8.6567\n",
      "Epoch 219/250\n",
      "745/745 - 1s - loss: 146.0362 - mse: 146.0362 - mae: 8.0354 - val_loss: 177.6797 - val_mse: 177.6797 - val_mae: 8.7794\n",
      "Epoch 220/250\n",
      "745/745 - 1s - loss: 144.7630 - mse: 144.7630 - mae: 7.9824 - val_loss: 184.2129 - val_mse: 184.2129 - val_mae: 9.1214\n",
      "Epoch 221/250\n",
      "745/745 - 1s - loss: 145.2043 - mse: 145.2043 - mae: 8.0111 - val_loss: 176.7980 - val_mse: 176.7980 - val_mae: 8.8068\n",
      "Epoch 222/250\n",
      "745/745 - 1s - loss: 145.3552 - mse: 145.3552 - mae: 8.0001 - val_loss: 178.9009 - val_mse: 178.9009 - val_mae: 8.6684\n",
      "Epoch 223/250\n",
      "745/745 - 1s - loss: 144.5068 - mse: 144.5068 - mae: 7.9695 - val_loss: 178.4908 - val_mse: 178.4908 - val_mae: 8.6227\n",
      "Epoch 224/250\n",
      "745/745 - 1s - loss: 144.3300 - mse: 144.3300 - mae: 7.9757 - val_loss: 180.2237 - val_mse: 180.2237 - val_mae: 8.7939\n",
      "Epoch 225/250\n",
      "745/745 - 1s - loss: 144.8759 - mse: 144.8759 - mae: 7.9897 - val_loss: 179.1373 - val_mse: 179.1373 - val_mae: 8.8270\n",
      "Epoch 226/250\n",
      "745/745 - 1s - loss: 144.7497 - mse: 144.7497 - mae: 7.9902 - val_loss: 180.4874 - val_mse: 180.4874 - val_mae: 8.6234\n",
      "Epoch 227/250\n",
      "745/745 - 1s - loss: 143.7211 - mse: 143.7211 - mae: 7.9685 - val_loss: 180.8278 - val_mse: 180.8278 - val_mae: 8.7968\n",
      "Epoch 228/250\n",
      "745/745 - 1s - loss: 145.1348 - mse: 145.1348 - mae: 7.9924 - val_loss: 178.8590 - val_mse: 178.8590 - val_mae: 8.8571\n",
      "Epoch 229/250\n",
      "745/745 - 1s - loss: 144.2961 - mse: 144.2961 - mae: 7.9821 - val_loss: 178.0594 - val_mse: 178.0594 - val_mae: 8.8265\n",
      "Epoch 230/250\n",
      "745/745 - 1s - loss: 145.1470 - mse: 145.1470 - mae: 8.0169 - val_loss: 182.7256 - val_mse: 182.7256 - val_mae: 9.0114\n",
      "Epoch 231/250\n",
      "745/745 - 1s - loss: 144.8795 - mse: 144.8795 - mae: 7.9819 - val_loss: 179.5210 - val_mse: 179.5210 - val_mae: 8.7835\n",
      "Epoch 232/250\n",
      "745/745 - 1s - loss: 143.7509 - mse: 143.7509 - mae: 7.9541 - val_loss: 179.5333 - val_mse: 179.5333 - val_mae: 8.9301\n",
      "Epoch 233/250\n",
      "745/745 - 1s - loss: 144.8978 - mse: 144.8978 - mae: 7.9837 - val_loss: 176.9849 - val_mse: 176.9849 - val_mae: 8.5912\n",
      "Epoch 234/250\n",
      "745/745 - 1s - loss: 144.2364 - mse: 144.2364 - mae: 7.9858 - val_loss: 176.0185 - val_mse: 176.0185 - val_mae: 8.6664\n",
      "Epoch 235/250\n",
      "745/745 - 1s - loss: 143.5058 - mse: 143.5058 - mae: 7.9334 - val_loss: 175.8698 - val_mse: 175.8698 - val_mae: 8.6186\n",
      "Epoch 236/250\n",
      "745/745 - 1s - loss: 144.1816 - mse: 144.1816 - mae: 7.9754 - val_loss: 178.6110 - val_mse: 178.6110 - val_mae: 8.7015\n",
      "Epoch 237/250\n",
      "745/745 - 1s - loss: 144.2728 - mse: 144.2728 - mae: 7.9827 - val_loss: 176.6038 - val_mse: 176.6038 - val_mae: 8.7099\n",
      "Epoch 238/250\n",
      "745/745 - 1s - loss: 144.0451 - mse: 144.0451 - mae: 7.9640 - val_loss: 184.7889 - val_mse: 184.7889 - val_mae: 9.0137\n",
      "Epoch 239/250\n",
      "745/745 - 1s - loss: 143.1128 - mse: 143.1128 - mae: 7.9568 - val_loss: 176.2217 - val_mse: 176.2217 - val_mae: 8.8466\n",
      "Epoch 240/250\n",
      "745/745 - 1s - loss: 143.7758 - mse: 143.7758 - mae: 7.9647 - val_loss: 180.8503 - val_mse: 180.8503 - val_mae: 8.9097\n",
      "Epoch 241/250\n",
      "745/745 - 1s - loss: 143.3895 - mse: 143.3895 - mae: 7.9467 - val_loss: 177.6322 - val_mse: 177.6322 - val_mae: 8.8649\n",
      "Epoch 242/250\n",
      "745/745 - 1s - loss: 143.5592 - mse: 143.5592 - mae: 7.9599 - val_loss: 181.7916 - val_mse: 181.7916 - val_mae: 8.6757\n",
      "Epoch 243/250\n",
      "745/745 - 1s - loss: 143.3448 - mse: 143.3448 - mae: 7.9378 - val_loss: 177.0234 - val_mse: 177.0234 - val_mae: 8.8294\n",
      "Epoch 244/250\n",
      "745/745 - 1s - loss: 142.9830 - mse: 142.9830 - mae: 7.9358 - val_loss: 180.8295 - val_mse: 180.8295 - val_mae: 8.9784\n",
      "Epoch 245/250\n",
      "745/745 - 1s - loss: 142.9550 - mse: 142.9550 - mae: 7.9519 - val_loss: 178.6976 - val_mse: 178.6976 - val_mae: 8.8323\n",
      "Epoch 246/250\n",
      "745/745 - 1s - loss: 142.5397 - mse: 142.5397 - mae: 7.9444 - val_loss: 179.6410 - val_mse: 179.6410 - val_mae: 8.9183\n",
      "Epoch 247/250\n",
      "745/745 - 1s - loss: 142.2970 - mse: 142.2970 - mae: 7.9238 - val_loss: 182.5701 - val_mse: 182.5701 - val_mae: 9.0858\n",
      "Epoch 248/250\n",
      "745/745 - 1s - loss: 143.6708 - mse: 143.6708 - mae: 7.9756 - val_loss: 180.3653 - val_mse: 180.3653 - val_mae: 8.9717\n",
      "Epoch 249/250\n",
      "745/745 - 1s - loss: 142.8530 - mse: 142.8530 - mae: 7.9542 - val_loss: 180.7251 - val_mse: 180.7251 - val_mae: 8.6890\n",
      "Epoch 250/250\n",
      "745/745 - 1s - loss: 142.3684 - mse: 142.3684 - mae: 7.9200 - val_loss: 181.3063 - val_mse: 181.3063 - val_mae: 8.6566\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pca, y_train, epochs = 250, batch_size = 16, verbose = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cc2af49a30>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "pca_preds = model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoring metrics\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test,pca_preds))\n",
    "mae = metrics.mean_absolute_error(y_test,pca_preds)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test,pca_preds)\n",
    "ex_var = metrics.explained_variance_score(y_test,pca_preds)\n",
    "r2_score = metrics.r2_score(y_test,pca_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated scoring metrics with reduced dimensions:\n",
      "\n",
      "Root Mean Squared Error: \t13.09 Kelvins\n",
      "Mean Absolute Error:\t\t8.47 Kelvins\n",
      "Mean Abs. Percent Error:\t7.59%\n",
      "Explained Variance Score:\t0.8523\n",
      "R2 Score:\t\t\t0.8511\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUpdated scoring metrics with reduced dimensions:\\n\")\n",
    "print(f\"Root Mean Squared Error: \t{np.round(rmse,2)} Kelvins\")\n",
    "print(f\"Mean Absolute Error:\t\t{np.round(mae,2)} Kelvins\")\n",
    "print(f\"Mean Abs. Percent Error:\t{np.round(mape,2)}%\")\n",
    "print(f\"Explained Variance Score:\t{np.round(ex_var,4)}\")\n",
    "print(f\"R2 Score:\t\t\t{np.round(r2_score,4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression part 2\n",
    "#### Elements dataset\n",
    "Now we run identical experiments on the next dataset, which gives us the detailed element-by-element makeup of every superconductor at the atomic level.  This dataset has a 1-to-1 correspondence with the prior dataset, and in theory they could be merged into one mega-DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>He</th>\n",
       "      <th>Li</th>\n",
       "      <th>Be</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>F</th>\n",
       "      <th>Ne</th>\n",
       "      <th>...</th>\n",
       "      <th>Au</th>\n",
       "      <th>Hg</th>\n",
       "      <th>Tl</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Po</th>\n",
       "      <th>At</th>\n",
       "      <th>Rn</th>\n",
       "      <th>critical_temp</th>\n",
       "      <th>material</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Ba0.2La1.8Cu1O4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Ba0.1La1.9Ag0.1Cu0.9O4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Ba0.1La1.9Cu1O4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Ba0.15La1.85Cu1O4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Ba0.3La1.7Cu1O4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     H  He   Li   Be    B    C    N    O    F  Ne  ...   Au   Hg   Tl   Pb  \\\n",
       "0  0.0   0  0.0  0.0  0.0  0.0  0.0  4.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0   0  0.0  0.0  0.0  0.0  0.0  4.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0   0  0.0  0.0  0.0  0.0  0.0  4.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0   0  0.0  0.0  0.0  0.0  0.0  4.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0   0  0.0  0.0  0.0  0.0  0.0  4.0  0.0   0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    Bi  Po  At  Rn  critical_temp                material  \n",
       "0  0.0   0   0   0           29.0         Ba0.2La1.8Cu1O4  \n",
       "1  0.0   0   0   0           26.0  Ba0.1La1.9Ag0.1Cu0.9O4  \n",
       "2  0.0   0   0   0           19.0         Ba0.1La1.9Cu1O4  \n",
       "3  0.0   0   0   0           22.0       Ba0.15La1.85Cu1O4  \n",
       "4  0.0   0   0   0           23.0         Ba0.3La1.7Cu1O4  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_df = pd.read_csv('../datasets/unique_m.csv')\n",
    "\n",
    "elements_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>He</th>\n",
       "      <th>Li</th>\n",
       "      <th>Be</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>F</th>\n",
       "      <th>Ne</th>\n",
       "      <th>...</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Au</th>\n",
       "      <th>Hg</th>\n",
       "      <th>Tl</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Po</th>\n",
       "      <th>At</th>\n",
       "      <th>Rn</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.000000</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>21263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.034638</td>\n",
       "      <td>0.142594</td>\n",
       "      <td>0.384968</td>\n",
       "      <td>0.013284</td>\n",
       "      <td>3.009129</td>\n",
       "      <td>0.014874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.020535</td>\n",
       "      <td>0.036663</td>\n",
       "      <td>0.047954</td>\n",
       "      <td>0.042461</td>\n",
       "      <td>0.201009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.421219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.267220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129552</td>\n",
       "      <td>0.848541</td>\n",
       "      <td>1.044486</td>\n",
       "      <td>4.408032</td>\n",
       "      <td>0.150427</td>\n",
       "      <td>3.811649</td>\n",
       "      <td>0.132119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307888</td>\n",
       "      <td>0.717975</td>\n",
       "      <td>0.205846</td>\n",
       "      <td>0.272298</td>\n",
       "      <td>0.274365</td>\n",
       "      <td>0.655927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.254362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  H       He            Li            Be             B  \\\n",
       "count  21263.000000  21263.0  21263.000000  21263.000000  21263.000000   \n",
       "mean       0.017685      0.0      0.012125      0.034638      0.142594   \n",
       "std        0.267220      0.0      0.129552      0.848541      1.044486   \n",
       "min        0.000000      0.0      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.0      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.0      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.0      0.000000      0.000000      0.000000   \n",
       "max       14.000000      0.0      3.000000     40.000000    105.000000   \n",
       "\n",
       "                  C             N             O             F       Ne  ...  \\\n",
       "count  21263.000000  21263.000000  21263.000000  21263.000000  21263.0  ...   \n",
       "mean       0.384968      0.013284      3.009129      0.014874      0.0  ...   \n",
       "std        4.408032      0.150427      3.811649      0.132119      0.0  ...   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.0  ...   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.0  ...   \n",
       "50%        0.000000      0.000000      1.000000      0.000000      0.0  ...   \n",
       "75%        0.000000      0.000000      6.800000      0.000000      0.0  ...   \n",
       "max      120.000000     12.800000     66.000000      4.000000      0.0  ...   \n",
       "\n",
       "                 Pt            Au            Hg            Tl            Pb  \\\n",
       "count  21263.000000  21263.000000  21263.000000  21263.000000  21263.000000   \n",
       "mean       0.034108      0.020535      0.036663      0.047954      0.042461   \n",
       "std        0.307888      0.717975      0.205846      0.272298      0.274365   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        5.800000     64.000000      8.000000      7.000000     19.000000   \n",
       "\n",
       "                 Bi       Po       At       Rn  critical_temp  \n",
       "count  21263.000000  21263.0  21263.0  21263.0   21263.000000  \n",
       "mean       0.201009      0.0      0.0      0.0      34.421219  \n",
       "std        0.655927      0.0      0.0      0.0      34.254362  \n",
       "min        0.000000      0.0      0.0      0.0       0.000210  \n",
       "25%        0.000000      0.0      0.0      0.0       5.365000  \n",
       "50%        0.000000      0.0      0.0      0.0      20.000000  \n",
       "75%        0.000000      0.0      0.0      0.0      63.000000  \n",
       "max       14.000000      0.0      0.0      0.0     185.000000  \n",
       "\n",
       "[8 rows x 87 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21263 entries, 0 to 21262\n",
      "Data columns (total 88 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   H              21263 non-null  float64\n",
      " 1   He             21263 non-null  int64  \n",
      " 2   Li             21263 non-null  float64\n",
      " 3   Be             21263 non-null  float64\n",
      " 4   B              21263 non-null  float64\n",
      " 5   C              21263 non-null  float64\n",
      " 6   N              21263 non-null  float64\n",
      " 7   O              21263 non-null  float64\n",
      " 8   F              21263 non-null  float64\n",
      " 9   Ne             21263 non-null  int64  \n",
      " 10  Na             21263 non-null  float64\n",
      " 11  Mg             21263 non-null  float64\n",
      " 12  Al             21263 non-null  float64\n",
      " 13  Si             21263 non-null  float64\n",
      " 14  P              21263 non-null  float64\n",
      " 15  S              21263 non-null  float64\n",
      " 16  Cl             21263 non-null  float64\n",
      " 17  Ar             21263 non-null  int64  \n",
      " 18  K              21263 non-null  float64\n",
      " 19  Ca             21263 non-null  float64\n",
      " 20  Sc             21263 non-null  float64\n",
      " 21  Ti             21263 non-null  float64\n",
      " 22  V              21263 non-null  float64\n",
      " 23  Cr             21263 non-null  float64\n",
      " 24  Mn             21263 non-null  float64\n",
      " 25  Fe             21263 non-null  float64\n",
      " 26  Co             21263 non-null  float64\n",
      " 27  Ni             21263 non-null  float64\n",
      " 28  Cu             21263 non-null  float64\n",
      " 29  Zn             21263 non-null  float64\n",
      " 30  Ga             21263 non-null  float64\n",
      " 31  Ge             21263 non-null  float64\n",
      " 32  As             21263 non-null  float64\n",
      " 33  Se             21263 non-null  float64\n",
      " 34  Br             21263 non-null  float64\n",
      " 35  Kr             21263 non-null  int64  \n",
      " 36  Rb             21263 non-null  float64\n",
      " 37  Sr             21263 non-null  float64\n",
      " 38  Y              21263 non-null  float64\n",
      " 39  Zr             21263 non-null  float64\n",
      " 40  Nb             21263 non-null  float64\n",
      " 41  Mo             21263 non-null  float64\n",
      " 42  Tc             21263 non-null  float64\n",
      " 43  Ru             21263 non-null  float64\n",
      " 44  Rh             21263 non-null  float64\n",
      " 45  Pd             21263 non-null  float64\n",
      " 46  Ag             21263 non-null  float64\n",
      " 47  Cd             21263 non-null  float64\n",
      " 48  In             21263 non-null  float64\n",
      " 49  Sn             21263 non-null  float64\n",
      " 50  Sb             21263 non-null  float64\n",
      " 51  Te             21263 non-null  float64\n",
      " 52  I              21263 non-null  float64\n",
      " 53  Xe             21263 non-null  int64  \n",
      " 54  Cs             21263 non-null  float64\n",
      " 55  Ba             21263 non-null  float64\n",
      " 56  La             21263 non-null  float64\n",
      " 57  Ce             21263 non-null  float64\n",
      " 58  Pr             21263 non-null  float64\n",
      " 59  Nd             21263 non-null  float64\n",
      " 60  Pm             21263 non-null  int64  \n",
      " 61  Sm             21263 non-null  float64\n",
      " 62  Eu             21263 non-null  float64\n",
      " 63  Gd             21263 non-null  float64\n",
      " 64  Tb             21263 non-null  float64\n",
      " 65  Dy             21263 non-null  float64\n",
      " 66  Ho             21263 non-null  float64\n",
      " 67  Er             21263 non-null  float64\n",
      " 68  Tm             21263 non-null  float64\n",
      " 69  Yb             21263 non-null  float64\n",
      " 70  Lu             21263 non-null  float64\n",
      " 71  Hf             21263 non-null  float64\n",
      " 72  Ta             21263 non-null  float64\n",
      " 73  W              21263 non-null  float64\n",
      " 74  Re             21263 non-null  float64\n",
      " 75  Os             21263 non-null  float64\n",
      " 76  Ir             21263 non-null  float64\n",
      " 77  Pt             21263 non-null  float64\n",
      " 78  Au             21263 non-null  float64\n",
      " 79  Hg             21263 non-null  float64\n",
      " 80  Tl             21263 non-null  float64\n",
      " 81  Pb             21263 non-null  float64\n",
      " 82  Bi             21263 non-null  float64\n",
      " 83  Po             21263 non-null  int64  \n",
      " 84  At             21263 non-null  int64  \n",
      " 85  Rn             21263 non-null  int64  \n",
      " 86  critical_temp  21263 non-null  float64\n",
      " 87  material       21263 non-null  object \n",
      "dtypes: float64(78), int64(9), object(1)\n",
      "memory usage: 14.3+ MB\n"
     ]
    }
   ],
   "source": [
    "elements_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice we're dropping TWO columns from X\n",
    "\n",
    "X = elements_df.drop(columns=['critical_temp','material'])\n",
    "y = elements_df['critical_temp']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate scaler and scale data\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                2784      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,329\n",
      "Trainable params: 3,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_dim = X_train_sc.shape[1], activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "745/745 - 1s - loss: 789.2092 - mse: 789.2092 - mae: 18.1118 - val_loss: 433.5536 - val_mse: 433.5536 - val_mae: 14.7176\n",
      "Epoch 2/250\n",
      "745/745 - 1s - loss: 395.0325 - mse: 395.0325 - mae: 13.4556 - val_loss: 364.4608 - val_mse: 364.4608 - val_mae: 13.2907\n",
      "Epoch 3/250\n",
      "745/745 - 1s - loss: 324.2941 - mse: 324.2941 - mae: 12.3559 - val_loss: 310.2792 - val_mse: 310.2792 - val_mae: 12.2330\n",
      "Epoch 4/250\n",
      "745/745 - 1s - loss: 274.4466 - mse: 274.4466 - mae: 11.3932 - val_loss: 270.6771 - val_mse: 270.6771 - val_mae: 11.5058\n",
      "Epoch 5/250\n",
      "745/745 - 1s - loss: 244.3115 - mse: 244.3115 - mae: 10.7396 - val_loss: 253.6586 - val_mse: 253.6586 - val_mae: 11.1130\n",
      "Epoch 6/250\n",
      "745/745 - 1s - loss: 226.8712 - mse: 226.8712 - mae: 10.3054 - val_loss: 238.4697 - val_mse: 238.4697 - val_mae: 10.6691\n",
      "Epoch 7/250\n",
      "745/745 - 1s - loss: 214.1754 - mse: 214.1754 - mae: 9.9839 - val_loss: 230.5312 - val_mse: 230.5312 - val_mae: 10.5401\n",
      "Epoch 8/250\n",
      "745/745 - 1s - loss: 206.7265 - mse: 206.7265 - mae: 9.7701 - val_loss: 224.0504 - val_mse: 224.0504 - val_mae: 10.2082\n",
      "Epoch 9/250\n",
      "745/745 - 1s - loss: 199.7220 - mse: 199.7220 - mae: 9.5957 - val_loss: 220.2382 - val_mse: 220.2382 - val_mae: 9.9738\n",
      "Epoch 10/250\n",
      "745/745 - 1s - loss: 193.8367 - mse: 193.8367 - mae: 9.4219 - val_loss: 212.7177 - val_mse: 212.7177 - val_mae: 9.8890\n",
      "Epoch 11/250\n",
      "745/745 - 1s - loss: 189.1817 - mse: 189.1817 - mae: 9.2642 - val_loss: 209.7691 - val_mse: 209.7691 - val_mae: 9.9125\n",
      "Epoch 12/250\n",
      "745/745 - 1s - loss: 184.4749 - mse: 184.4749 - mae: 9.1426 - val_loss: 210.2870 - val_mse: 210.2870 - val_mae: 9.9207\n",
      "Epoch 13/250\n",
      "745/745 - 1s - loss: 180.2111 - mse: 180.2111 - mae: 9.0231 - val_loss: 204.0267 - val_mse: 204.0267 - val_mae: 9.7572\n",
      "Epoch 14/250\n",
      "745/745 - 1s - loss: 177.1048 - mse: 177.1048 - mae: 8.9054 - val_loss: 199.8001 - val_mse: 199.8001 - val_mae: 9.5926\n",
      "Epoch 15/250\n",
      "745/745 - 1s - loss: 174.0740 - mse: 174.0740 - mae: 8.8052 - val_loss: 201.4234 - val_mse: 201.4234 - val_mae: 9.2802\n",
      "Epoch 16/250\n",
      "745/745 - 1s - loss: 171.8967 - mse: 171.8967 - mae: 8.7610 - val_loss: 195.9830 - val_mse: 195.9830 - val_mae: 9.3672\n",
      "Epoch 17/250\n",
      "745/745 - 1s - loss: 168.7180 - mse: 168.7180 - mae: 8.6862 - val_loss: 201.8338 - val_mse: 201.8338 - val_mae: 9.2070\n",
      "Epoch 18/250\n",
      "745/745 - 1s - loss: 167.8835 - mse: 167.8835 - mae: 8.6462 - val_loss: 195.2323 - val_mse: 195.2323 - val_mae: 9.0937\n",
      "Epoch 19/250\n",
      "745/745 - 1s - loss: 165.4843 - mse: 165.4843 - mae: 8.5335 - val_loss: 195.3014 - val_mse: 195.3014 - val_mae: 9.2816\n",
      "Epoch 20/250\n",
      "745/745 - 1s - loss: 163.9599 - mse: 163.9599 - mae: 8.4992 - val_loss: 191.8730 - val_mse: 191.8730 - val_mae: 9.2034\n",
      "Epoch 21/250\n",
      "745/745 - 1s - loss: 162.7417 - mse: 162.7417 - mae: 8.4354 - val_loss: 194.6865 - val_mse: 194.6865 - val_mae: 9.2161\n",
      "Epoch 22/250\n",
      "745/745 - 1s - loss: 161.9865 - mse: 161.9865 - mae: 8.4110 - val_loss: 194.3819 - val_mse: 194.3819 - val_mae: 9.0138\n",
      "Epoch 23/250\n",
      "745/745 - 1s - loss: 160.8043 - mse: 160.8043 - mae: 8.3650 - val_loss: 191.4269 - val_mse: 191.4269 - val_mae: 8.9884\n",
      "Epoch 24/250\n",
      "745/745 - 1s - loss: 159.1673 - mse: 159.1673 - mae: 8.3261 - val_loss: 192.6558 - val_mse: 192.6558 - val_mae: 9.0223\n",
      "Epoch 25/250\n",
      "745/745 - 1s - loss: 157.8343 - mse: 157.8343 - mae: 8.2432 - val_loss: 198.3420 - val_mse: 198.3420 - val_mae: 9.0237\n",
      "Epoch 26/250\n",
      "745/745 - 1s - loss: 157.4684 - mse: 157.4684 - mae: 8.2523 - val_loss: 192.9841 - val_mse: 192.9841 - val_mae: 8.9548\n",
      "Epoch 27/250\n",
      "745/745 - 1s - loss: 157.1204 - mse: 157.1204 - mae: 8.2452 - val_loss: 190.6365 - val_mse: 190.6365 - val_mae: 8.9341\n",
      "Epoch 28/250\n",
      "745/745 - 1s - loss: 155.8232 - mse: 155.8232 - mae: 8.2165 - val_loss: 191.8631 - val_mse: 191.8631 - val_mae: 8.8574\n",
      "Epoch 29/250\n",
      "745/745 - 1s - loss: 154.8655 - mse: 154.8655 - mae: 8.1807 - val_loss: 195.8183 - val_mse: 195.8183 - val_mae: 8.7402\n",
      "Epoch 30/250\n",
      "745/745 - 1s - loss: 154.1858 - mse: 154.1858 - mae: 8.1264 - val_loss: 190.9092 - val_mse: 190.9092 - val_mae: 8.9048\n",
      "Epoch 31/250\n",
      "745/745 - 1s - loss: 153.7852 - mse: 153.7852 - mae: 8.1384 - val_loss: 192.7825 - val_mse: 192.7825 - val_mae: 9.0791\n",
      "Epoch 32/250\n",
      "745/745 - 1s - loss: 152.4343 - mse: 152.4343 - mae: 8.0686 - val_loss: 195.4062 - val_mse: 195.4062 - val_mae: 8.7460\n",
      "Epoch 33/250\n",
      "745/745 - 1s - loss: 152.7256 - mse: 152.7256 - mae: 8.0771 - val_loss: 197.0752 - val_mse: 197.0752 - val_mae: 8.7098\n",
      "Epoch 34/250\n",
      "745/745 - 1s - loss: 151.4573 - mse: 151.4573 - mae: 8.0401 - val_loss: 195.4214 - val_mse: 195.4214 - val_mae: 9.1617\n",
      "Epoch 35/250\n",
      "745/745 - 1s - loss: 151.1203 - mse: 151.1203 - mae: 8.0542 - val_loss: 197.0483 - val_mse: 197.0483 - val_mae: 8.7052\n",
      "Epoch 36/250\n",
      "745/745 - 1s - loss: 150.2373 - mse: 150.2373 - mae: 8.0056 - val_loss: 191.7670 - val_mse: 191.7670 - val_mae: 8.9338\n",
      "Epoch 37/250\n",
      "745/745 - 1s - loss: 150.1379 - mse: 150.1379 - mae: 7.9850 - val_loss: 190.2062 - val_mse: 190.2062 - val_mae: 8.7169\n",
      "Epoch 38/250\n",
      "745/745 - 1s - loss: 150.5997 - mse: 150.5997 - mae: 7.9997 - val_loss: 192.3320 - val_mse: 192.3320 - val_mae: 8.6129\n",
      "Epoch 39/250\n",
      "745/745 - 1s - loss: 149.2123 - mse: 149.2123 - mae: 7.9685 - val_loss: 192.4467 - val_mse: 192.4467 - val_mae: 8.7029\n",
      "Epoch 40/250\n",
      "745/745 - 1s - loss: 148.8095 - mse: 148.8095 - mae: 7.9549 - val_loss: 200.7638 - val_mse: 200.7638 - val_mae: 8.6410\n",
      "Epoch 41/250\n",
      "745/745 - 1s - loss: 148.4236 - mse: 148.4236 - mae: 7.9379 - val_loss: 196.3463 - val_mse: 196.3463 - val_mae: 8.5725\n",
      "Epoch 42/250\n",
      "745/745 - 1s - loss: 148.3839 - mse: 148.3839 - mae: 7.9219 - val_loss: 194.2885 - val_mse: 194.2885 - val_mae: 8.6641\n",
      "Epoch 43/250\n",
      "745/745 - 1s - loss: 147.6989 - mse: 147.6989 - mae: 7.9010 - val_loss: 191.2973 - val_mse: 191.2973 - val_mae: 8.5793\n",
      "Epoch 44/250\n",
      "745/745 - 1s - loss: 146.8505 - mse: 146.8505 - mae: 7.8610 - val_loss: 193.4803 - val_mse: 193.4803 - val_mae: 8.8306\n",
      "Epoch 45/250\n",
      "745/745 - 1s - loss: 146.7235 - mse: 146.7235 - mae: 7.8962 - val_loss: 198.0567 - val_mse: 198.0567 - val_mae: 8.7522\n",
      "Epoch 46/250\n",
      "745/745 - 1s - loss: 146.9146 - mse: 146.9146 - mae: 7.8583 - val_loss: 204.4244 - val_mse: 204.4244 - val_mae: 8.6924\n",
      "Epoch 47/250\n",
      "745/745 - 1s - loss: 146.0107 - mse: 146.0107 - mae: 7.8627 - val_loss: 191.0302 - val_mse: 191.0302 - val_mae: 8.6784\n",
      "Epoch 48/250\n",
      "745/745 - 1s - loss: 145.8758 - mse: 145.8758 - mae: 7.8263 - val_loss: 196.3596 - val_mse: 196.3596 - val_mae: 8.8544\n",
      "Epoch 49/250\n",
      "745/745 - 1s - loss: 145.3968 - mse: 145.3968 - mae: 7.8206 - val_loss: 194.3425 - val_mse: 194.3425 - val_mae: 8.7325\n",
      "Epoch 50/250\n",
      "745/745 - 1s - loss: 144.5040 - mse: 144.5040 - mae: 7.7886 - val_loss: 193.7813 - val_mse: 193.7813 - val_mae: 8.6015\n",
      "Epoch 51/250\n",
      "745/745 - 1s - loss: 144.4761 - mse: 144.4761 - mae: 7.7938 - val_loss: 198.3953 - val_mse: 198.3953 - val_mae: 8.5243\n",
      "Epoch 52/250\n",
      "745/745 - 1s - loss: 145.1299 - mse: 145.1299 - mae: 7.8069 - val_loss: 197.4862 - val_mse: 197.4862 - val_mae: 8.5509\n",
      "Epoch 53/250\n",
      "745/745 - 1s - loss: 143.1855 - mse: 143.1855 - mae: 7.7510 - val_loss: 197.0677 - val_mse: 197.0677 - val_mae: 8.8608\n",
      "Epoch 54/250\n",
      "745/745 - 1s - loss: 143.5190 - mse: 143.5190 - mae: 7.7678 - val_loss: 194.1287 - val_mse: 194.1287 - val_mae: 8.6439\n",
      "Epoch 55/250\n",
      "745/745 - 1s - loss: 143.2597 - mse: 143.2597 - mae: 7.7411 - val_loss: 200.5839 - val_mse: 200.5839 - val_mae: 8.5644\n",
      "Epoch 56/250\n",
      "745/745 - 1s - loss: 142.5284 - mse: 142.5284 - mae: 7.7283 - val_loss: 195.7073 - val_mse: 195.7073 - val_mae: 8.5048\n",
      "Epoch 57/250\n",
      "745/745 - 1s - loss: 142.0308 - mse: 142.0308 - mae: 7.7223 - val_loss: 194.8670 - val_mse: 194.8670 - val_mae: 8.6621\n",
      "Epoch 58/250\n",
      "745/745 - 1s - loss: 141.8413 - mse: 141.8413 - mae: 7.6983 - val_loss: 195.2062 - val_mse: 195.2062 - val_mae: 8.4601\n",
      "Epoch 59/250\n",
      "745/745 - 1s - loss: 141.8479 - mse: 141.8479 - mae: 7.7022 - val_loss: 194.8102 - val_mse: 194.8102 - val_mae: 8.5252\n",
      "Epoch 60/250\n",
      "745/745 - 1s - loss: 141.8229 - mse: 141.8229 - mae: 7.7084 - val_loss: 201.6056 - val_mse: 201.6056 - val_mae: 8.9374\n",
      "Epoch 61/250\n",
      "745/745 - 1s - loss: 141.0479 - mse: 141.0479 - mae: 7.6660 - val_loss: 203.0517 - val_mse: 203.0517 - val_mae: 8.5144\n",
      "Epoch 62/250\n",
      "745/745 - 1s - loss: 141.1505 - mse: 141.1505 - mae: 7.6816 - val_loss: 199.7662 - val_mse: 199.7662 - val_mae: 8.5438\n",
      "Epoch 63/250\n",
      "745/745 - 1s - loss: 140.3478 - mse: 140.3478 - mae: 7.6511 - val_loss: 195.2161 - val_mse: 195.2161 - val_mae: 8.6106\n",
      "Epoch 64/250\n",
      "745/745 - 1s - loss: 140.3839 - mse: 140.3839 - mae: 7.6470 - val_loss: 195.9385 - val_mse: 195.9385 - val_mae: 8.4768\n",
      "Epoch 65/250\n",
      "745/745 - 1s - loss: 139.6689 - mse: 139.6689 - mae: 7.6152 - val_loss: 200.3121 - val_mse: 200.3121 - val_mae: 8.4544\n",
      "Epoch 66/250\n",
      "745/745 - 1s - loss: 140.1198 - mse: 140.1198 - mae: 7.6495 - val_loss: 194.8008 - val_mse: 194.8008 - val_mae: 8.4190\n",
      "Epoch 67/250\n",
      "745/745 - 1s - loss: 139.0600 - mse: 139.0600 - mae: 7.6155 - val_loss: 191.7968 - val_mse: 191.7968 - val_mae: 8.4845\n",
      "Epoch 68/250\n",
      "745/745 - 1s - loss: 138.4738 - mse: 138.4738 - mae: 7.5820 - val_loss: 192.7723 - val_mse: 192.7723 - val_mae: 8.5528\n",
      "Epoch 69/250\n",
      "745/745 - 1s - loss: 139.2507 - mse: 139.2507 - mae: 7.6015 - val_loss: 203.3774 - val_mse: 203.3774 - val_mae: 8.4707\n",
      "Epoch 70/250\n",
      "745/745 - 1s - loss: 138.1114 - mse: 138.1114 - mae: 7.5723 - val_loss: 190.9082 - val_mse: 190.9082 - val_mae: 8.4963\n",
      "Epoch 71/250\n",
      "745/745 - 1s - loss: 137.6803 - mse: 137.6803 - mae: 7.5738 - val_loss: 191.4267 - val_mse: 191.4267 - val_mae: 8.4213\n",
      "Epoch 72/250\n",
      "745/745 - 1s - loss: 138.3998 - mse: 138.3998 - mae: 7.5559 - val_loss: 195.6356 - val_mse: 195.6356 - val_mae: 8.3679\n",
      "Epoch 73/250\n",
      "745/745 - 1s - loss: 137.3643 - mse: 137.3643 - mae: 7.5621 - val_loss: 202.3262 - val_mse: 202.3262 - val_mae: 8.3476\n",
      "Epoch 74/250\n",
      "745/745 - 1s - loss: 137.1557 - mse: 137.1557 - mae: 7.5274 - val_loss: 194.7405 - val_mse: 194.7405 - val_mae: 8.4184\n",
      "Epoch 75/250\n",
      "745/745 - 1s - loss: 137.2840 - mse: 137.2840 - mae: 7.5402 - val_loss: 196.3012 - val_mse: 196.3012 - val_mae: 8.7932\n",
      "Epoch 76/250\n",
      "745/745 - 1s - loss: 136.9075 - mse: 136.9075 - mae: 7.5544 - val_loss: 189.3549 - val_mse: 189.3549 - val_mae: 8.5525\n",
      "Epoch 77/250\n",
      "745/745 - 1s - loss: 137.1694 - mse: 137.1694 - mae: 7.5319 - val_loss: 191.4634 - val_mse: 191.4634 - val_mae: 8.4196\n",
      "Epoch 78/250\n",
      "745/745 - 1s - loss: 135.7955 - mse: 135.7955 - mae: 7.4992 - val_loss: 188.6308 - val_mse: 188.6308 - val_mae: 8.3371\n",
      "Epoch 79/250\n",
      "745/745 - 1s - loss: 135.9276 - mse: 135.9276 - mae: 7.4966 - val_loss: 191.6953 - val_mse: 191.6953 - val_mae: 8.3877\n",
      "Epoch 80/250\n",
      "745/745 - 1s - loss: 135.6424 - mse: 135.6424 - mae: 7.4975 - val_loss: 190.5632 - val_mse: 190.5632 - val_mae: 8.2977\n",
      "Epoch 81/250\n",
      "745/745 - 1s - loss: 135.3064 - mse: 135.3064 - mae: 7.4617 - val_loss: 190.1894 - val_mse: 190.1894 - val_mae: 8.2990\n",
      "Epoch 82/250\n",
      "745/745 - 1s - loss: 135.4442 - mse: 135.4442 - mae: 7.5041 - val_loss: 191.8685 - val_mse: 191.8685 - val_mae: 8.6701\n",
      "Epoch 83/250\n",
      "745/745 - 1s - loss: 134.4469 - mse: 134.4469 - mae: 7.4618 - val_loss: 190.8410 - val_mse: 190.8410 - val_mae: 8.4216\n",
      "Epoch 84/250\n",
      "745/745 - 1s - loss: 134.0458 - mse: 134.0458 - mae: 7.4377 - val_loss: 195.6566 - val_mse: 195.6566 - val_mae: 8.2417\n",
      "Epoch 85/250\n",
      "745/745 - 1s - loss: 134.2853 - mse: 134.2853 - mae: 7.4393 - val_loss: 191.4685 - val_mse: 191.4685 - val_mae: 8.6335\n",
      "Epoch 86/250\n",
      "745/745 - 1s - loss: 133.8577 - mse: 133.8577 - mae: 7.4415 - val_loss: 183.8364 - val_mse: 183.8364 - val_mae: 8.3813\n",
      "Epoch 87/250\n",
      "745/745 - 1s - loss: 134.1291 - mse: 134.1291 - mae: 7.4323 - val_loss: 188.3253 - val_mse: 188.3253 - val_mae: 8.2801\n",
      "Epoch 88/250\n",
      "745/745 - 1s - loss: 133.6035 - mse: 133.6035 - mae: 7.4246 - val_loss: 187.2085 - val_mse: 187.2085 - val_mae: 8.3619\n",
      "Epoch 89/250\n",
      "745/745 - 1s - loss: 133.2229 - mse: 133.2229 - mae: 7.4025 - val_loss: 187.3281 - val_mse: 187.3281 - val_mae: 8.4396\n",
      "Epoch 90/250\n",
      "745/745 - 1s - loss: 133.3139 - mse: 133.3139 - mae: 7.4161 - val_loss: 199.6482 - val_mse: 199.6482 - val_mae: 8.2995\n",
      "Epoch 91/250\n",
      "745/745 - 1s - loss: 133.6828 - mse: 133.6828 - mae: 7.4068 - val_loss: 187.6205 - val_mse: 187.6205 - val_mae: 8.2361\n",
      "Epoch 92/250\n",
      "745/745 - 1s - loss: 132.4483 - mse: 132.4483 - mae: 7.3922 - val_loss: 183.3610 - val_mse: 183.3610 - val_mae: 8.3604\n",
      "Epoch 93/250\n",
      "745/745 - 1s - loss: 131.6391 - mse: 131.6391 - mae: 7.3713 - val_loss: 191.3092 - val_mse: 191.3092 - val_mae: 8.2665\n",
      "Epoch 94/250\n",
      "745/745 - 1s - loss: 131.7832 - mse: 131.7832 - mae: 7.3487 - val_loss: 188.2001 - val_mse: 188.2001 - val_mae: 8.3579\n",
      "Epoch 95/250\n",
      "745/745 - 1s - loss: 132.4184 - mse: 132.4184 - mae: 7.3951 - val_loss: 185.3806 - val_mse: 185.3806 - val_mae: 8.3236\n",
      "Epoch 96/250\n",
      "745/745 - 1s - loss: 131.1082 - mse: 131.1082 - mae: 7.3255 - val_loss: 194.0432 - val_mse: 194.0432 - val_mae: 8.6154\n",
      "Epoch 97/250\n",
      "745/745 - 1s - loss: 130.9072 - mse: 130.9072 - mae: 7.3359 - val_loss: 181.9877 - val_mse: 181.9877 - val_mae: 8.2307\n",
      "Epoch 98/250\n",
      "745/745 - 1s - loss: 130.8353 - mse: 130.8353 - mae: 7.3335 - val_loss: 186.8158 - val_mse: 186.8158 - val_mae: 8.2123\n",
      "Epoch 99/250\n",
      "745/745 - 1s - loss: 130.6054 - mse: 130.6054 - mae: 7.3222 - val_loss: 186.7294 - val_mse: 186.7294 - val_mae: 8.2015\n",
      "Epoch 100/250\n",
      "745/745 - 1s - loss: 130.0284 - mse: 130.0284 - mae: 7.3151 - val_loss: 182.8475 - val_mse: 182.8475 - val_mae: 8.4941\n",
      "Epoch 101/250\n",
      "745/745 - 1s - loss: 130.8325 - mse: 130.8325 - mae: 7.3348 - val_loss: 185.7112 - val_mse: 185.7112 - val_mae: 8.1698\n",
      "Epoch 102/250\n",
      "745/745 - 1s - loss: 130.5418 - mse: 130.5418 - mae: 7.3201 - val_loss: 185.3241 - val_mse: 185.3241 - val_mae: 8.2690\n",
      "Epoch 103/250\n",
      "745/745 - 1s - loss: 130.5354 - mse: 130.5354 - mae: 7.3024 - val_loss: 187.9532 - val_mse: 187.9532 - val_mae: 8.1788\n",
      "Epoch 104/250\n",
      "745/745 - 1s - loss: 129.3046 - mse: 129.3046 - mae: 7.2708 - val_loss: 180.8867 - val_mse: 180.8867 - val_mae: 8.3014\n",
      "Epoch 105/250\n",
      "745/745 - 1s - loss: 129.8830 - mse: 129.8830 - mae: 7.3084 - val_loss: 196.9969 - val_mse: 196.9969 - val_mae: 8.1579\n",
      "Epoch 106/250\n",
      "745/745 - 1s - loss: 129.3883 - mse: 129.3883 - mae: 7.2818 - val_loss: 182.5972 - val_mse: 182.5972 - val_mae: 8.1897\n",
      "Epoch 107/250\n",
      "745/745 - 1s - loss: 129.2113 - mse: 129.2113 - mae: 7.2779 - val_loss: 185.9810 - val_mse: 185.9810 - val_mae: 8.2612\n",
      "Epoch 108/250\n",
      "745/745 - 1s - loss: 129.2000 - mse: 129.2000 - mae: 7.3124 - val_loss: 186.4207 - val_mse: 186.4207 - val_mae: 8.2718\n",
      "Epoch 109/250\n",
      "745/745 - 1s - loss: 128.3194 - mse: 128.3194 - mae: 7.2394 - val_loss: 191.5811 - val_mse: 191.5811 - val_mae: 8.2278\n",
      "Epoch 110/250\n",
      "745/745 - 1s - loss: 128.1952 - mse: 128.1952 - mae: 7.2641 - val_loss: 185.7411 - val_mse: 185.7411 - val_mae: 8.1289\n",
      "Epoch 111/250\n",
      "745/745 - 1s - loss: 128.5492 - mse: 128.5492 - mae: 7.2417 - val_loss: 185.8776 - val_mse: 185.8776 - val_mae: 8.2010\n",
      "Epoch 112/250\n",
      "745/745 - 1s - loss: 127.4010 - mse: 127.4010 - mae: 7.2232 - val_loss: 191.9198 - val_mse: 191.9198 - val_mae: 8.1787\n",
      "Epoch 113/250\n",
      "745/745 - 1s - loss: 127.9100 - mse: 127.9100 - mae: 7.2274 - val_loss: 191.0890 - val_mse: 191.0890 - val_mae: 8.1142\n",
      "Epoch 114/250\n",
      "745/745 - 1s - loss: 127.4081 - mse: 127.4081 - mae: 7.2275 - val_loss: 185.4475 - val_mse: 185.4475 - val_mae: 8.0563\n",
      "Epoch 115/250\n",
      "745/745 - 1s - loss: 127.0955 - mse: 127.0955 - mae: 7.1948 - val_loss: 185.5574 - val_mse: 185.5574 - val_mae: 8.3411\n",
      "Epoch 116/250\n",
      "745/745 - 1s - loss: 126.5049 - mse: 126.5049 - mae: 7.2008 - val_loss: 190.0854 - val_mse: 190.0854 - val_mae: 8.1332\n",
      "Epoch 117/250\n",
      "745/745 - 1s - loss: 127.2227 - mse: 127.2227 - mae: 7.2188 - val_loss: 188.5975 - val_mse: 188.5975 - val_mae: 8.1378\n",
      "Epoch 118/250\n",
      "745/745 - 1s - loss: 126.7296 - mse: 126.7296 - mae: 7.1933 - val_loss: 188.6202 - val_mse: 188.6202 - val_mae: 8.2868\n",
      "Epoch 119/250\n",
      "745/745 - 1s - loss: 126.5444 - mse: 126.5444 - mae: 7.2005 - val_loss: 193.2405 - val_mse: 193.2405 - val_mae: 8.2419\n",
      "Epoch 120/250\n",
      "745/745 - 1s - loss: 126.5817 - mse: 126.5817 - mae: 7.1938 - val_loss: 196.1510 - val_mse: 196.1510 - val_mae: 8.1394\n",
      "Epoch 121/250\n",
      "745/745 - 1s - loss: 126.4186 - mse: 126.4186 - mae: 7.2050 - val_loss: 187.6407 - val_mse: 187.6407 - val_mae: 8.1243\n",
      "Epoch 122/250\n",
      "745/745 - 1s - loss: 126.4045 - mse: 126.4045 - mae: 7.1851 - val_loss: 192.8217 - val_mse: 192.8217 - val_mae: 8.1326\n",
      "Epoch 123/250\n",
      "745/745 - 1s - loss: 126.3031 - mse: 126.3031 - mae: 7.1872 - val_loss: 193.3714 - val_mse: 193.3714 - val_mae: 8.0994\n",
      "Epoch 124/250\n",
      "745/745 - 1s - loss: 125.3208 - mse: 125.3208 - mae: 7.1172 - val_loss: 191.1751 - val_mse: 191.1751 - val_mae: 8.2457\n",
      "Epoch 125/250\n",
      "745/745 - 1s - loss: 125.0870 - mse: 125.0870 - mae: 7.1376 - val_loss: 188.4324 - val_mse: 188.4324 - val_mae: 8.0595\n",
      "Epoch 126/250\n",
      "745/745 - 1s - loss: 125.2793 - mse: 125.2793 - mae: 7.1686 - val_loss: 190.5776 - val_mse: 190.5776 - val_mae: 8.3152\n",
      "Epoch 127/250\n",
      "745/745 - 1s - loss: 126.0794 - mse: 126.0794 - mae: 7.2078 - val_loss: 188.1608 - val_mse: 188.1608 - val_mae: 8.1820\n",
      "Epoch 128/250\n",
      "745/745 - 1s - loss: 125.0177 - mse: 125.0177 - mae: 7.1448 - val_loss: 184.8536 - val_mse: 184.8536 - val_mae: 8.2128\n",
      "Epoch 129/250\n",
      "745/745 - 1s - loss: 124.4181 - mse: 124.4181 - mae: 7.1279 - val_loss: 196.7353 - val_mse: 196.7353 - val_mae: 8.3846\n",
      "Epoch 130/250\n",
      "745/745 - 1s - loss: 124.2694 - mse: 124.2694 - mae: 7.1320 - val_loss: 192.0814 - val_mse: 192.0814 - val_mae: 8.1222\n",
      "Epoch 131/250\n",
      "745/745 - 1s - loss: 124.6949 - mse: 124.6949 - mae: 7.1242 - val_loss: 197.9505 - val_mse: 197.9505 - val_mae: 8.4697\n",
      "Epoch 132/250\n",
      "745/745 - 1s - loss: 124.7874 - mse: 124.7874 - mae: 7.1371 - val_loss: 197.1657 - val_mse: 197.1657 - val_mae: 8.1318\n",
      "Epoch 133/250\n",
      "745/745 - 1s - loss: 124.7791 - mse: 124.7791 - mae: 7.1406 - val_loss: 194.9244 - val_mse: 194.9244 - val_mae: 8.3503\n",
      "Epoch 134/250\n",
      "745/745 - 1s - loss: 123.8428 - mse: 123.8428 - mae: 7.1132 - val_loss: 194.7931 - val_mse: 194.7931 - val_mae: 8.0882\n",
      "Epoch 135/250\n",
      "745/745 - 1s - loss: 124.8395 - mse: 124.8395 - mae: 7.1337 - val_loss: 197.4353 - val_mse: 197.4353 - val_mae: 8.0473\n",
      "Epoch 136/250\n",
      "745/745 - 1s - loss: 124.0816 - mse: 124.0816 - mae: 7.1000 - val_loss: 199.0096 - val_mse: 199.0096 - val_mae: 8.2573\n",
      "Epoch 137/250\n",
      "745/745 - 1s - loss: 124.0456 - mse: 124.0456 - mae: 7.1151 - val_loss: 203.1969 - val_mse: 203.1969 - val_mae: 8.2800\n",
      "Epoch 138/250\n",
      "745/745 - 1s - loss: 123.1781 - mse: 123.1781 - mae: 7.1019 - val_loss: 195.1921 - val_mse: 195.1921 - val_mae: 8.3238\n",
      "Epoch 139/250\n",
      "745/745 - 1s - loss: 123.8554 - mse: 123.8554 - mae: 7.0905 - val_loss: 196.5524 - val_mse: 196.5524 - val_mae: 8.3154\n",
      "Epoch 140/250\n",
      "745/745 - 1s - loss: 123.2137 - mse: 123.2137 - mae: 7.0941 - val_loss: 206.3889 - val_mse: 206.3889 - val_mae: 8.1741\n",
      "Epoch 141/250\n",
      "745/745 - 1s - loss: 124.0785 - mse: 124.0785 - mae: 7.0955 - val_loss: 195.9844 - val_mse: 195.9844 - val_mae: 8.2931\n",
      "Epoch 142/250\n",
      "745/745 - 1s - loss: 123.1397 - mse: 123.1397 - mae: 7.0783 - val_loss: 197.0070 - val_mse: 197.0070 - val_mae: 8.0952\n",
      "Epoch 143/250\n",
      "745/745 - 1s - loss: 122.8749 - mse: 122.8749 - mae: 7.0501 - val_loss: 195.5992 - val_mse: 195.5992 - val_mae: 8.1577\n",
      "Epoch 144/250\n",
      "745/745 - 1s - loss: 122.8233 - mse: 122.8233 - mae: 7.0786 - val_loss: 203.1916 - val_mse: 203.1916 - val_mae: 8.3889\n",
      "Epoch 145/250\n",
      "745/745 - 1s - loss: 122.5100 - mse: 122.5100 - mae: 7.0692 - val_loss: 199.7068 - val_mse: 199.7068 - val_mae: 8.2253\n",
      "Epoch 146/250\n",
      "745/745 - 1s - loss: 122.7765 - mse: 122.7765 - mae: 7.0514 - val_loss: 203.8525 - val_mse: 203.8525 - val_mae: 8.4636\n",
      "Epoch 147/250\n",
      "745/745 - 1s - loss: 122.1348 - mse: 122.1348 - mae: 7.0577 - val_loss: 203.9642 - val_mse: 203.9642 - val_mae: 8.2650\n",
      "Epoch 148/250\n",
      "745/745 - 1s - loss: 122.6387 - mse: 122.6387 - mae: 7.0705 - val_loss: 196.8561 - val_mse: 196.8561 - val_mae: 8.0881\n",
      "Epoch 149/250\n",
      "745/745 - 1s - loss: 122.2879 - mse: 122.2879 - mae: 7.0297 - val_loss: 201.8322 - val_mse: 201.8322 - val_mae: 8.1543\n",
      "Epoch 150/250\n",
      "745/745 - 1s - loss: 122.0787 - mse: 122.0787 - mae: 7.0434 - val_loss: 204.8965 - val_mse: 204.8965 - val_mae: 8.0213\n",
      "Epoch 151/250\n",
      "745/745 - 1s - loss: 121.9625 - mse: 121.9625 - mae: 7.0268 - val_loss: 199.4839 - val_mse: 199.4839 - val_mae: 8.3057\n",
      "Epoch 152/250\n",
      "745/745 - 1s - loss: 121.8961 - mse: 121.8961 - mae: 7.0355 - val_loss: 205.7386 - val_mse: 205.7386 - val_mae: 8.0831\n",
      "Epoch 153/250\n",
      "745/745 - 1s - loss: 121.7448 - mse: 121.7448 - mae: 7.0205 - val_loss: 206.5355 - val_mse: 206.5355 - val_mae: 8.0445\n",
      "Epoch 154/250\n",
      "745/745 - 1s - loss: 121.8248 - mse: 121.8248 - mae: 7.0375 - val_loss: 211.1353 - val_mse: 211.1353 - val_mae: 8.0822\n",
      "Epoch 155/250\n",
      "745/745 - 1s - loss: 122.2025 - mse: 122.2025 - mae: 7.0398 - val_loss: 206.5676 - val_mse: 206.5676 - val_mae: 8.0579\n",
      "Epoch 156/250\n",
      "745/745 - 1s - loss: 122.2370 - mse: 122.2370 - mae: 7.0260 - val_loss: 201.3210 - val_mse: 201.3210 - val_mae: 8.1093\n",
      "Epoch 157/250\n",
      "745/745 - 1s - loss: 121.4077 - mse: 121.4077 - mae: 7.0161 - val_loss: 211.9786 - val_mse: 211.9786 - val_mae: 8.3117\n",
      "Epoch 158/250\n",
      "745/745 - 1s - loss: 122.1735 - mse: 122.1735 - mae: 7.0323 - val_loss: 211.3315 - val_mse: 211.3315 - val_mae: 8.0199\n",
      "Epoch 159/250\n",
      "745/745 - 1s - loss: 121.9812 - mse: 121.9812 - mae: 7.0279 - val_loss: 214.9681 - val_mse: 214.9681 - val_mae: 8.1189\n",
      "Epoch 160/250\n",
      "745/745 - 1s - loss: 121.1132 - mse: 121.1132 - mae: 6.9991 - val_loss: 210.1526 - val_mse: 210.1526 - val_mae: 8.1557\n",
      "Epoch 161/250\n",
      "745/745 - 1s - loss: 120.8392 - mse: 120.8392 - mae: 6.9903 - val_loss: 214.3533 - val_mse: 214.3533 - val_mae: 8.0246\n",
      "Epoch 162/250\n",
      "745/745 - 1s - loss: 121.5270 - mse: 121.5270 - mae: 7.0308 - val_loss: 206.5773 - val_mse: 206.5773 - val_mae: 8.1000\n",
      "Epoch 163/250\n",
      "745/745 - 1s - loss: 120.3619 - mse: 120.3619 - mae: 6.9805 - val_loss: 217.8421 - val_mse: 217.8421 - val_mae: 8.1210\n",
      "Epoch 164/250\n",
      "745/745 - 1s - loss: 121.0794 - mse: 121.0794 - mae: 6.9970 - val_loss: 205.5215 - val_mse: 205.5215 - val_mae: 8.0713\n",
      "Epoch 165/250\n",
      "745/745 - 1s - loss: 120.6079 - mse: 120.6079 - mae: 7.0006 - val_loss: 208.1543 - val_mse: 208.1543 - val_mae: 8.0795\n",
      "Epoch 166/250\n",
      "745/745 - 1s - loss: 120.5111 - mse: 120.5111 - mae: 6.9907 - val_loss: 205.4711 - val_mse: 205.4711 - val_mae: 8.2047\n",
      "Epoch 167/250\n",
      "745/745 - 1s - loss: 120.6656 - mse: 120.6656 - mae: 6.9926 - val_loss: 208.5352 - val_mse: 208.5352 - val_mae: 8.1546\n",
      "Epoch 168/250\n",
      "745/745 - 1s - loss: 120.7261 - mse: 120.7261 - mae: 6.9863 - val_loss: 214.3159 - val_mse: 214.3159 - val_mae: 8.1306\n",
      "Epoch 169/250\n",
      "745/745 - 1s - loss: 120.0906 - mse: 120.0906 - mae: 6.9969 - val_loss: 209.0721 - val_mse: 209.0721 - val_mae: 8.3806\n",
      "Epoch 170/250\n",
      "745/745 - 1s - loss: 120.1779 - mse: 120.1779 - mae: 6.9962 - val_loss: 216.8992 - val_mse: 216.8992 - val_mae: 8.0905\n",
      "Epoch 171/250\n",
      "745/745 - 1s - loss: 119.4058 - mse: 119.4058 - mae: 6.9622 - val_loss: 215.8223 - val_mse: 215.8223 - val_mae: 8.0561\n",
      "Epoch 172/250\n",
      "745/745 - 1s - loss: 119.8586 - mse: 119.8586 - mae: 6.9627 - val_loss: 215.4607 - val_mse: 215.4607 - val_mae: 8.0684\n",
      "Epoch 173/250\n",
      "745/745 - 1s - loss: 119.3186 - mse: 119.3186 - mae: 6.9532 - val_loss: 216.4383 - val_mse: 216.4383 - val_mae: 8.0306\n",
      "Epoch 174/250\n",
      "745/745 - 1s - loss: 118.8225 - mse: 118.8225 - mae: 6.9616 - val_loss: 212.6839 - val_mse: 212.6839 - val_mae: 8.0983\n",
      "Epoch 175/250\n",
      "745/745 - 1s - loss: 118.7296 - mse: 118.7296 - mae: 6.9072 - val_loss: 221.3452 - val_mse: 221.3452 - val_mae: 8.0907\n",
      "Epoch 176/250\n",
      "745/745 - 1s - loss: 118.3091 - mse: 118.3091 - mae: 6.9289 - val_loss: 214.3233 - val_mse: 214.3233 - val_mae: 8.3149\n",
      "Epoch 177/250\n",
      "745/745 - 1s - loss: 118.6976 - mse: 118.6976 - mae: 6.9499 - val_loss: 206.7255 - val_mse: 206.7255 - val_mae: 8.2940\n",
      "Epoch 178/250\n",
      "745/745 - 1s - loss: 118.9041 - mse: 118.9041 - mae: 6.9458 - val_loss: 211.5299 - val_mse: 211.5299 - val_mae: 8.1146\n",
      "Epoch 179/250\n",
      "745/745 - 1s - loss: 119.1998 - mse: 119.1998 - mae: 6.9624 - val_loss: 224.0932 - val_mse: 224.0932 - val_mae: 8.0937\n",
      "Epoch 180/250\n",
      "745/745 - 1s - loss: 118.2171 - mse: 118.2171 - mae: 6.9382 - val_loss: 215.4455 - val_mse: 215.4455 - val_mae: 8.0144\n",
      "Epoch 181/250\n",
      "745/745 - 1s - loss: 118.2516 - mse: 118.2516 - mae: 6.9264 - val_loss: 228.4261 - val_mse: 228.4261 - val_mae: 8.0537\n",
      "Epoch 182/250\n",
      "745/745 - 1s - loss: 118.0675 - mse: 118.0675 - mae: 6.9161 - val_loss: 220.8936 - val_mse: 220.8936 - val_mae: 8.0477\n",
      "Epoch 183/250\n",
      "745/745 - 1s - loss: 117.7531 - mse: 117.7531 - mae: 6.9179 - val_loss: 215.7039 - val_mse: 215.7039 - val_mae: 8.1931\n",
      "Epoch 184/250\n",
      "745/745 - 1s - loss: 118.2106 - mse: 118.2106 - mae: 6.9408 - val_loss: 208.7003 - val_mse: 208.7003 - val_mae: 8.2936\n",
      "Epoch 185/250\n",
      "745/745 - 1s - loss: 117.5284 - mse: 117.5284 - mae: 6.9110 - val_loss: 213.9343 - val_mse: 213.9343 - val_mae: 8.2670\n",
      "Epoch 186/250\n",
      "745/745 - 1s - loss: 118.0115 - mse: 118.0115 - mae: 6.9394 - val_loss: 224.0377 - val_mse: 224.0377 - val_mae: 7.9910\n",
      "Epoch 187/250\n",
      "745/745 - 1s - loss: 117.3552 - mse: 117.3552 - mae: 6.8886 - val_loss: 210.8231 - val_mse: 210.8231 - val_mae: 8.0298\n",
      "Epoch 188/250\n",
      "745/745 - 1s - loss: 117.6220 - mse: 117.6220 - mae: 6.9304 - val_loss: 218.5760 - val_mse: 218.5760 - val_mae: 8.3710\n",
      "Epoch 189/250\n",
      "745/745 - 1s - loss: 116.9012 - mse: 116.9012 - mae: 6.8846 - val_loss: 215.0820 - val_mse: 215.0820 - val_mae: 8.1297\n",
      "Epoch 190/250\n",
      "745/745 - 1s - loss: 117.3151 - mse: 117.3151 - mae: 6.8759 - val_loss: 219.0042 - val_mse: 219.0042 - val_mae: 8.3132\n",
      "Epoch 191/250\n",
      "745/745 - 1s - loss: 117.5321 - mse: 117.5321 - mae: 6.9125 - val_loss: 216.3819 - val_mse: 216.3819 - val_mae: 8.0043\n",
      "Epoch 192/250\n",
      "745/745 - 1s - loss: 117.2477 - mse: 117.2477 - mae: 6.8898 - val_loss: 219.4670 - val_mse: 219.4670 - val_mae: 8.0413\n",
      "Epoch 193/250\n",
      "745/745 - 1s - loss: 117.0989 - mse: 117.0989 - mae: 6.8698 - val_loss: 221.3493 - val_mse: 221.3493 - val_mae: 8.1934\n",
      "Epoch 194/250\n",
      "745/745 - 1s - loss: 116.5130 - mse: 116.5130 - mae: 6.8761 - val_loss: 228.2055 - val_mse: 228.2055 - val_mae: 8.0622\n",
      "Epoch 195/250\n",
      "745/745 - 1s - loss: 116.0120 - mse: 116.0120 - mae: 6.8530 - val_loss: 215.5925 - val_mse: 215.5925 - val_mae: 7.9742\n",
      "Epoch 196/250\n",
      "745/745 - 1s - loss: 116.4335 - mse: 116.4335 - mae: 6.8875 - val_loss: 214.8543 - val_mse: 214.8543 - val_mae: 8.1231\n",
      "Epoch 197/250\n",
      "745/745 - 1s - loss: 116.9376 - mse: 116.9376 - mae: 6.8913 - val_loss: 218.2932 - val_mse: 218.2932 - val_mae: 8.1532\n",
      "Epoch 198/250\n",
      "745/745 - 1s - loss: 116.1201 - mse: 116.1201 - mae: 6.8964 - val_loss: 224.7552 - val_mse: 224.7552 - val_mae: 7.9704\n",
      "Epoch 199/250\n",
      "745/745 - 1s - loss: 117.0073 - mse: 117.0073 - mae: 6.8738 - val_loss: 216.6685 - val_mse: 216.6685 - val_mae: 7.9910\n",
      "Epoch 200/250\n",
      "745/745 - 1s - loss: 116.4498 - mse: 116.4498 - mae: 6.8676 - val_loss: 226.5165 - val_mse: 226.5165 - val_mae: 8.0053\n",
      "Epoch 201/250\n",
      "745/745 - 1s - loss: 115.7876 - mse: 115.7876 - mae: 6.8522 - val_loss: 221.3602 - val_mse: 221.3602 - val_mae: 8.0492\n",
      "Epoch 202/250\n",
      "745/745 - 1s - loss: 116.2445 - mse: 116.2445 - mae: 6.8520 - val_loss: 214.5246 - val_mse: 214.5246 - val_mae: 8.0585\n",
      "Epoch 203/250\n",
      "745/745 - 1s - loss: 116.2729 - mse: 116.2729 - mae: 6.8651 - val_loss: 217.9005 - val_mse: 217.9005 - val_mae: 8.7333\n",
      "Epoch 204/250\n",
      "745/745 - 1s - loss: 116.3945 - mse: 116.3945 - mae: 6.8767 - val_loss: 219.7876 - val_mse: 219.7876 - val_mae: 7.9967\n",
      "Epoch 205/250\n",
      "745/745 - 1s - loss: 115.6210 - mse: 115.6210 - mae: 6.8514 - val_loss: 215.1532 - val_mse: 215.1532 - val_mae: 7.9403\n",
      "Epoch 206/250\n",
      "745/745 - 1s - loss: 116.5659 - mse: 116.5659 - mae: 6.8708 - val_loss: 216.2530 - val_mse: 216.2530 - val_mae: 8.1911\n",
      "Epoch 207/250\n",
      "745/745 - 1s - loss: 116.0162 - mse: 116.0162 - mae: 6.8664 - val_loss: 210.8860 - val_mse: 210.8860 - val_mae: 8.1120\n",
      "Epoch 208/250\n",
      "745/745 - 1s - loss: 115.3892 - mse: 115.3892 - mae: 6.8257 - val_loss: 213.9281 - val_mse: 213.9281 - val_mae: 8.1682\n",
      "Epoch 209/250\n",
      "745/745 - 1s - loss: 115.5693 - mse: 115.5693 - mae: 6.8481 - val_loss: 225.5880 - val_mse: 225.5880 - val_mae: 8.0525\n",
      "Epoch 210/250\n",
      "745/745 - 1s - loss: 115.2381 - mse: 115.2381 - mae: 6.8465 - val_loss: 211.4884 - val_mse: 211.4884 - val_mae: 8.0162\n",
      "Epoch 211/250\n",
      "745/745 - 1s - loss: 115.6504 - mse: 115.6504 - mae: 6.8389 - val_loss: 210.4106 - val_mse: 210.4106 - val_mae: 8.0658\n",
      "Epoch 212/250\n",
      "745/745 - 1s - loss: 115.2540 - mse: 115.2540 - mae: 6.8285 - val_loss: 211.6642 - val_mse: 211.6642 - val_mae: 7.9470\n",
      "Epoch 213/250\n",
      "745/745 - 1s - loss: 114.8959 - mse: 114.8959 - mae: 6.8177 - val_loss: 217.3342 - val_mse: 217.3342 - val_mae: 8.3001\n",
      "Epoch 214/250\n",
      "745/745 - 1s - loss: 115.0589 - mse: 115.0589 - mae: 6.8114 - val_loss: 219.0423 - val_mse: 219.0423 - val_mae: 7.8896\n",
      "Epoch 215/250\n",
      "745/745 - 1s - loss: 115.4651 - mse: 115.4651 - mae: 6.8278 - val_loss: 219.0541 - val_mse: 219.0541 - val_mae: 8.0735\n",
      "Epoch 216/250\n",
      "745/745 - 1s - loss: 115.5424 - mse: 115.5424 - mae: 6.8381 - val_loss: 210.2740 - val_mse: 210.2740 - val_mae: 7.9700\n",
      "Epoch 217/250\n",
      "745/745 - 1s - loss: 115.0202 - mse: 115.0202 - mae: 6.8207 - val_loss: 215.5436 - val_mse: 215.5436 - val_mae: 8.6217\n",
      "Epoch 218/250\n",
      "745/745 - 1s - loss: 115.0484 - mse: 115.0484 - mae: 6.8147 - val_loss: 209.7237 - val_mse: 209.7237 - val_mae: 8.0712\n",
      "Epoch 219/250\n",
      "745/745 - 1s - loss: 114.1576 - mse: 114.1576 - mae: 6.7982 - val_loss: 215.4742 - val_mse: 215.4742 - val_mae: 8.1785\n",
      "Epoch 220/250\n",
      "745/745 - 1s - loss: 115.2713 - mse: 115.2713 - mae: 6.8312 - val_loss: 222.1306 - val_mse: 222.1306 - val_mae: 8.1025\n",
      "Epoch 221/250\n",
      "745/745 - 1s - loss: 114.6181 - mse: 114.6181 - mae: 6.8247 - val_loss: 212.2132 - val_mse: 212.2132 - val_mae: 7.9302\n",
      "Epoch 222/250\n",
      "745/745 - 1s - loss: 113.2045 - mse: 113.2045 - mae: 6.7700 - val_loss: 223.3401 - val_mse: 223.3401 - val_mae: 8.0932\n",
      "Epoch 223/250\n",
      "745/745 - 1s - loss: 115.0060 - mse: 115.0060 - mae: 6.8106 - val_loss: 219.5753 - val_mse: 219.5753 - val_mae: 7.9858\n",
      "Epoch 224/250\n",
      "745/745 - 1s - loss: 114.6031 - mse: 114.6031 - mae: 6.8072 - val_loss: 213.0871 - val_mse: 213.0871 - val_mae: 7.9420\n",
      "Epoch 225/250\n",
      "745/745 - 1s - loss: 115.1185 - mse: 115.1185 - mae: 6.8435 - val_loss: 222.6712 - val_mse: 222.6712 - val_mae: 7.9357\n",
      "Epoch 226/250\n",
      "745/745 - 1s - loss: 114.2782 - mse: 114.2782 - mae: 6.7969 - val_loss: 220.5712 - val_mse: 220.5712 - val_mae: 8.0011\n",
      "Epoch 227/250\n",
      "745/745 - 1s - loss: 114.4140 - mse: 114.4140 - mae: 6.7937 - val_loss: 211.1782 - val_mse: 211.1782 - val_mae: 8.0924\n",
      "Epoch 228/250\n",
      "745/745 - 1s - loss: 114.1056 - mse: 114.1056 - mae: 6.8017 - val_loss: 210.6932 - val_mse: 210.6932 - val_mae: 7.9140\n",
      "Epoch 229/250\n",
      "745/745 - 1s - loss: 113.5787 - mse: 113.5787 - mae: 6.7796 - val_loss: 225.7443 - val_mse: 225.7443 - val_mae: 8.1521\n",
      "Epoch 230/250\n",
      "745/745 - 1s - loss: 114.2965 - mse: 114.2965 - mae: 6.8163 - val_loss: 220.8809 - val_mse: 220.8809 - val_mae: 7.9665\n",
      "Epoch 231/250\n",
      "745/745 - 1s - loss: 113.3685 - mse: 113.3685 - mae: 6.7742 - val_loss: 237.0186 - val_mse: 237.0186 - val_mae: 8.2341\n",
      "Epoch 232/250\n",
      "745/745 - 1s - loss: 113.9753 - mse: 113.9753 - mae: 6.7900 - val_loss: 212.7883 - val_mse: 212.7883 - val_mae: 8.2449\n",
      "Epoch 233/250\n",
      "745/745 - 1s - loss: 113.7296 - mse: 113.7296 - mae: 6.7763 - val_loss: 211.5091 - val_mse: 211.5091 - val_mae: 7.9015\n",
      "Epoch 234/250\n",
      "745/745 - 1s - loss: 113.8360 - mse: 113.8360 - mae: 6.7925 - val_loss: 213.9626 - val_mse: 213.9626 - val_mae: 7.9553\n",
      "Epoch 235/250\n",
      "745/745 - 1s - loss: 113.3531 - mse: 113.3531 - mae: 6.7648 - val_loss: 219.3138 - val_mse: 219.3138 - val_mae: 7.9460\n",
      "Epoch 236/250\n",
      "745/745 - 1s - loss: 114.3678 - mse: 114.3678 - mae: 6.8041 - val_loss: 216.3050 - val_mse: 216.3050 - val_mae: 8.1176\n",
      "Epoch 237/250\n",
      "745/745 - 1s - loss: 113.8845 - mse: 113.8845 - mae: 6.7904 - val_loss: 219.4635 - val_mse: 219.4635 - val_mae: 7.9352\n",
      "Epoch 238/250\n",
      "745/745 - 1s - loss: 112.7052 - mse: 112.7052 - mae: 6.7665 - val_loss: 213.8871 - val_mse: 213.8871 - val_mae: 7.9013\n",
      "Epoch 239/250\n",
      "745/745 - 1s - loss: 113.7429 - mse: 113.7429 - mae: 6.7962 - val_loss: 214.0663 - val_mse: 214.0663 - val_mae: 8.3656\n",
      "Epoch 240/250\n",
      "745/745 - 1s - loss: 114.1635 - mse: 114.1635 - mae: 6.7791 - val_loss: 216.9462 - val_mse: 216.9462 - val_mae: 8.8019\n",
      "Epoch 241/250\n",
      "745/745 - 1s - loss: 112.9903 - mse: 112.9903 - mae: 6.7492 - val_loss: 210.6833 - val_mse: 210.6833 - val_mae: 8.0865\n",
      "Epoch 242/250\n",
      "745/745 - 1s - loss: 113.0203 - mse: 113.0203 - mae: 6.7580 - val_loss: 212.6067 - val_mse: 212.6067 - val_mae: 8.1037\n",
      "Epoch 243/250\n",
      "745/745 - 1s - loss: 112.7695 - mse: 112.7695 - mae: 6.7752 - val_loss: 227.8114 - val_mse: 227.8114 - val_mae: 7.9517\n",
      "Epoch 244/250\n",
      "745/745 - 1s - loss: 112.6851 - mse: 112.6851 - mae: 6.7407 - val_loss: 219.4599 - val_mse: 219.4599 - val_mae: 8.1909\n",
      "Epoch 245/250\n",
      "745/745 - 1s - loss: 112.4456 - mse: 112.4456 - mae: 6.7666 - val_loss: 220.8007 - val_mse: 220.8007 - val_mae: 9.0431\n",
      "Epoch 246/250\n",
      "745/745 - 1s - loss: 113.1286 - mse: 113.1286 - mae: 6.7576 - val_loss: 203.4583 - val_mse: 203.4583 - val_mae: 8.0618\n",
      "Epoch 247/250\n",
      "745/745 - 1s - loss: 112.7677 - mse: 112.7677 - mae: 6.7454 - val_loss: 216.4536 - val_mse: 216.4536 - val_mae: 7.9312\n",
      "Epoch 248/250\n",
      "745/745 - 1s - loss: 112.5120 - mse: 112.5120 - mae: 6.7778 - val_loss: 213.8816 - val_mse: 213.8816 - val_mae: 7.8908\n",
      "Epoch 249/250\n",
      "745/745 - 1s - loss: 112.5996 - mse: 112.5996 - mae: 6.7570 - val_loss: 203.7895 - val_mse: 203.7895 - val_mae: 7.9625\n",
      "Epoch 250/250\n",
      "745/745 - 1s - loss: 112.8362 - mse: 112.8362 - mae: 6.7498 - val_loss: 219.9896 - val_mse: 219.9896 - val_mae: 8.0291\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_sc, y_train, epochs = 250, batch_size = 16, verbose = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cc2b20c160>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(metrics.mean_squared_error(y_test,y_preds))\n",
    "mae = metrics.mean_absolute_error(y_test,y_preds)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test,y_preds)\n",
    "ex_var = metrics.explained_variance_score(y_test,y_preds)\n",
    "r2_score = metrics.r2_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error:\t23.01 Kelvins\n",
      "Mean Absolute Error:\t\t8.57 Kelvins\n",
      "Mean Abs. Percent Error:\t6.44%\n",
      "Explained Variance Score:\t0.5536\n",
      "R2 Score:\t\t\t0.5536\n"
     ]
    }
   ],
   "source": [
    "print(f\"Root Mean Squared Error:\t{np.round(rmse,2)} Kelvins\")\n",
    "print(f\"Mean Absolute Error:\t\t{np.round(mae,2)} Kelvins\")\n",
    "print(f\"Mean Abs. Percent Error:\t{np.round(mape,2)}%\")\n",
    "print(f\"Explained Variance Score:\t{np.round(ex_var,4)}\")\n",
    "print(f\"R2 Score:\t\t\t{np.round(r2_score,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "##### (still part 2)\n",
    "\n",
    "Let's reduce the number of dimensions and see what effect it has on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.95)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate PCA with enough dimensions to capture 95% of explained variance\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features is reduced from 86 to 65\n"
     ]
    }
   ],
   "source": [
    "X_train_pca = pca.transform(X_train_sc)\n",
    "X_test_pca = pca.transform(X_test_sc)\n",
    "\n",
    "print(f\"The number of features is reduced from {X_train_sc.shape[1]} to {X_train_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                2112      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,657\n",
      "Trainable params: 2,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_dim = X_train_pca.shape[1], activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "745/745 - 2s - loss: 1073.8600 - mse: 1073.8600 - mae: 21.8428 - val_loss: 525.5934 - val_mse: 525.5934 - val_mae: 15.8225\n",
      "Epoch 2/250\n",
      "745/745 - 1s - loss: 478.6841 - mse: 478.6841 - mae: 15.0417 - val_loss: 458.6813 - val_mse: 458.6813 - val_mae: 15.0633\n",
      "Epoch 3/250\n",
      "745/745 - 1s - loss: 411.6725 - mse: 411.6725 - mae: 14.0128 - val_loss: 407.0152 - val_mse: 407.0152 - val_mae: 14.2750\n",
      "Epoch 4/250\n",
      "745/745 - 1s - loss: 357.1116 - mse: 357.1116 - mae: 13.0963 - val_loss: 353.0217 - val_mse: 353.0217 - val_mae: 13.2888\n",
      "Epoch 5/250\n",
      "745/745 - 1s - loss: 312.4359 - mse: 312.4359 - mae: 12.4099 - val_loss: 322.5935 - val_mse: 322.5935 - val_mae: 12.6369\n",
      "Epoch 6/250\n",
      "745/745 - 1s - loss: 286.1377 - mse: 286.1377 - mae: 11.9612 - val_loss: 300.2783 - val_mse: 300.2783 - val_mae: 12.4806\n",
      "Epoch 7/250\n",
      "745/745 - 1s - loss: 269.1266 - mse: 269.1266 - mae: 11.5987 - val_loss: 284.4467 - val_mse: 284.4467 - val_mae: 12.0305\n",
      "Epoch 8/250\n",
      "745/745 - 1s - loss: 260.7072 - mse: 260.7072 - mae: 11.4116 - val_loss: 278.5815 - val_mse: 278.5815 - val_mae: 11.9185\n",
      "Epoch 9/250\n",
      "745/745 - 1s - loss: 249.7833 - mse: 249.7833 - mae: 11.1729 - val_loss: 271.6723 - val_mse: 271.6723 - val_mae: 11.8081\n",
      "Epoch 10/250\n",
      "745/745 - 1s - loss: 243.1025 - mse: 243.1025 - mae: 11.0410 - val_loss: 271.9058 - val_mse: 271.9058 - val_mae: 11.5726\n",
      "Epoch 11/250\n",
      "745/745 - 1s - loss: 237.7954 - mse: 237.7954 - mae: 10.8940 - val_loss: 259.3062 - val_mse: 259.3062 - val_mae: 11.4190\n",
      "Epoch 12/250\n",
      "745/745 - 1s - loss: 233.5690 - mse: 233.5690 - mae: 10.7768 - val_loss: 258.3792 - val_mse: 258.3792 - val_mae: 11.4111\n",
      "Epoch 13/250\n",
      "745/745 - 1s - loss: 231.5476 - mse: 231.5476 - mae: 10.6787 - val_loss: 255.9621 - val_mse: 255.9621 - val_mae: 11.3460\n",
      "Epoch 14/250\n",
      "745/745 - 1s - loss: 225.8527 - mse: 225.8527 - mae: 10.5874 - val_loss: 246.1968 - val_mse: 246.1968 - val_mae: 11.0400\n",
      "Epoch 15/250\n",
      "745/745 - 1s - loss: 221.9463 - mse: 221.9463 - mae: 10.4709 - val_loss: 253.8163 - val_mse: 253.8163 - val_mae: 11.0264\n",
      "Epoch 16/250\n",
      "745/745 - 1s - loss: 217.8893 - mse: 217.8893 - mae: 10.3298 - val_loss: 242.3155 - val_mse: 242.3155 - val_mae: 10.9152\n",
      "Epoch 17/250\n",
      "745/745 - 1s - loss: 214.7410 - mse: 214.7410 - mae: 10.2611 - val_loss: 239.5459 - val_mse: 239.5459 - val_mae: 10.7908\n",
      "Epoch 18/250\n",
      "745/745 - 1s - loss: 213.4219 - mse: 213.4219 - mae: 10.1817 - val_loss: 240.3799 - val_mse: 240.3799 - val_mae: 10.7872\n",
      "Epoch 19/250\n",
      "745/745 - 1s - loss: 208.9924 - mse: 208.9924 - mae: 10.0926 - val_loss: 233.7287 - val_mse: 233.7287 - val_mae: 10.5812\n",
      "Epoch 20/250\n",
      "745/745 - 1s - loss: 206.2840 - mse: 206.2840 - mae: 10.0115 - val_loss: 231.8606 - val_mse: 231.8606 - val_mae: 10.5882\n",
      "Epoch 21/250\n",
      "745/745 - 1s - loss: 203.4457 - mse: 203.4457 - mae: 9.9337 - val_loss: 231.2304 - val_mse: 231.2304 - val_mae: 10.5292\n",
      "Epoch 22/250\n",
      "745/745 - 1s - loss: 202.1259 - mse: 202.1259 - mae: 9.8728 - val_loss: 229.0774 - val_mse: 229.0774 - val_mae: 10.5241\n",
      "Epoch 23/250\n",
      "745/745 - 1s - loss: 199.5625 - mse: 199.5625 - mae: 9.8037 - val_loss: 227.5932 - val_mse: 227.5932 - val_mae: 10.3530\n",
      "Epoch 24/250\n",
      "745/745 - 1s - loss: 197.0979 - mse: 197.0979 - mae: 9.7308 - val_loss: 225.0975 - val_mse: 225.0975 - val_mae: 10.4300\n",
      "Epoch 25/250\n",
      "745/745 - 1s - loss: 198.0268 - mse: 198.0268 - mae: 9.7040 - val_loss: 221.2666 - val_mse: 221.2666 - val_mae: 10.2414\n",
      "Epoch 26/250\n",
      "745/745 - 1s - loss: 192.6827 - mse: 192.6827 - mae: 9.6089 - val_loss: 221.0826 - val_mse: 221.0826 - val_mae: 10.2508\n",
      "Epoch 27/250\n",
      "745/745 - 1s - loss: 190.2857 - mse: 190.2857 - mae: 9.5298 - val_loss: 224.3434 - val_mse: 224.3434 - val_mae: 10.1706\n",
      "Epoch 28/250\n",
      "745/745 - 1s - loss: 189.6958 - mse: 189.6958 - mae: 9.5310 - val_loss: 217.8806 - val_mse: 217.8806 - val_mae: 10.1900\n",
      "Epoch 29/250\n",
      "745/745 - 1s - loss: 188.4335 - mse: 188.4335 - mae: 9.4596 - val_loss: 214.3237 - val_mse: 214.3237 - val_mae: 10.1412\n",
      "Epoch 30/250\n",
      "745/745 - 1s - loss: 188.0661 - mse: 188.0661 - mae: 9.4251 - val_loss: 215.3394 - val_mse: 215.3394 - val_mae: 10.1855\n",
      "Epoch 31/250\n",
      "745/745 - 1s - loss: 187.4208 - mse: 187.4208 - mae: 9.4117 - val_loss: 214.0554 - val_mse: 214.0554 - val_mae: 9.9219\n",
      "Epoch 32/250\n",
      "745/745 - 1s - loss: 184.6167 - mse: 184.6167 - mae: 9.3276 - val_loss: 212.4705 - val_mse: 212.4705 - val_mae: 10.0073\n",
      "Epoch 33/250\n",
      "745/745 - 1s - loss: 183.8136 - mse: 183.8136 - mae: 9.3141 - val_loss: 217.5998 - val_mse: 217.5998 - val_mae: 10.1360\n",
      "Epoch 34/250\n",
      "745/745 - 1s - loss: 181.3639 - mse: 181.3639 - mae: 9.2595 - val_loss: 219.4362 - val_mse: 219.4362 - val_mae: 10.0862\n",
      "Epoch 35/250\n",
      "745/745 - 1s - loss: 180.4751 - mse: 180.4751 - mae: 9.1982 - val_loss: 210.4534 - val_mse: 210.4534 - val_mae: 9.9444\n",
      "Epoch 36/250\n",
      "745/745 - 1s - loss: 183.4160 - mse: 183.4160 - mae: 9.2531 - val_loss: 214.5451 - val_mse: 214.5451 - val_mae: 10.1582\n",
      "Epoch 37/250\n",
      "745/745 - 1s - loss: 179.4212 - mse: 179.4212 - mae: 9.1491 - val_loss: 211.6880 - val_mse: 211.6880 - val_mae: 9.8924\n",
      "Epoch 38/250\n",
      "745/745 - 1s - loss: 179.4639 - mse: 179.4639 - mae: 9.1893 - val_loss: 206.2708 - val_mse: 206.2708 - val_mae: 9.7864\n",
      "Epoch 39/250\n",
      "745/745 - 1s - loss: 177.7397 - mse: 177.7397 - mae: 9.1362 - val_loss: 203.5266 - val_mse: 203.5266 - val_mae: 9.8260\n",
      "Epoch 40/250\n",
      "745/745 - 1s - loss: 176.8221 - mse: 176.8221 - mae: 9.0923 - val_loss: 204.8911 - val_mse: 204.8911 - val_mae: 9.6901\n",
      "Epoch 41/250\n",
      "745/745 - 1s - loss: 175.9881 - mse: 175.9881 - mae: 9.1010 - val_loss: 208.3832 - val_mse: 208.3832 - val_mae: 9.9224\n",
      "Epoch 42/250\n",
      "745/745 - 1s - loss: 173.5598 - mse: 173.5598 - mae: 9.0220 - val_loss: 205.9457 - val_mse: 205.9457 - val_mae: 9.7292\n",
      "Epoch 43/250\n",
      "745/745 - 1s - loss: 176.0602 - mse: 176.0602 - mae: 9.0189 - val_loss: 208.1858 - val_mse: 208.1858 - val_mae: 9.8202\n",
      "Epoch 44/250\n",
      "745/745 - 1s - loss: 172.5591 - mse: 172.5591 - mae: 8.9771 - val_loss: 202.9974 - val_mse: 202.9974 - val_mae: 9.6712\n",
      "Epoch 45/250\n",
      "745/745 - 1s - loss: 171.6934 - mse: 171.6934 - mae: 8.9227 - val_loss: 209.3901 - val_mse: 209.3901 - val_mae: 9.7957\n",
      "Epoch 46/250\n",
      "745/745 - 1s - loss: 173.1225 - mse: 173.1225 - mae: 8.9464 - val_loss: 203.5787 - val_mse: 203.5787 - val_mae: 9.6460\n",
      "Epoch 47/250\n",
      "745/745 - 1s - loss: 172.6996 - mse: 172.6996 - mae: 8.9463 - val_loss: 206.7505 - val_mse: 206.7505 - val_mae: 9.7669\n",
      "Epoch 48/250\n",
      "745/745 - 1s - loss: 172.1789 - mse: 172.1789 - mae: 8.8961 - val_loss: 207.2083 - val_mse: 207.2083 - val_mae: 9.9036\n",
      "Epoch 49/250\n",
      "745/745 - 1s - loss: 170.6283 - mse: 170.6283 - mae: 8.9240 - val_loss: 199.3803 - val_mse: 199.3803 - val_mae: 9.5816\n",
      "Epoch 50/250\n",
      "745/745 - 1s - loss: 168.5861 - mse: 168.5861 - mae: 8.8613 - val_loss: 202.6880 - val_mse: 202.6880 - val_mae: 9.5490\n",
      "Epoch 51/250\n",
      "745/745 - 1s - loss: 168.6070 - mse: 168.6070 - mae: 8.8183 - val_loss: 207.2289 - val_mse: 207.2289 - val_mae: 9.8789\n",
      "Epoch 52/250\n",
      "745/745 - 1s - loss: 176.7329 - mse: 176.7329 - mae: 8.8750 - val_loss: 204.8809 - val_mse: 204.8809 - val_mae: 9.7316\n",
      "Epoch 53/250\n",
      "745/745 - 1s - loss: 168.1638 - mse: 168.1638 - mae: 8.7896 - val_loss: 210.7775 - val_mse: 210.7775 - val_mae: 9.6800\n",
      "Epoch 54/250\n",
      "745/745 - 1s - loss: 167.5956 - mse: 167.5956 - mae: 8.7957 - val_loss: 208.8711 - val_mse: 208.8711 - val_mae: 9.6935\n",
      "Epoch 55/250\n",
      "745/745 - 1s - loss: 166.7073 - mse: 166.7073 - mae: 8.7481 - val_loss: 206.4412 - val_mse: 206.4412 - val_mae: 9.8406\n",
      "Epoch 56/250\n",
      "745/745 - 1s - loss: 168.0713 - mse: 168.0713 - mae: 8.7830 - val_loss: 203.0135 - val_mse: 203.0135 - val_mae: 9.5427\n",
      "Epoch 57/250\n",
      "745/745 - 1s - loss: 166.6634 - mse: 166.6634 - mae: 8.7442 - val_loss: 210.5532 - val_mse: 210.5532 - val_mae: 9.6571\n",
      "Epoch 58/250\n",
      "745/745 - 1s - loss: 166.7983 - mse: 166.7983 - mae: 8.7490 - val_loss: 205.3200 - val_mse: 205.3200 - val_mae: 9.5736\n",
      "Epoch 59/250\n",
      "745/745 - 1s - loss: 165.6688 - mse: 165.6688 - mae: 8.6897 - val_loss: 203.1166 - val_mse: 203.1166 - val_mae: 9.5857\n",
      "Epoch 60/250\n",
      "745/745 - 1s - loss: 163.7763 - mse: 163.7763 - mae: 8.6972 - val_loss: 206.5157 - val_mse: 206.5157 - val_mae: 9.6455\n",
      "Epoch 61/250\n",
      "745/745 - 1s - loss: 163.3204 - mse: 163.3204 - mae: 8.6557 - val_loss: 206.2700 - val_mse: 206.2700 - val_mae: 9.5036\n",
      "Epoch 62/250\n",
      "745/745 - 1s - loss: 163.4669 - mse: 163.4669 - mae: 8.6850 - val_loss: 204.7957 - val_mse: 204.7957 - val_mae: 9.6047\n",
      "Epoch 63/250\n",
      "745/745 - 1s - loss: 162.9296 - mse: 162.9296 - mae: 8.6502 - val_loss: 214.0763 - val_mse: 214.0763 - val_mae: 9.7382\n",
      "Epoch 64/250\n",
      "745/745 - 1s - loss: 163.2025 - mse: 163.2025 - mae: 8.6517 - val_loss: 201.7043 - val_mse: 201.7043 - val_mae: 9.4268\n",
      "Epoch 65/250\n",
      "745/745 - 1s - loss: 162.5452 - mse: 162.5452 - mae: 8.6584 - val_loss: 205.9528 - val_mse: 205.9528 - val_mae: 9.7947\n",
      "Epoch 66/250\n",
      "745/745 - 1s - loss: 161.2507 - mse: 161.2507 - mae: 8.6103 - val_loss: 203.2108 - val_mse: 203.2108 - val_mae: 9.4624\n",
      "Epoch 67/250\n",
      "745/745 - 1s - loss: 162.6115 - mse: 162.6115 - mae: 8.6105 - val_loss: 202.9070 - val_mse: 202.9070 - val_mae: 9.5094\n",
      "Epoch 68/250\n",
      "745/745 - 1s - loss: 165.3032 - mse: 165.3032 - mae: 8.6600 - val_loss: 207.8328 - val_mse: 207.8328 - val_mae: 9.3657\n",
      "Epoch 69/250\n",
      "745/745 - 1s - loss: 160.6483 - mse: 160.6483 - mae: 8.5325 - val_loss: 200.0901 - val_mse: 200.0901 - val_mae: 9.2966\n",
      "Epoch 70/250\n",
      "745/745 - 1s - loss: 163.3219 - mse: 163.3219 - mae: 8.5738 - val_loss: 200.1521 - val_mse: 200.1521 - val_mae: 9.3858\n",
      "Epoch 71/250\n",
      "745/745 - 1s - loss: 158.6978 - mse: 158.6978 - mae: 8.5134 - val_loss: 205.4015 - val_mse: 205.4015 - val_mae: 9.6962\n",
      "Epoch 72/250\n",
      "745/745 - 1s - loss: 159.0293 - mse: 159.0293 - mae: 8.5249 - val_loss: 210.7599 - val_mse: 210.7599 - val_mae: 9.4176\n",
      "Epoch 73/250\n",
      "745/745 - 1s - loss: 162.1860 - mse: 162.1860 - mae: 8.6063 - val_loss: 205.0578 - val_mse: 205.0578 - val_mae: 9.5177\n",
      "Epoch 74/250\n",
      "745/745 - 1s - loss: 158.8274 - mse: 158.8274 - mae: 8.5254 - val_loss: 199.7755 - val_mse: 199.7755 - val_mae: 9.4026\n",
      "Epoch 75/250\n",
      "745/745 - 1s - loss: 157.2080 - mse: 157.2080 - mae: 8.4772 - val_loss: 197.5460 - val_mse: 197.5460 - val_mae: 9.3659\n",
      "Epoch 76/250\n",
      "745/745 - 1s - loss: 161.1658 - mse: 161.1658 - mae: 8.5143 - val_loss: 202.5453 - val_mse: 202.5453 - val_mae: 9.7179\n",
      "Epoch 77/250\n",
      "745/745 - 1s - loss: 156.6149 - mse: 156.6149 - mae: 8.4431 - val_loss: 206.2584 - val_mse: 206.2584 - val_mae: 9.4055\n",
      "Epoch 78/250\n",
      "745/745 - 1s - loss: 157.9899 - mse: 157.9899 - mae: 8.4637 - val_loss: 201.9940 - val_mse: 201.9940 - val_mae: 9.3894\n",
      "Epoch 79/250\n",
      "745/745 - 1s - loss: 156.8789 - mse: 156.8789 - mae: 8.4418 - val_loss: 198.8904 - val_mse: 198.8904 - val_mae: 9.3753\n",
      "Epoch 80/250\n",
      "745/745 - 1s - loss: 156.6626 - mse: 156.6626 - mae: 8.4338 - val_loss: 201.7909 - val_mse: 201.7909 - val_mae: 9.3712\n",
      "Epoch 81/250\n",
      "745/745 - 1s - loss: 158.4959 - mse: 158.4959 - mae: 8.4785 - val_loss: 201.1195 - val_mse: 201.1195 - val_mae: 9.4109\n",
      "Epoch 82/250\n",
      "745/745 - 1s - loss: 156.4009 - mse: 156.4009 - mae: 8.4374 - val_loss: 198.8654 - val_mse: 198.8654 - val_mae: 9.5675\n",
      "Epoch 83/250\n",
      "745/745 - 1s - loss: 158.1391 - mse: 158.1391 - mae: 8.4460 - val_loss: 201.7032 - val_mse: 201.7032 - val_mae: 9.4815\n",
      "Epoch 84/250\n",
      "745/745 - 1s - loss: 156.1036 - mse: 156.1036 - mae: 8.3997 - val_loss: 209.7483 - val_mse: 209.7483 - val_mae: 9.6175\n",
      "Epoch 85/250\n",
      "745/745 - 1s - loss: 155.0925 - mse: 155.0925 - mae: 8.3699 - val_loss: 206.4129 - val_mse: 206.4129 - val_mae: 9.5601\n",
      "Epoch 86/250\n",
      "745/745 - 1s - loss: 156.5743 - mse: 156.5743 - mae: 8.3819 - val_loss: 199.8952 - val_mse: 199.8952 - val_mae: 9.2548\n",
      "Epoch 87/250\n",
      "745/745 - 1s - loss: 153.3493 - mse: 153.3493 - mae: 8.3326 - val_loss: 198.7315 - val_mse: 198.7315 - val_mae: 9.4052\n",
      "Epoch 88/250\n",
      "745/745 - 1s - loss: 155.4505 - mse: 155.4505 - mae: 8.3775 - val_loss: 196.6960 - val_mse: 196.6960 - val_mae: 9.1778\n",
      "Epoch 89/250\n",
      "745/745 - 1s - loss: 153.4347 - mse: 153.4347 - mae: 8.3438 - val_loss: 199.5315 - val_mse: 199.5315 - val_mae: 9.4422\n",
      "Epoch 90/250\n",
      "745/745 - 1s - loss: 155.6747 - mse: 155.6747 - mae: 8.3567 - val_loss: 198.2291 - val_mse: 198.2291 - val_mae: 9.4116\n",
      "Epoch 91/250\n",
      "745/745 - 1s - loss: 157.6951 - mse: 157.6951 - mae: 8.4062 - val_loss: 199.6408 - val_mse: 199.6408 - val_mae: 9.3842\n",
      "Epoch 92/250\n",
      "745/745 - 1s - loss: 152.1881 - mse: 152.1881 - mae: 8.2726 - val_loss: 195.7073 - val_mse: 195.7073 - val_mae: 9.1299\n",
      "Epoch 93/250\n",
      "745/745 - 1s - loss: 152.5785 - mse: 152.5785 - mae: 8.3046 - val_loss: 197.5426 - val_mse: 197.5426 - val_mae: 9.3108\n",
      "Epoch 94/250\n",
      "745/745 - 1s - loss: 153.7728 - mse: 153.7728 - mae: 8.3127 - val_loss: 198.6737 - val_mse: 198.6737 - val_mae: 9.4940\n",
      "Epoch 95/250\n",
      "745/745 - 1s - loss: 152.1250 - mse: 152.1250 - mae: 8.2622 - val_loss: 199.8582 - val_mse: 199.8582 - val_mae: 9.2580\n",
      "Epoch 96/250\n",
      "745/745 - 1s - loss: 153.2268 - mse: 153.2268 - mae: 8.2919 - val_loss: 202.7622 - val_mse: 202.7622 - val_mae: 9.3038\n",
      "Epoch 97/250\n",
      "745/745 - 1s - loss: 152.4424 - mse: 152.4424 - mae: 8.2962 - val_loss: 199.8683 - val_mse: 199.8683 - val_mae: 9.1419\n",
      "Epoch 98/250\n",
      "745/745 - 1s - loss: 152.9683 - mse: 152.9683 - mae: 8.3104 - val_loss: 199.5832 - val_mse: 199.5832 - val_mae: 9.3635\n",
      "Epoch 99/250\n",
      "745/745 - 1s - loss: 152.2628 - mse: 152.2628 - mae: 8.2475 - val_loss: 207.0974 - val_mse: 207.0974 - val_mae: 9.3133\n",
      "Epoch 100/250\n",
      "745/745 - 1s - loss: 151.2985 - mse: 151.2985 - mae: 8.2704 - val_loss: 197.1499 - val_mse: 197.1499 - val_mae: 9.2558\n",
      "Epoch 101/250\n",
      "745/745 - 1s - loss: 152.6619 - mse: 152.6619 - mae: 8.2527 - val_loss: 202.4338 - val_mse: 202.4338 - val_mae: 9.2669\n",
      "Epoch 102/250\n",
      "745/745 - 1s - loss: 150.1469 - mse: 150.1469 - mae: 8.2376 - val_loss: 197.9622 - val_mse: 197.9622 - val_mae: 9.2174\n",
      "Epoch 103/250\n",
      "745/745 - 1s - loss: 150.4016 - mse: 150.4016 - mae: 8.2404 - val_loss: 203.8865 - val_mse: 203.8865 - val_mae: 9.2250\n",
      "Epoch 104/250\n",
      "745/745 - 1s - loss: 149.4061 - mse: 149.4061 - mae: 8.2009 - val_loss: 196.6058 - val_mse: 196.6058 - val_mae: 9.1210\n",
      "Epoch 105/250\n",
      "745/745 - 1s - loss: 150.8957 - mse: 150.8957 - mae: 8.2185 - val_loss: 202.8134 - val_mse: 202.8134 - val_mae: 9.6005\n",
      "Epoch 106/250\n",
      "745/745 - 1s - loss: 151.3088 - mse: 151.3088 - mae: 8.2531 - val_loss: 200.4326 - val_mse: 200.4326 - val_mae: 9.2383\n",
      "Epoch 107/250\n",
      "745/745 - 1s - loss: 149.1399 - mse: 149.1399 - mae: 8.1985 - val_loss: 199.8956 - val_mse: 199.8956 - val_mae: 9.1317\n",
      "Epoch 108/250\n",
      "745/745 - 1s - loss: 149.4179 - mse: 149.4179 - mae: 8.1932 - val_loss: 197.1701 - val_mse: 197.1701 - val_mae: 9.2707\n",
      "Epoch 109/250\n",
      "745/745 - 1s - loss: 148.5910 - mse: 148.5910 - mae: 8.1582 - val_loss: 204.4321 - val_mse: 204.4321 - val_mae: 9.2677\n",
      "Epoch 110/250\n",
      "745/745 - 1s - loss: 148.0684 - mse: 148.0684 - mae: 8.1566 - val_loss: 199.3909 - val_mse: 199.3909 - val_mae: 9.2864\n",
      "Epoch 111/250\n",
      "745/745 - 1s - loss: 149.1203 - mse: 149.1203 - mae: 8.2262 - val_loss: 198.2334 - val_mse: 198.2334 - val_mae: 9.2788\n",
      "Epoch 112/250\n",
      "745/745 - 1s - loss: 152.3687 - mse: 152.3687 - mae: 8.2281 - val_loss: 197.8133 - val_mse: 197.8133 - val_mae: 9.1395\n",
      "Epoch 113/250\n",
      "745/745 - 1s - loss: 147.8561 - mse: 147.8561 - mae: 8.1264 - val_loss: 209.1572 - val_mse: 209.1572 - val_mae: 9.4535\n",
      "Epoch 114/250\n",
      "745/745 - 1s - loss: 148.9478 - mse: 148.9478 - mae: 8.1685 - val_loss: 191.3129 - val_mse: 191.3129 - val_mae: 9.1486\n",
      "Epoch 115/250\n",
      "745/745 - 1s - loss: 149.3762 - mse: 149.3762 - mae: 8.1694 - val_loss: 194.4505 - val_mse: 194.4505 - val_mae: 9.1300\n",
      "Epoch 116/250\n",
      "745/745 - 1s - loss: 148.1296 - mse: 148.1296 - mae: 8.1419 - val_loss: 189.5242 - val_mse: 189.5242 - val_mae: 9.0624\n",
      "Epoch 117/250\n",
      "745/745 - 1s - loss: 148.1733 - mse: 148.1733 - mae: 8.1270 - val_loss: 196.4521 - val_mse: 196.4521 - val_mae: 9.2401\n",
      "Epoch 118/250\n",
      "745/745 - 1s - loss: 146.8380 - mse: 146.8380 - mae: 8.0994 - val_loss: 193.4863 - val_mse: 193.4863 - val_mae: 9.0494\n",
      "Epoch 119/250\n",
      "745/745 - 1s - loss: 147.1249 - mse: 147.1249 - mae: 8.1224 - val_loss: 202.6261 - val_mse: 202.6261 - val_mae: 9.1853\n",
      "Epoch 120/250\n",
      "745/745 - 1s - loss: 147.8271 - mse: 147.8271 - mae: 8.1681 - val_loss: 192.4405 - val_mse: 192.4405 - val_mae: 9.0437\n",
      "Epoch 121/250\n",
      "745/745 - 1s - loss: 145.9262 - mse: 145.9262 - mae: 8.1149 - val_loss: 204.0680 - val_mse: 204.0680 - val_mae: 9.1941\n",
      "Epoch 122/250\n",
      "745/745 - 1s - loss: 146.9481 - mse: 146.9481 - mae: 8.1336 - val_loss: 206.0103 - val_mse: 206.0103 - val_mae: 9.0934\n",
      "Epoch 123/250\n",
      "745/745 - 1s - loss: 146.3255 - mse: 146.3255 - mae: 8.0831 - val_loss: 193.8262 - val_mse: 193.8262 - val_mae: 9.1265\n",
      "Epoch 124/250\n",
      "745/745 - 1s - loss: 145.4706 - mse: 145.4706 - mae: 8.0681 - val_loss: 195.8935 - val_mse: 195.8935 - val_mae: 9.1720\n",
      "Epoch 125/250\n",
      "745/745 - 1s - loss: 146.5548 - mse: 146.5548 - mae: 8.1150 - val_loss: 197.3066 - val_mse: 197.3066 - val_mae: 9.3215\n",
      "Epoch 126/250\n",
      "745/745 - 1s - loss: 147.1907 - mse: 147.1907 - mae: 8.0985 - val_loss: 197.9805 - val_mse: 197.9805 - val_mae: 9.0324\n",
      "Epoch 127/250\n",
      "745/745 - 1s - loss: 144.2980 - mse: 144.2980 - mae: 8.0153 - val_loss: 201.3673 - val_mse: 201.3673 - val_mae: 9.2771\n",
      "Epoch 128/250\n",
      "745/745 - 1s - loss: 145.9673 - mse: 145.9673 - mae: 8.0631 - val_loss: 203.2406 - val_mse: 203.2406 - val_mae: 9.4270\n",
      "Epoch 129/250\n",
      "745/745 - 1s - loss: 145.6096 - mse: 145.6096 - mae: 8.0874 - val_loss: 201.2925 - val_mse: 201.2925 - val_mae: 8.9952\n",
      "Epoch 130/250\n",
      "745/745 - 1s - loss: 145.3447 - mse: 145.3447 - mae: 8.0843 - val_loss: 191.7156 - val_mse: 191.7156 - val_mae: 8.8930\n",
      "Epoch 131/250\n",
      "745/745 - 1s - loss: 143.2516 - mse: 143.2516 - mae: 7.9655 - val_loss: 192.3792 - val_mse: 192.3792 - val_mae: 9.0697\n",
      "Epoch 132/250\n",
      "745/745 - 1s - loss: 143.9989 - mse: 143.9989 - mae: 8.0126 - val_loss: 197.6557 - val_mse: 197.6557 - val_mae: 9.0907\n",
      "Epoch 133/250\n",
      "745/745 - 1s - loss: 142.9122 - mse: 142.9122 - mae: 8.0387 - val_loss: 193.8161 - val_mse: 193.8161 - val_mae: 9.0786\n",
      "Epoch 134/250\n",
      "745/745 - 1s - loss: 145.2555 - mse: 145.2555 - mae: 8.0697 - val_loss: 205.3784 - val_mse: 205.3784 - val_mae: 9.0539\n",
      "Epoch 135/250\n",
      "745/745 - 1s - loss: 144.7585 - mse: 144.7585 - mae: 8.0425 - val_loss: 208.0419 - val_mse: 208.0419 - val_mae: 9.2971\n",
      "Epoch 136/250\n",
      "745/745 - 1s - loss: 143.5709 - mse: 143.5709 - mae: 8.0460 - val_loss: 190.3375 - val_mse: 190.3375 - val_mae: 8.9587\n",
      "Epoch 137/250\n",
      "745/745 - 1s - loss: 143.4963 - mse: 143.4963 - mae: 8.0205 - val_loss: 194.1724 - val_mse: 194.1724 - val_mae: 8.9495\n",
      "Epoch 138/250\n",
      "745/745 - 1s - loss: 143.1351 - mse: 143.1351 - mae: 7.9951 - val_loss: 194.3866 - val_mse: 194.3866 - val_mae: 9.0858\n",
      "Epoch 139/250\n",
      "745/745 - 1s - loss: 142.7494 - mse: 142.7494 - mae: 7.9853 - val_loss: 192.9321 - val_mse: 192.9321 - val_mae: 9.1216\n",
      "Epoch 140/250\n",
      "745/745 - 1s - loss: 142.0158 - mse: 142.0158 - mae: 7.9838 - val_loss: 200.6496 - val_mse: 200.6496 - val_mae: 9.1201\n",
      "Epoch 141/250\n",
      "745/745 - 1s - loss: 143.7527 - mse: 143.7527 - mae: 8.0083 - val_loss: 205.5993 - val_mse: 205.5993 - val_mae: 9.0740\n",
      "Epoch 142/250\n",
      "745/745 - 1s - loss: 142.2622 - mse: 142.2622 - mae: 7.9888 - val_loss: 199.1470 - val_mse: 199.1470 - val_mae: 9.1364\n",
      "Epoch 143/250\n",
      "745/745 - 1s - loss: 143.5206 - mse: 143.5206 - mae: 8.0178 - val_loss: 199.4319 - val_mse: 199.4319 - val_mae: 9.1412\n",
      "Epoch 144/250\n",
      "745/745 - 1s - loss: 141.6849 - mse: 141.6849 - mae: 7.9686 - val_loss: 201.6517 - val_mse: 201.6517 - val_mae: 9.1995\n",
      "Epoch 145/250\n",
      "745/745 - 1s - loss: 143.1077 - mse: 143.1077 - mae: 7.9793 - val_loss: 193.3577 - val_mse: 193.3577 - val_mae: 8.9765\n",
      "Epoch 146/250\n",
      "745/745 - 1s - loss: 141.4232 - mse: 141.4232 - mae: 7.9606 - val_loss: 198.0489 - val_mse: 198.0489 - val_mae: 8.9425\n",
      "Epoch 147/250\n",
      "745/745 - 1s - loss: 142.0801 - mse: 142.0801 - mae: 7.9784 - val_loss: 195.1071 - val_mse: 195.1071 - val_mae: 9.0545\n",
      "Epoch 148/250\n",
      "745/745 - 1s - loss: 142.7505 - mse: 142.7505 - mae: 7.9858 - val_loss: 193.3370 - val_mse: 193.3370 - val_mae: 9.0272\n",
      "Epoch 149/250\n",
      "745/745 - 1s - loss: 141.6575 - mse: 141.6575 - mae: 7.9820 - val_loss: 194.3736 - val_mse: 194.3736 - val_mae: 9.0604\n",
      "Epoch 150/250\n",
      "745/745 - 1s - loss: 139.9244 - mse: 139.9244 - mae: 7.9050 - val_loss: 196.3524 - val_mse: 196.3524 - val_mae: 8.9919\n",
      "Epoch 151/250\n",
      "745/745 - 1s - loss: 141.8907 - mse: 141.8907 - mae: 7.9950 - val_loss: 214.8207 - val_mse: 214.8207 - val_mae: 9.0638\n",
      "Epoch 152/250\n",
      "745/745 - 1s - loss: 140.3328 - mse: 140.3328 - mae: 7.9143 - val_loss: 204.3937 - val_mse: 204.3937 - val_mae: 9.1620\n",
      "Epoch 153/250\n",
      "745/745 - 1s - loss: 141.4062 - mse: 141.4062 - mae: 7.9625 - val_loss: 196.5231 - val_mse: 196.5231 - val_mae: 8.9648\n",
      "Epoch 154/250\n",
      "745/745 - 1s - loss: 141.5808 - mse: 141.5808 - mae: 8.0017 - val_loss: 211.5756 - val_mse: 211.5756 - val_mae: 9.0768\n",
      "Epoch 155/250\n",
      "745/745 - 1s - loss: 141.1241 - mse: 141.1241 - mae: 7.9305 - val_loss: 198.5732 - val_mse: 198.5732 - val_mae: 9.1733\n",
      "Epoch 156/250\n",
      "745/745 - 1s - loss: 146.8647 - mse: 146.8647 - mae: 8.0078 - val_loss: 201.0571 - val_mse: 201.0571 - val_mae: 9.0344\n",
      "Epoch 157/250\n",
      "745/745 - 1s - loss: 140.9419 - mse: 140.9419 - mae: 7.9462 - val_loss: 203.1233 - val_mse: 203.1233 - val_mae: 9.0668\n",
      "Epoch 158/250\n",
      "745/745 - 1s - loss: 139.8659 - mse: 139.8659 - mae: 7.9033 - val_loss: 207.3671 - val_mse: 207.3671 - val_mae: 9.1562\n",
      "Epoch 159/250\n",
      "745/745 - 1s - loss: 138.8364 - mse: 138.8364 - mae: 7.8710 - val_loss: 193.8596 - val_mse: 193.8596 - val_mae: 8.8786\n",
      "Epoch 160/250\n",
      "745/745 - 1s - loss: 141.5882 - mse: 141.5882 - mae: 7.9046 - val_loss: 197.2477 - val_mse: 197.2477 - val_mae: 9.0325\n",
      "Epoch 161/250\n",
      "745/745 - 1s - loss: 138.7495 - mse: 138.7495 - mae: 7.8686 - val_loss: 192.6956 - val_mse: 192.6956 - val_mae: 8.9027\n",
      "Epoch 162/250\n",
      "745/745 - 1s - loss: 139.8543 - mse: 139.8543 - mae: 7.9194 - val_loss: 197.7995 - val_mse: 197.7995 - val_mae: 9.0337\n",
      "Epoch 163/250\n",
      "745/745 - 1s - loss: 140.0606 - mse: 140.0606 - mae: 7.9261 - val_loss: 191.3461 - val_mse: 191.3461 - val_mae: 9.0007\n",
      "Epoch 164/250\n",
      "745/745 - 1s - loss: 140.7976 - mse: 140.7976 - mae: 7.9368 - val_loss: 195.2225 - val_mse: 195.2225 - val_mae: 9.0176\n",
      "Epoch 165/250\n",
      "745/745 - 1s - loss: 139.3032 - mse: 139.3032 - mae: 7.8958 - val_loss: 196.4207 - val_mse: 196.4207 - val_mae: 8.8908\n",
      "Epoch 166/250\n",
      "745/745 - 1s - loss: 138.1828 - mse: 138.1828 - mae: 7.8729 - val_loss: 203.6729 - val_mse: 203.6729 - val_mae: 8.9318\n",
      "Epoch 167/250\n",
      "745/745 - 1s - loss: 140.8791 - mse: 140.8791 - mae: 7.9097 - val_loss: 194.7348 - val_mse: 194.7348 - val_mae: 8.8926\n",
      "Epoch 168/250\n",
      "745/745 - 1s - loss: 139.1798 - mse: 139.1798 - mae: 7.8948 - val_loss: 196.1994 - val_mse: 196.1994 - val_mae: 9.0130\n",
      "Epoch 169/250\n",
      "745/745 - 1s - loss: 138.3340 - mse: 138.3340 - mae: 7.8620 - val_loss: 200.8127 - val_mse: 200.8127 - val_mae: 9.1775\n",
      "Epoch 170/250\n",
      "745/745 - 1s - loss: 140.1684 - mse: 140.1684 - mae: 7.9021 - val_loss: 221.2140 - val_mse: 221.2140 - val_mae: 9.1481\n",
      "Epoch 171/250\n",
      "745/745 - 1s - loss: 138.6988 - mse: 138.6988 - mae: 7.8613 - val_loss: 200.8166 - val_mse: 200.8166 - val_mae: 9.0278\n",
      "Epoch 172/250\n",
      "745/745 - 1s - loss: 138.4768 - mse: 138.4768 - mae: 7.8833 - val_loss: 197.0081 - val_mse: 197.0081 - val_mae: 9.0560\n",
      "Epoch 173/250\n",
      "745/745 - 1s - loss: 139.7869 - mse: 139.7869 - mae: 7.9123 - val_loss: 202.9387 - val_mse: 202.9387 - val_mae: 8.9236\n",
      "Epoch 174/250\n",
      "745/745 - 1s - loss: 138.4152 - mse: 138.4152 - mae: 7.8783 - val_loss: 197.9321 - val_mse: 197.9321 - val_mae: 9.0209\n",
      "Epoch 175/250\n",
      "745/745 - 1s - loss: 137.3082 - mse: 137.3082 - mae: 7.8541 - val_loss: 208.1925 - val_mse: 208.1925 - val_mae: 9.0523\n",
      "Epoch 176/250\n",
      "745/745 - 1s - loss: 137.9561 - mse: 137.9561 - mae: 7.8759 - val_loss: 195.0541 - val_mse: 195.0541 - val_mae: 9.0074\n",
      "Epoch 177/250\n",
      "745/745 - 1s - loss: 137.1941 - mse: 137.1941 - mae: 7.8380 - val_loss: 192.0379 - val_mse: 192.0379 - val_mae: 9.1125\n",
      "Epoch 178/250\n",
      "745/745 - 1s - loss: 138.0645 - mse: 138.0645 - mae: 7.8727 - val_loss: 212.0981 - val_mse: 212.0981 - val_mae: 8.9700\n",
      "Epoch 179/250\n",
      "745/745 - 1s - loss: 139.4096 - mse: 139.4096 - mae: 7.8737 - val_loss: 189.5596 - val_mse: 189.5596 - val_mae: 9.0103\n",
      "Epoch 180/250\n",
      "745/745 - 1s - loss: 139.1849 - mse: 139.1849 - mae: 7.9104 - val_loss: 198.7827 - val_mse: 198.7827 - val_mae: 8.9033\n",
      "Epoch 181/250\n",
      "745/745 - 1s - loss: 135.9709 - mse: 135.9709 - mae: 7.7795 - val_loss: 211.1162 - val_mse: 211.1162 - val_mae: 9.1233\n",
      "Epoch 182/250\n",
      "745/745 - 1s - loss: 136.7383 - mse: 136.7383 - mae: 7.8274 - val_loss: 197.1874 - val_mse: 197.1874 - val_mae: 8.9323\n",
      "Epoch 183/250\n",
      "745/745 - 1s - loss: 137.5475 - mse: 137.5475 - mae: 7.8469 - val_loss: 197.3953 - val_mse: 197.3953 - val_mae: 9.2674\n",
      "Epoch 184/250\n",
      "745/745 - 1s - loss: 137.6403 - mse: 137.6403 - mae: 7.8469 - val_loss: 191.9867 - val_mse: 191.9867 - val_mae: 8.9649\n",
      "Epoch 185/250\n",
      "745/745 - 1s - loss: 136.1653 - mse: 136.1653 - mae: 7.7983 - val_loss: 198.8984 - val_mse: 198.8984 - val_mae: 8.8200\n",
      "Epoch 186/250\n",
      "745/745 - 1s - loss: 136.1695 - mse: 136.1695 - mae: 7.8140 - val_loss: 200.8770 - val_mse: 200.8770 - val_mae: 8.9335\n",
      "Epoch 187/250\n",
      "745/745 - 1s - loss: 136.5132 - mse: 136.5132 - mae: 7.8022 - val_loss: 199.0090 - val_mse: 199.0090 - val_mae: 9.0800\n",
      "Epoch 188/250\n",
      "745/745 - 1s - loss: 137.8449 - mse: 137.8449 - mae: 7.8586 - val_loss: 195.3905 - val_mse: 195.3905 - val_mae: 8.9344\n",
      "Epoch 189/250\n",
      "745/745 - 1s - loss: 136.7160 - mse: 136.7160 - mae: 7.8296 - val_loss: 204.5108 - val_mse: 204.5108 - val_mae: 8.8920\n",
      "Epoch 190/250\n",
      "745/745 - 1s - loss: 136.0297 - mse: 136.0297 - mae: 7.7652 - val_loss: 197.1075 - val_mse: 197.1075 - val_mae: 9.1898\n",
      "Epoch 191/250\n",
      "745/745 - 1s - loss: 137.7523 - mse: 137.7523 - mae: 7.8521 - val_loss: 201.5536 - val_mse: 201.5536 - val_mae: 8.9847\n",
      "Epoch 192/250\n",
      "745/745 - 1s - loss: 136.6404 - mse: 136.6404 - mae: 7.8061 - val_loss: 197.7117 - val_mse: 197.7117 - val_mae: 8.9925\n",
      "Epoch 193/250\n",
      "745/745 - 1s - loss: 135.4769 - mse: 135.4769 - mae: 7.7819 - val_loss: 203.0973 - val_mse: 203.0973 - val_mae: 8.9678\n",
      "Epoch 194/250\n",
      "745/745 - 1s - loss: 136.8801 - mse: 136.8801 - mae: 7.8317 - val_loss: 200.7296 - val_mse: 200.7296 - val_mae: 8.9891\n",
      "Epoch 195/250\n",
      "745/745 - 1s - loss: 137.0340 - mse: 137.0340 - mae: 7.8263 - val_loss: 200.0446 - val_mse: 200.0446 - val_mae: 8.9517\n",
      "Epoch 196/250\n",
      "745/745 - 1s - loss: 134.7272 - mse: 134.7272 - mae: 7.7713 - val_loss: 200.4108 - val_mse: 200.4108 - val_mae: 9.0517\n",
      "Epoch 197/250\n",
      "745/745 - 1s - loss: 135.9840 - mse: 135.9840 - mae: 7.7827 - val_loss: 207.2684 - val_mse: 207.2684 - val_mae: 8.8871\n",
      "Epoch 198/250\n",
      "745/745 - 1s - loss: 135.8027 - mse: 135.8027 - mae: 7.7971 - val_loss: 198.0298 - val_mse: 198.0298 - val_mae: 8.8730\n",
      "Epoch 199/250\n",
      "745/745 - 1s - loss: 135.3783 - mse: 135.3783 - mae: 7.7755 - val_loss: 199.2026 - val_mse: 199.2026 - val_mae: 8.9209\n",
      "Epoch 200/250\n",
      "745/745 - 1s - loss: 135.9736 - mse: 135.9736 - mae: 7.7624 - val_loss: 198.0424 - val_mse: 198.0424 - val_mae: 8.8612\n",
      "Epoch 201/250\n",
      "745/745 - 1s - loss: 135.8880 - mse: 135.8880 - mae: 7.7870 - val_loss: 208.4162 - val_mse: 208.4162 - val_mae: 8.9031\n",
      "Epoch 202/250\n",
      "745/745 - 1s - loss: 135.0423 - mse: 135.0423 - mae: 7.7695 - val_loss: 197.5571 - val_mse: 197.5571 - val_mae: 8.8464\n",
      "Epoch 203/250\n",
      "745/745 - 1s - loss: 134.3786 - mse: 134.3786 - mae: 7.7461 - val_loss: 210.7847 - val_mse: 210.7847 - val_mae: 9.4020\n",
      "Epoch 204/250\n",
      "745/745 - 1s - loss: 134.3708 - mse: 134.3708 - mae: 7.7283 - val_loss: 196.1067 - val_mse: 196.1067 - val_mae: 8.9247\n",
      "Epoch 205/250\n",
      "745/745 - 1s - loss: 134.8953 - mse: 134.8953 - mae: 7.7489 - val_loss: 199.2022 - val_mse: 199.2022 - val_mae: 9.0197\n",
      "Epoch 206/250\n",
      "745/745 - 1s - loss: 134.8304 - mse: 134.8304 - mae: 7.7843 - val_loss: 210.6996 - val_mse: 210.6996 - val_mae: 8.9992\n",
      "Epoch 207/250\n",
      "745/745 - 1s - loss: 135.8917 - mse: 135.8917 - mae: 7.8128 - val_loss: 214.0433 - val_mse: 214.0433 - val_mae: 9.0826\n",
      "Epoch 208/250\n",
      "745/745 - 1s - loss: 134.5611 - mse: 134.5611 - mae: 7.7663 - val_loss: 201.8919 - val_mse: 201.8919 - val_mae: 8.7688\n",
      "Epoch 209/250\n",
      "745/745 - 1s - loss: 133.6437 - mse: 133.6437 - mae: 7.6853 - val_loss: 202.1088 - val_mse: 202.1088 - val_mae: 8.9109\n",
      "Epoch 210/250\n",
      "745/745 - 1s - loss: 132.8098 - mse: 132.8098 - mae: 7.6942 - val_loss: 206.1781 - val_mse: 206.1781 - val_mae: 8.9128\n",
      "Epoch 211/250\n",
      "745/745 - 1s - loss: 133.8051 - mse: 133.8051 - mae: 7.7552 - val_loss: 188.4060 - val_mse: 188.4060 - val_mae: 8.9299\n",
      "Epoch 212/250\n",
      "745/745 - 1s - loss: 134.1997 - mse: 134.1997 - mae: 7.7306 - val_loss: 201.4321 - val_mse: 201.4321 - val_mae: 8.7875\n",
      "Epoch 213/250\n",
      "745/745 - 1s - loss: 134.1920 - mse: 134.1920 - mae: 7.7323 - val_loss: 194.3476 - val_mse: 194.3476 - val_mae: 8.8828\n",
      "Epoch 214/250\n",
      "745/745 - 1s - loss: 133.3332 - mse: 133.3332 - mae: 7.6986 - val_loss: 200.4048 - val_mse: 200.4048 - val_mae: 8.7947\n",
      "Epoch 215/250\n",
      "745/745 - 1s - loss: 134.2985 - mse: 134.2985 - mae: 7.7472 - val_loss: 201.5658 - val_mse: 201.5658 - val_mae: 8.9212\n",
      "Epoch 216/250\n",
      "745/745 - 1s - loss: 133.0276 - mse: 133.0276 - mae: 7.7083 - val_loss: 197.2728 - val_mse: 197.2728 - val_mae: 8.9044\n",
      "Epoch 217/250\n",
      "745/745 - 1s - loss: 133.1611 - mse: 133.1611 - mae: 7.7086 - val_loss: 202.5258 - val_mse: 202.5258 - val_mae: 8.8888\n",
      "Epoch 218/250\n",
      "745/745 - 1s - loss: 133.9785 - mse: 133.9785 - mae: 7.7277 - val_loss: 203.1243 - val_mse: 203.1243 - val_mae: 8.8712\n",
      "Epoch 219/250\n",
      "745/745 - 1s - loss: 134.3560 - mse: 134.3560 - mae: 7.7136 - val_loss: 195.3566 - val_mse: 195.3566 - val_mae: 8.9012\n",
      "Epoch 220/250\n",
      "745/745 - 1s - loss: 133.0954 - mse: 133.0954 - mae: 7.6996 - val_loss: 193.6737 - val_mse: 193.6737 - val_mae: 8.9047\n",
      "Epoch 221/250\n",
      "745/745 - 1s - loss: 132.9348 - mse: 132.9348 - mae: 7.6925 - val_loss: 201.9011 - val_mse: 201.9011 - val_mae: 9.4608\n",
      "Epoch 222/250\n",
      "745/745 - 1s - loss: 133.6614 - mse: 133.6614 - mae: 7.7480 - val_loss: 197.6873 - val_mse: 197.6873 - val_mae: 8.8974\n",
      "Epoch 223/250\n",
      "745/745 - 1s - loss: 132.3737 - mse: 132.3737 - mae: 7.7074 - val_loss: 201.4383 - val_mse: 201.4383 - val_mae: 8.9514\n",
      "Epoch 224/250\n",
      "745/745 - 1s - loss: 133.3998 - mse: 133.3998 - mae: 7.7092 - val_loss: 236.3623 - val_mse: 236.3623 - val_mae: 9.1524\n",
      "Epoch 225/250\n",
      "745/745 - 1s - loss: 133.1501 - mse: 133.1501 - mae: 7.6695 - val_loss: 196.9478 - val_mse: 196.9478 - val_mae: 9.0108\n",
      "Epoch 226/250\n",
      "745/745 - 1s - loss: 131.9109 - mse: 131.9109 - mae: 7.6831 - val_loss: 195.1513 - val_mse: 195.1513 - val_mae: 8.8010\n",
      "Epoch 227/250\n",
      "745/745 - 1s - loss: 132.1396 - mse: 132.1396 - mae: 7.6872 - val_loss: 192.6736 - val_mse: 192.6736 - val_mae: 8.8878\n",
      "Epoch 228/250\n",
      "745/745 - 1s - loss: 132.8014 - mse: 132.8014 - mae: 7.7208 - val_loss: 203.9121 - val_mse: 203.9121 - val_mae: 9.0556\n",
      "Epoch 229/250\n",
      "745/745 - 1s - loss: 132.4577 - mse: 132.4577 - mae: 7.6920 - val_loss: 193.5446 - val_mse: 193.5446 - val_mae: 8.9837\n",
      "Epoch 230/250\n",
      "745/745 - 1s - loss: 131.6981 - mse: 131.6981 - mae: 7.6552 - val_loss: 199.4071 - val_mse: 199.4071 - val_mae: 8.9121\n",
      "Epoch 231/250\n",
      "745/745 - 1s - loss: 133.5016 - mse: 133.5016 - mae: 7.7106 - val_loss: 200.5526 - val_mse: 200.5526 - val_mae: 8.8753\n",
      "Epoch 232/250\n",
      "745/745 - 1s - loss: 132.4605 - mse: 132.4605 - mae: 7.6628 - val_loss: 207.0649 - val_mse: 207.0649 - val_mae: 8.7330\n",
      "Epoch 233/250\n",
      "745/745 - 1s - loss: 132.1396 - mse: 132.1396 - mae: 7.6709 - val_loss: 216.9876 - val_mse: 216.9876 - val_mae: 8.9153\n",
      "Epoch 234/250\n",
      "745/745 - 1s - loss: 132.8598 - mse: 132.8598 - mae: 7.6834 - val_loss: 196.4344 - val_mse: 196.4344 - val_mae: 8.8323\n",
      "Epoch 235/250\n",
      "745/745 - 1s - loss: 132.5350 - mse: 132.5350 - mae: 7.6592 - val_loss: 207.1230 - val_mse: 207.1230 - val_mae: 9.2287\n",
      "Epoch 236/250\n",
      "745/745 - 1s - loss: 131.9164 - mse: 131.9164 - mae: 7.6699 - val_loss: 203.0443 - val_mse: 203.0443 - val_mae: 8.8392\n",
      "Epoch 237/250\n",
      "745/745 - 1s - loss: 131.3367 - mse: 131.3367 - mae: 7.6236 - val_loss: 200.2611 - val_mse: 200.2611 - val_mae: 8.9759\n",
      "Epoch 238/250\n",
      "745/745 - 1s - loss: 130.4119 - mse: 130.4119 - mae: 7.6108 - val_loss: 198.4401 - val_mse: 198.4401 - val_mae: 8.8638\n",
      "Epoch 239/250\n",
      "745/745 - 1s - loss: 131.4783 - mse: 131.4783 - mae: 7.6397 - val_loss: 199.9159 - val_mse: 199.9159 - val_mae: 8.8425\n",
      "Epoch 240/250\n",
      "745/745 - 1s - loss: 131.6314 - mse: 131.6314 - mae: 7.6720 - val_loss: 198.3002 - val_mse: 198.3002 - val_mae: 8.8583\n",
      "Epoch 241/250\n",
      "745/745 - 1s - loss: 131.9052 - mse: 131.9052 - mae: 7.6308 - val_loss: 213.4718 - val_mse: 213.4718 - val_mae: 9.0915\n",
      "Epoch 242/250\n",
      "745/745 - 1s - loss: 132.2082 - mse: 132.2082 - mae: 7.6945 - val_loss: 208.7011 - val_mse: 208.7011 - val_mae: 8.8170\n",
      "Epoch 243/250\n",
      "745/745 - 1s - loss: 131.4318 - mse: 131.4318 - mae: 7.6532 - val_loss: 218.7964 - val_mse: 218.7964 - val_mae: 9.0506\n",
      "Epoch 244/250\n",
      "745/745 - 1s - loss: 132.1340 - mse: 132.1340 - mae: 7.6790 - val_loss: 199.9669 - val_mse: 199.9669 - val_mae: 8.8628\n",
      "Epoch 245/250\n",
      "745/745 - 1s - loss: 132.3596 - mse: 132.3596 - mae: 7.6906 - val_loss: 196.0205 - val_mse: 196.0205 - val_mae: 8.7238\n",
      "Epoch 246/250\n",
      "745/745 - 1s - loss: 130.5273 - mse: 130.5273 - mae: 7.6087 - val_loss: 205.8727 - val_mse: 205.8727 - val_mae: 8.9244\n",
      "Epoch 247/250\n",
      "745/745 - 1s - loss: 131.4919 - mse: 131.4919 - mae: 7.6474 - val_loss: 205.1126 - val_mse: 205.1126 - val_mae: 9.1307\n",
      "Epoch 248/250\n",
      "745/745 - 1s - loss: 131.0284 - mse: 131.0284 - mae: 7.6323 - val_loss: 198.7741 - val_mse: 198.7741 - val_mae: 8.9258\n",
      "Epoch 249/250\n",
      "745/745 - 1s - loss: 130.2646 - mse: 130.2646 - mae: 7.6128 - val_loss: 201.7919 - val_mse: 201.7919 - val_mae: 8.7803\n",
      "Epoch 250/250\n",
      "745/745 - 1s - loss: 131.7574 - mse: 131.7574 - mae: 7.7021 - val_loss: 197.9997 - val_mse: 197.9997 - val_mae: 8.7991\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pca, y_train, epochs = 250, batch_size = 16, verbose = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cc25c27ac0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwOklEQVR4nO3deZxU1Z338c+vqqur932h6WbfaUCWFk1wx6hoFDWYkMSJGpWMSUbNMgkmM4/mmXFilnGMcTQxiUoianhwgRg1UYTgioICNpuAbE3TO70vVV11nj9ONd1NL2AvVHPr9369+lXVt27dOqdu1feee+65t8QYg1JKqcjgCncBlFJKnToa+kopFUE09JVSKoJo6CulVATR0FdKqQgSFe4CnEhGRoYZPXp0uIuhlFKnlU2bNlUYYzKPnz7kQ3/06NFs3Lgx3MVQSqnTiogc6G66du8opVQE0dBXSqkIoqGvlFIRZMj36SulnMPv91NUVERzc3O4i+IYMTEx5OXl4fF4Tmp+DX2l1ClTVFREYmIio0ePRkTCXZzTnjGGyspKioqKGDNmzEk9R7t3lFKnTHNzM+np6Rr4A0RESE9P/1R7Thr6SqlTSgN/YH3a99Oxof/EW/tYvaU43MVQSqkhxbGhv3zDQV4pPBLuYiilhpDq6moefvjhT/28yy+/nOrq6oEvUBg4NvRdIgSC+gMxSql2PYV+IBDo9XkvvfQSKSkpg1SqU8uxo3dcLkEzXynV0dKlS9m7dy8zZ87E4/GQkJBATk4OmzdvZvv27Vx99dUcOnSI5uZm7rjjDpYsWQK0Xw6mvr6eBQsWcM455/D222+Tm5vLqlWriI2NDXPNTp5zQ18gqKmv1JD1k79sY3tx7YAuc+rwJO6+Mr/Hx++77z4KCwvZvHkz69at44orrqCwsPDYcMfHHnuMtLQ0mpqaOPPMM/nCF75Aenp6p2Xs3r2bp59+mt/97nd88Ytf5Nlnn+X6668f0HoMJseGvtslBPX3f5VSvZg7d26n8e0PPvggzz//PACHDh1i9+7dXUJ/zJgxzJw5E4A5c+awf//+U1XcAeHY0BcRApr5Sg1ZvbXIT5X4+Phj99etW8drr73GO++8Q1xcHBdccEG349+9Xu+x+263m6amplNS1oHi2AO5brFnqymlVJvExETq6uq6faympobU1FTi4uLYuXMn77777iku3anh2Ja+jt5RSh0vPT2defPmMW3aNGJjY8nOzj722GWXXcZvfvMbZsyYwaRJkzj77LPDWNLB49zQ1z59pVQ3nnrqqW6ne71eXn755W4fa+u3z8jIoLCw8Nj073//+wNevsHm2O4dO3on3KVQSqmhxbGhr6N3lFKqK8eGvkuEgIa+Ukp14ujQ1+O4SinV2QlDX0QeE5EyESnsMC1NRF4Vkd2h29QOj90lIntEZJeIXNph+hwR+Sj02IMyyNdX1TNylVKqq5Np6T8BXHbctKXAGmPMBGBN6H9EZCqwGMgPPedhEXGHnvMIsASYEPo7fpkDSvv0lVKqqxOGvjFmPVB13OSFwLLQ/WXA1R2mP2OMaTHG7AP2AHNFJAdIMsa8Y+wZU3/s8JxBITpOXynVTwkJCQAUFxezaNGibue54IIL2LhxY6/LeeCBB2hsbDz2fzgv1dzXPv1sY8wRgNBtVmh6LnCow3xFoWm5ofvHT++WiCwRkY0isrG8vLxPBXSLoA19pdRAGD58OCtXruzz848P/XBeqnmgD+R2109vepneLWPMo8aYAmNMQWZmZp8K4nKho3eUUp388Ic/7HQ9/XvuuYef/OQnzJ8/n9mzZzN9+nRWrVrV5Xn79+9n2rRpADQ1NbF48WJmzJjBl770pU7X3rntttsoKCggPz+fu+++G7AXcSsuLubCCy/kwgsvBOylmisqKgC4//77mTZtGtOmTeOBBx449npTpkzh1ltvJT8/n0suuWTArvHT1zNyS0UkxxhzJNR1UxaaXgSM6DBfHlAcmp7XzfRB4xLRA7lKDWUvL4WSjwZ2mcOmw4L7enx48eLF3HnnnXzzm98EYMWKFbzyyit85zvfISkpiYqKCs4++2yuuuqqHn979pFHHiEuLo6tW7eydetWZs+efeyxe++9l7S0NAKBAPPnz2fr1q3cfvvt3H///axdu5aMjIxOy9q0aROPP/44GzZswBjDWWedxfnnn09qauqgXcK5ry391cANofs3AKs6TF8sIl4RGYM9YPteqAuoTkTODo3a+VqH5wwKO2RTQ18p1W7WrFmUlZVRXFzMli1bSE1NJScnhx/96EfMmDGDiy++mMOHD1NaWtrjMtavX38sfGfMmMGMGTOOPbZixQpmz57NrFmz2LZtG9u3b++1PG+++SbXXHMN8fHxJCQkcO211/LGG28Ag3cJ5xO29EXkaeACIENEioC7gfuAFSJyM3AQuA7AGLNNRFYA24FW4FvGmLbfIbsNOxIoFng59Ddo3C49OUupIa2XFvlgWrRoEStXrqSkpITFixezfPlyysvL2bRpEx6Ph9GjR3d7SeWOutsL2LdvH7/85S95//33SU1N5cYbbzzhcnq7EvBgXcL5ZEbvfNkYk2OM8Rhj8owxfzDGVBpj5htjJoRuqzrMf68xZpwxZpIx5uUO0zcaY6aFHvu2GeTrHotee0cp1Y3FixfzzDPPsHLlShYtWkRNTQ1ZWVl4PB7Wrl3LgQMHen3+eeedx/LlywEoLCxk69atANTW1hIfH09ycjKlpaWdLt7W0yWdzzvvPF544QUaGxtpaGjg+eef59xzzx3A2nbl2KtsurV7RynVjfz8fOrq6sjNzSUnJ4evfvWrXHnllRQUFDBz5kwmT57c6/Nvu+02brrpJmbMmMHMmTOZO3cuAGeccQazZs0iPz+fsWPHMm/evGPPWbJkCQsWLCAnJ4e1a9cemz579mxuvPHGY8u45ZZbmDVr1qD+GpcM9R8aKSgoMCcaA9udpc9uZe2uMjb86OJBKJVSqi927NjBlClTwl0Mx+nufRWRTcaYguPndey1d+zJWeEuhVJKDS2ODX23S38uUSmljufY0NdLKys1NGljbGB92vfT0aGvJ2cpNbTExMRQWVmpwT9AjDFUVlYSExNz0s9x7OgdvZ6+UkNPXl4eRUVF9PWaWqqrmJgY8vLyTjxjiGND3+1Ch2wqNcR4PB7GjBkT7mJENEd37+illZVSqjPnhr5LL62slFLHc27oi15aWSmljufY0NfLMCilVFeODX0J/XKWDg1TSql2jg19t8te+lSP5SqlVDvHhn4o83UEj1JKdeDc0D/W0tfQV0qpNs4NfdHQV0qp4zk29N2iffpKKXU8x4a+aJ++Ukp14djQbxu9o0M2lVKqnWNDv61PX1v6SinVzrmhr+P0lVKqC+eGfqhPX0fvKKVUO8eGvluHbCqlVBeODX3t01dKqa6cG/rHRu+EuSBKKTWEODf0dZy+Ukp14djQd+u1d5RSqgvHhr7ogVyllOrCsaGv195RSqmuHBv62qevlFJdOTf0tU9fKaW66Ffoi8h3RGSbiBSKyNMiEiMiaSLyqojsDt2mdpj/LhHZIyK7ROTS/he/Z8eupx8czFdRSqnTS59DX0RygduBAmPMNMANLAaWAmuMMROANaH/EZGpocfzgcuAh0XE3b/i98wdqpm29JVSql1/u3eigFgRiQLigGJgIbAs9Pgy4OrQ/YXAM8aYFmPMPmAPMLefr9+jttE7AQ19pZQ6ps+hb4w5DPwSOAgcAWqMMX8Hso0xR0LzHAGyQk/JBQ51WERRaNqgaBu9o9fTV0qpdv3p3knFtt7HAMOBeBG5vrendDOt20QWkSUislFENpaXl/epfO3X3unT05VSypH6071zMbDPGFNujPEDzwGfBUpFJAcgdFsWmr8IGNHh+XnY7qAujDGPGmMKjDEFmZmZfSqcK1QzHbKplFLt+hP6B4GzRSRObAf6fGAHsBq4ITTPDcCq0P3VwGIR8YrIGGAC8F4/Xr9XLu3eUUqpLqL6+kRjzAYRWQl8ALQCHwKPAgnAChG5GbthuC40/zYRWQFsD83/LWNMoJ/l71HbtXf0QK5SSrXrc+gDGGPuBu4+bnILttXf3fz3Avf25zVPVvsvZ52KV1NKqdODc8/IPXZylqa+Ukq1cX7oa/eOUkod49jQP9anry19pZQ6xrGhL9qnr5RSXTg29PWXs5RSqivHhr726SulVFeOD33t01dKqXaODf227h1t6CulVDvHhr7+XKJSSnXl4NDXPn2llDqec0NfR+8opVQXjg1997GWfpgLopRSQ4hjQ1/79JVSqivnhr5Lr6evlFLHc27o6zh9pZTqwrGhr336SinVlWNDX0I109E7SinVzrGh79Zx+kop1YVjQ7+9Tz/MBVFKqSHEuaGv3TtKKdWFc0NffyNXKaW6cGzo6+gdpZTqyrGh3/ZziQHt3lFKqWMcHPqCS/SMXKWU6sixoQ+2X1/PyFVKqXbODn2XaJ++Ukp14OzQFx2yqZRSHTk69N0iOmRTKaU6cHTou0R09I5SSnXg7NB3CZr5SinVztmhL3o9faWU6sjRoe92iR7IVUqpDhwd+iIa+kop1VG/Ql9EUkRkpYjsFJEdIvIZEUkTkVdFZHfoNrXD/HeJyB4R2SUil/a/+L2zo3cG+1WUUur00d+W/q+AV4wxk4EzgB3AUmCNMWYCsCb0PyIyFVgM5AOXAQ+LiLufr98rl+i1d5RSqqM+h76IJAHnAX8AMMb4jDHVwEJgWWi2ZcDVofsLgWeMMS3GmH3AHmBuX1//ZLi0T18ppTrpT0t/LFAOPC4iH4rI70UkHsg2xhwBCN1mhebPBQ51eH5RaNqgcenJWUop1Ul/Qj8KmA08YoyZBTQQ6srpgXQzrdtEFpElIrJRRDaWl5f3uYBuvfaOUkp10p/QLwKKjDEbQv+vxG4ESkUkByB0W9Zh/hEdnp8HFHe3YGPMo8aYAmNMQWZmZp8LKNqnr5RSnfQ59I0xJcAhEZkUmjQf2A6sBm4ITbsBWBW6vxpYLCJeERkDTADe6+vrnwy99o5SSnUW1c/n/wuwXESigU+Am7AbkhUicjNwELgOwBizTURWYDcMrcC3jDGBfr5+r1w6Tl8ppTrpV+gbYzYDBd08NL+H+e8F7u3Pa34aLpcQ0HH6Sil1jKPPyNWfS1RKqc4cHfpul15aWSmlOnJ06Ntr74S7FEopNXQ4OvTdgo7eUUqpDhwd+jp6RymlOnN26LtEf0RFKaU6cHboC/pziUop1YGjQ19H7yilVGeODn3t01dKqc6cG/p//zcuq3teR+8opVQHzg39feuZ1rJJx+krpVQHzg39+EySAtU6ekcppTpwdugHq7VPXymlOnB26AeOEgzqZTaVUqqNo0PfY/zEmKZwl0QppYYMR4c+QFKgOrzlUEqpIcS5oZ9gQz85WB3eciil1BDi3NCPbwv9o2EuiFJKDR2OD/2UYE2YC6KUUkOHc0M/LgOAFFMd3nIopdQQ4tzQj4qmyZ1IYqt27yilVBvnhj7QHJ1GYrCaZn8g3EVRSqkhwdGh74/NIENqqWzwhbsoSik1JDg69E1cJhnUUFnfEu6iKKXUkODo0HclZpMl1VTWa0tfKaXA4aHvSc0jSRo5Wl0V7qIopdSQ4OjQj80cCUBLZVGYS6KUUkODo0PfmzoCgGCNhr5SSoHDQ5+k4QBIbXGYC6KUUkNDRIR+dOORMBdEKaWGBmeHfpSXWlcKcc1l4S6JUkoNCc4OfaA2Ootkf2m4i6GUUkOC40O/KTab9EAFQf2BdKWU6n/oi4hbRD4UkRdD/6eJyKsisjt0m9ph3rtEZI+I7BKRS/v72ifDHz+cYVJFdZP/VLycUkoNaQPR0r8D2NHh/6XAGmPMBGBN6H9EZCqwGMgHLgMeFhH3ALx+ryQ5lxRpoKJKr7aplFL9Cn0RyQOuAH7fYfJCYFno/jLg6g7TnzHGtBhj9gF7gLn9ef2T4U3LA+Boyb7BfimllBry+tvSfwD4ARDsMC3bGHMEIHSbFZqeCxzqMF9RaFoXIrJERDaKyMby8vJ+FTAxaxQAjRUH+7UcpZRygj6Hvoh8Higzxmw62ad0M63bo6vGmEeNMQXGmILMzMy+FhGA5OwxAPirDvdrOUop5QRR/XjuPOAqEbkciAGSRORJoFREcowxR0QkB2gbJF8EjOjw/Dxg0E+VjU4N7UzU6qUYlFKqzy19Y8xdxpg8Y8xo7AHa140x1wOrgRtCs90ArArdXw0sFhGviIwBJgDv9bnkJ8sTQ40k4WnQs3KVUqo/Lf2e3AesEJGbgYPAdQDGmG0isgLYDrQC3zLGnJLfMaz2ZBHXomflKqXUgIS+MWYdsC50vxKY38N89wL3DsRrfhqNMdmkaPeOUko5/4xcgNb4HLJMpf5AulIq4kVE6JM0nFSpp6xSf0FLKRXZIiL0o9PsoKGqkgNhLolSSoVXRIR+Qpb92cT6Mg19pVRki4jQz8ibCICvbE+YS6KUUuEVEaHvzRhDHXHEVm0Ld1GUUiqsIiL0EeGAZxwZdbvCXRKllAqryAh9oCJhEiP8n0BQh20qpSJXxIR+U3o+Mfjwl2lrXykVuSIm9F3DzwCg5pOTvSioUko5T8SEfsrIfFqMh5aDG8NdFKWUCpuICf28jGQ+CE4g7vA74S6KUkqFTcSE/rCkGN5hGql1u6ChItzFUUqpsIiY0He7hMOpoZ/k3bc+vIVRSqkwiZjQB0gceyZ1JpbgJ+vCXRSllAqLiAr9maMyeTuYT2DnKzpeXykVkSIq9GePTOWFwDw8jaWw7x/hLo5SSp1yERX6I9Ji2RJ7Fo2uBNjyTLiLo5RSp1xEhb6IcMaYYbzCZzHbXoD9b4W7SEopdUpFVOgDXD49h/9qvIbmhDxYfh0c/iDcRVJKqVMm4kJ//pQsGjxpPJB7P8Snw9OLYd3P4LBenkEp5XwRF/px0VHMn5LFip0+6q59CkwQ1v0XPHuLjuhRSjlexIU+wK3njqW2uZW73w3A93bBoseh6hPY+WK4i6aUUoMqIkP/jBEpfOvC8Tz3wWHW76mCqQshbSz89Xvw3BLQk7eUUg4VkaEP8K0Lx5GXGsvPXtlJEBdc/RvInQO7X4U/LoSNj8OHT9pbpZRyiKhwFyBcvFFuvnfJRL7z5y38eeMhvjz3LPjKn8HfDMsXwd//DXwN4HLDuAshdXS4i6yUUv0WsS19gIVn5DJvfDr//kIhb+4OXXnTEwOX/wJamyFzEogb1t0HxoS3sEopNQAiOvRdLuGR6+cwPiuBry97n1cKj9gHsqbALWvgppdh7q2w5Wl4qAB+XQCbnw5voZVSqh8iOvQBkmI8PH3r2UzNSeKfn/yAe1Zv42BlIwyfCXFpcPE9cOWDkDISoryw6lvw3u+grgSCwXAXXyk1GMp3wX/lQfnH4S7JgBMzxLstCgoKzMaNg/8Th83+AD99aQfL3jkAwF0LJvON88d1nqmlDv54NRwOlSc60Y78mfA5GD8fvImDXk6l1Cmw8XF48U5Y+DDM+mq4S9MnIrLJGFNw/PSIPZB7vBiPm58snMat543lpy/t5Kcv76S4uokfXDaZeG/obfImws2vQvEH9gzeI1tgx2rY/KTdAMy9Bc7/IbS22JE/k6+AtDHhrZhS6tMr32lvK/eEtxyDQEP/OHmpcTz45VlkJXl54u39vLajjP+8ehoXTs6yM7hckFdg/wCu/BUUvQ/v/x7e/B/Y+Jjt9vHVwYbfws1/h6Sczi/ib4I9r9k9h5lfObUVVKo3R/fbs9MXPWa7NCPVYIf+gbchOx9ikgdn+b3Q0O+G2yXcfWU+n5+Rw9JnP+KmJ97n8unDuOqMXC6YlEmMx91hZg+M+qz9m30DFK4EccGoc+zu4W/Pg+nXQUst5M6GjEl2ekWorzDKay//kDkJcs4IR3Wtgxtg2HSIjgtfGdTJObof9q6FOTeCyMAuu/BZ24jZ9jzMu2Nglz1YgkH4ZC3knQkxSQOzzLK20N974nkPvQ9//ip8bTVkTe55vkAr1By0v9H9+AL4zLfh0nsHpryfQp8P5IrICBFZKyI7RGSbiNwRmp4mIq+KyO7QbWqH59wlIntEZJeIXDoQFRhMc0al8dfbz+V7n5vI6zvL+OcnN3Htw2+zp6y++yeMPR+u+rVt/c+4zo7+SRkJG35jL/Hw4nfgicuhvgy+tByGzYCVX4fnbrUbh9W32w9Gm8Yq8DVCwG/vG2P3EBqrei945V547hvw4XJoCZW1Yo8996C75+55DR67BF5Z2vWxQGvn4arNNfDSv8L+N3svQ3caq2DTE9Bc++mfOxiObLFfwFPB1zBww37X/8I2HD7+m/3/5aXwxv0Ds+zdr4VuX+36WNtnEKDwOfjNOdDqs///4xd23Q6mts/uP34Oe1+39xsq4PcXwZPXwit3DczrNB2F+hKIioGqvb0P2AgG4K/fhfpS2L6q9+Wu+yk8OAv+/E/2/51/DctQ8D4fyBWRHCDHGPOBiCQCm4CrgRuBKmPMfSKyFEg1xvxQRKYCTwNzgeHAa8BEY0yvVzk7VQdyT6SlNcDrO8pY+txH1DX7WTA9h2+cN5Zpw5NxuU7Q2gq02pO8qj6Boo0w8ix7sldJof3AnHkrHNkM7zwEYy+AuUtsqL73KHji7d5AS609aLz1z3ZvYcRc+8GPjocvP2N3E/9yB1QfhIZyO7oIA544mPVPdt7K3ZA5GS7+CXz8sg29+Ewo3Q61ReCOto/VFcMZX7ZfqGdvhomX2Y1ZfSk8uQhKPwK3F657AiZfbutYUwSv3wvDZ9lhrse3QINBWP4FW474LFi83NahL+pK4M/X25ZS/tXt0yv3QuqY9tfuWIbS7XYvpu0ku5oi+wWcejV84Xe9v96eNbD9Bci/BsZd1PXxgN8ex/EmdH2spQ5e/K5tQS/4mX1vjlf4rA3PmV/uvRxgP0v/PREaKyFjoj2h8MHZNqC+u92OODv0nm1AzPwKzLu99+XVl9nPgAg0VcPPx9plBXzww30QnWAvSlj8ITx2KVz1kC3nn66x6/KmVyA+Ax4KtbK/u7P3vcWD79oh0R27NfxN4Ilt/3/vWtuwuPa39ix5gHcfsY2WBT+335msfLjtLdtQee93MHqe7TK5/UM78mbHX+Cy+3ovi6/R7qm7PZ2nH3gHHr8MJl0Bu/4KdxZCyggb0DVF9n6bt34Fr/4fe0wva7K9nIuvAa64HxKzO6+3/5lq69pSa7/nn6yDb75rv9/rfgZJw+Hs2yAhq/d1dpJ6OpA7YKN3RGQV8FDo7wJjzJHQhmGdMWaSiNwFYIz5aWj+vwH3GGPe6W25QyX025TXtfDYW/v40zsHqG9pJTXOw8KZudz42dGMzojHGIP0dZd742Pw6j3QUgOI/dIG/BBosR+2w5vsh+XQexBshSlX2VZ6fKb9IDVV226iuhL4p+fsh++DP8GWp+zy5v87vP1rGxguD4w+B+qO2I3R5/8HVv+L/YIjQOhz4U2yyz7zFtv6a6iAhb+Gd/4XijfDFb+EhGy7Z+FvsM8fe4ENxx0vQmyKvV/yEWxebrsMdvzFtqaufBBGzbMnxB142+4V1RTZg99pY+0XpXI3HNoAGx6178PsG+xe06ENEJcBkxbYZY8+x240C262/bAVu2HatZA+zobj8uvsiXZXPmDLt+b/wgfL7Jf1B3vtF6+jtf8F+9bDud+zZ2iD3aB8eyO4Q72iDRX2xL2PVtj3euJlcM1vO4f/mv+AN35pN3TJebBkbefXee0n8GaolX7Rv0NcOux6Cc76ZzsizJjOG6/9b8ITV9iN8pan7Ubs6AG7vvKvheZqG5oYiE2F72zvOfgKn4OVN8H8u+Hc78Lmp+CF2+Cif4PX/9N+JvautZ+72FQoLYTMKXDLa/DzMXbDcMFdUHPIPtcE7Tqdc4Nd/tED8NH/syc6Tl1oGyN/ugZGnA1TrrTLy51jW+jDpsHYC234v/2Q/Q5k5dvPWsAPy78Y+l508MU/wrO3wowvwgVL4Vcz7WCLptAewaLHoWyH7bbMzref2drD9jP09q/hYOgzd8saW78XboPkEfa79faDduTOqm/CP71gz8p/60Eb8F9bZeffvsqu2ylXQdZU+Md9oYKJ3Vie+XW74ag+CEf3wdp7Q3v4020D6/7J9v078Lb9M0G7QcydAyZgPw+Jw7pfdydhUENfREYD64FpwEFjTEqHx44aY1JF5CHgXWPMk6HpfwBeNsas7GZ5S4AlACNHjpxz4MCBfpdxoNU0+flbYQnrd5fzt20ltAYNybEeYj1ufnP9HM4YkdK3BTfX2tFB2dPt9f7b+Bph999h0uX2SxbltSGy8yV45iv2g/L5++1xgeODonS7/SKMPsdeZmLfehuG6aEhqcGA3RPZ8Chg7Bd096s2ZKdeA6u/bYMoIRsWPw15c2wL9ukvw/437DJyzoDrltmN0Np7bagPm25bwBUfgyvKBtkl/2n7pB9fYDc44rYh2dzhC+2OtsdIDr0H/kY7LXOKrfORzfaYybw7bCvLBNs3TMkjbZ8pAiM/YzcMbTuSiTk2UEsL218ne7rda7n29zZ0UkfbL3VMiu1Cwdg9rdgUuwf03C0w9xt2j+fwJhsg4oJpX7Ab3ncegs/ebgPo+X+2IVdSaMN7+Cx47W745gb73ojYQHrxTpj9Nagttu9dW/29iXadFn9o92imXGmXt/4XsO8N+MEn8PIP7cixsRfa93fPqza0Zl1vuw6f+TKMOd+u34Kb7HqZ/TWYcKndUG34rQ1UETt90xOQPh6WrIPfXQRl22154tJtQ2HcfNi7BubcBJset3uRicOg+pA9vnDgbRtuaWPt+/DX79kBDeK268GbZFvVjZV2ueKy6y93jt3TKd9hAzdtHJz1DXj5B+3rStxw5s1273fmV2HbC7aR4Y62G+LUUbbRdOAdyJxo6xaXbg/Iujx2Hfoa7J5xQ7ndmzn7NrsHkXemDdv3Hm1/vQmXwOcfsK3z8Z+ze2jPLbEb1eQR9rMbbLWPfelJ+7n6/XzbMFi8HNb/0u4dmg5dQ/FZdm+sbc9i2VXtv9W94Bf2+/jUl+x30RjbGLrtbfs974NBC30RSQD+AdxrjHlORKp7CP3/Bd45LvRfMsY829vyh1pLvztltc08/d4hSmqbeWN3OZX1Pr5y1khmj0xlbGY8E7MTcZ+oC6g/6kpsIA/0Qb02xtjWmjvafiDbBAO266PiYxsq0fF2enONDbHMyaFw22lDLDm3/bm+RijZCh+/Ylv30xbZMEjItnsER7bY1lXemXaDkjHJLqu+zIZFQiZ88EcbPKPm2TCatgj+/mMYcZZt/QWDNrg2L4czFttlHHzb7v776m2L76GC9g3OsOl2rwEgKdd+Cfethyv+G+Z8HR75jA2RxOEw6jM2nKYvsntXAKu+bVvficNtd5k3yS77m+/YkHlwpg2goL/9fRh9rm1Jgn0/2rpTHg2Fde5su/Fq44qCc74LF/3YhthL/woFX4eUUXY9jDy7PTR+e66tT9tG0e21G3JXaE8lby5c/nN77klzDUz5vA262BS7ft76le3KGP85e6B06kL437m25RqdaDcuGx6xG8lvb7TvzebldqNUW2Q3tDf+1baK33rArq/FT0HpNht8o8+167/gZhtwwYD9i4q25ftopa1LMLTBGHehba3P/Cp8+EfbKDj/h/Y9Ot6L37EbAW+y/aw0HbVlScq19Zq0wI7A2/wUvPBNwMAZX7FdeE1H7eALEfjL7VD4vN14Acy709Yl70zbAErIbP8uPHer7Uodd6GdVl8OB96ye671ZbbbpuNgjZY6u6dXW2z3WtxRtiEQm2qPxRWutA2IPhqU0BcRD/Ai8DdjzP2habtwcPfOiZTWNvMfL27nlULb+gdwCaTFe8lK9HL1rOFclp9Dbmrs4G4I1Ml547/t6IuoaLu7Pv//2JZn4nDb1bD1GdtqjfLasKsrtY+7uhkD0VAJzy+xwV5wE+QWQPWB9lBadqUNgot+bIO3tBBm39geHB0des++Zs4Ztqtq/xt2gzjyM7bf/mTUHLbBEpMEm5bZ1vyan9jX/tx/tO9JNlXbDfrJjNxqrLLBmzjMdpv98aquJzDVHLbdQ2ffBjkz2qcfvwc6mD75hy3bvDvg3O/brqj4jO7nrSuxI5bGX9z52EIbf7MdzRTw2fdw7+v2eNQQPxlzwENfbMf1MuxB2zs7TP8FUNnhQG6aMeYHIpIPPEX7gdw1wITT5UDup1Xb7Ofw0SZ2ltSyt6yByoYWdpfWs/HAUQAyE71cOyuX2Gg3q7cUc874DG6aN4bUOA8pcdFhLn0EMsYeC0gfP3jBFAx2v7E4nVXube8mHEqMsXtdkz8/cMM4TzODEfrnAG8AHwFtHVc/AjYAK4CRwEHgOmNMVeg5Pwa+DrQCdxpjXj7R65yuod+TbcU1FB6u4ZXCEtbvriAQNEzLTWJbce2xhtCM3GQmZicyJjOe8yZkEuUWDh9t4oJJWSfcO9hX0cDbeyv4ytyRfT+grJQ67Q366J3B4rTQ78jXGqS6yUdWYgwfFdWwu6yOA5WNbNhXySflDZTVtXSaf/KwROaOSWNfRQONvgCpcdHkJMdw3sRMzhmfQdAYPv/rN9lX0cDPvzCDL545oodXVko5nYb+aehog49Vmw/TGjSkxUfzhzf3sb+igRFpcaQnRFNZ76PoaBP1La3EeFwkeD1UNrQwPjOBw9VNXDQ5i9zUWCrqfNS3+Jmak0yUWxiTEc9ZY9JIT/CesAyV9S0kxniIjnJYt4RSDqeh71C+1iAb9lXy+s4yahr9nD8pk4LRafz7C4XsLa+nuLqJpBgPiTFR7K9sPPY8l8CErEQSYqIIGkNKrIeAgTiPm1EZceSlxvHuJ5W8UljC5GGJXDwlm/2VDfz4iimkxUXzUmEJiTFRXDDRHoT84GA103OTdeOg1BChoR+hgkGDCIgILa0BgkHYWVLL6zvL2FVSR4OvFZcIRxt9uEVo8AU4WNmILxAkJc7DgmnDeHHrEeqaW4l2u4jzuol2u451Pc0ckYI3ysWGfVXMHJHCWWPTaPEHGZeVgL81yHv7qpiQbU9Wqm3yc/HUbCZkJbKnrJ7xWQlkJXppbg0QFx3F4eom/rKlmInZCVw0Obu3aimlTkBDX520ltYAZbUt5KbE4nIJR2qaaPQF8LUGeWjtHtwiXD59GKW1Lfz5/UMU1zTxhdl5PPPeQXyBIB63i0afHZSVkxxDaW0zIoLHLTT7209W8Ua5SIuPprS2mfFZCXxcaq8T5BK4+ZwxBIKwt7yeycMS8QcMLa32OEZ9Sys5yTGMSo+nqsFHwBiunJFDjMdNjMdNbbOfg5WNeNwuJmYndDmgXdfs56WPjnDxlOyT6uJS6nSkoa8GXZMvgAh43C4q61sIGshO8lLV4CPK5cITJWzYV8WBigZGpsfx8kclHG30My4zni1F1Xx2XAaXTRvGfS/v5PWdZXijXIzJiGdveT1ul+CNclPX7CcuOor6ltZuy5Aa56GmyU/oFAlGpMUSE+UmJc7D8BQ7BvvN3RVUNvjISY5h9qhUiqpst9ekYYl4o9yMy4wnOc5DZb0Pf8Bw1tg06ppb8biFEalxJHijOFDVSNHRRgpGpZEWH01Vg494r5v46KgTX4tpkPhag+wqqWN63qm/XK8aejT01Wml0ddKrMeNiNDsD+Bxu3C7hGDQ4HIJNY1+9lc2kBgTRaMvwD8+Lgeg6GgjmQlepg5PpqrBxz8+LkOw3VfFNU0EAobpeclcPj2Hh9fupckfYFR6HEFj2FVSj681QG1z9xuU7kS7XURHuY5thNwu4bPj0kmNi8YlEDSwdlcZ8dFRTMhOIC81Fm+Um3ivm8wEL2kJXnYcqaXZHyAvNY6io43MHJFCRb2PuGg3E7MTKKlpoaK+hbzUWOaMSsUYOHS0kUnDEimtaaG22Y/H7eI//7qdN3ZXcOfFE7hj/oRjXXo1jX6ykmKOldkYQ9BwbPhvxy5A5Rwa+kqdpOLqJpr9AdITvLQGgrz7SRUZCdG0Bg2Hqhqpb2llZFocmYleVm0uxhcIMjUniSZfgNLaZl7bUUrQgD8QpKGllUvyh2GMPZZSXtdCkz9Aoy9AILQ7EuUSokJdX9FuF75Az5fydQm4RI6d7d2RCBSMSuX9/UdJjfMweVgSe8vrKatr4awxdm+lpslPZUMLxsCMvGRGp8fzt20lxEa7mTsmHZfA5kPVTMxOJCc5hqKjTdQ2+Zmel0z+8GSa/AHio934A0G2F9eyt7wBj1tYMD2HeeMzOFjZSEltE8EgTB2eRHpCNC3+IOX1LewurWNYcixjM+Iprm6irK6FKTlJjE6PY39lI1Whva8RaXG0BoK4XYKIYIyx3YYuV9j2ok5HGvpKhUFPV10NBg1HG31U1PvISYkhJsrN0UYfGQleCg/XkJ0UQ02Tn+LqJoYlx5CeEM3+ikbe2F1O0BgmZieyu7SevNRYUuOj8bUGGZ4Sy8wRKazcdIjNh6rZfqSOlFgP+cOTeHV7KTkpsWTER5MWH03QwIeHjvJxSR3nTshEBD46XEOzP8DMEansLa+nqsFHRkI0qXHRFBbXdDoeAxAf7WZ8VgJ1za18UtHQ5/fI7ZJjG0CA3JRYDlc34XYJ8dFumluD+FqDuARykmMZkRZLgjeKhpYAdS1+/K2GfZUNoT28JKbkJJEeH83Bqkbqm1tpaQ0QG+0mKdZDaU0zYzMTSPBGUd3kp6y2mfqWViYPSyQ5LprqBh9RbhfDU+wGL9rtYlxWPJkJMbS0BmhpDeIPBEmP97KzpJaaJj9jM+OJiXJTXt8SOk7lJTPRy/CUGLxRbhp9rRxt9NPka6XJF8QXCJKV6KU1aKhq8OGNcpE/PIna5lbio91EuV34WoPsKatn6vC+n02soa+U6rPWQJD9lY0kxdjjKS4RRqbF4XLZlvhrO8ooq2tmVFo8OSm2K2lrUTX1LQG8US6SYz1Myk6ktLaZveUNpMZ5GJkex44jdewuq2NcRgLDU2L58OBRth+pZXxWAkFjqG9uxetxkxQTRbM/yOHqJg5VNdLkDxDjcZMc68Elwqj0OMrrWigsrmFfRQPGQKzHTVJsFDEeN3XNrdQ1+8lM8FJc0wzYPaOMBC/eKBdFR5sG/D0TgbS4aCobfCecN8bjotlvN2wZCV7qW1ppaQ2y5e5LSGj7je5P/foa+kqpCNB2HCMjwdupO6jteFBDSyv+QJAEbxRRbnteSX1LK40trSTFemjyBThS08yo9DhaA4adJbXUNbfi9bjwRrlxu+zvauSlxpGTHMOBqkaafQEyE734AkGqGnyU1rZQdLSRkppmhqfEkp3kJTY6ijiPG7dbKKttJjrKRWpcNBX1PgoP15CTHEODL0BJTROxHjefGZfOBZOyOv8866egoa+UUhGkp9DX0yeVUiqCaOgrpVQE0dBXSqkIoqGvlFIRRENfKaUiiIa+UkpFEA19pZSKIBr6SikVQYb8yVkiUg4c6OPTM4CKASzO6UDrHBm0zpGjr/UeZYzJPH7ikA/9/hCRjd2dkeZkWufIoHWOHANdb+3eUUqpCKKhr5RSEcTpof9ouAsQBlrnyKB1jhwDWm9H9+krpZTqzOktfaWUUh1o6CulVARxZOiLyGUisktE9ojI0nCXZ7CIyH4R+UhENovIxtC0NBF5VUR2h25Tw13O/hKRx0SkTEQKO0zrsZ4icldo3e8SkUvDU+r+6aHO94jI4dD63iwil3d4zAl1HiEia0Vkh4hsE5E7QtMdu657qfPgrWtjjKP+ADewFxgLRANbgKnhLtcg1XU/kHHctJ8DS0P3lwI/C3c5B6Ce5wGzgcIT1ROYGlrnXmBM6LPgDncdBqjO9wDf72Zep9Q5B5gdup8IfByqm2PXdS91HrR17cSW/lxgjzHmE2OMD3gGWBjmMp1KC4FlofvLgKvDV5SBYYxZD1QdN7mnei4EnjHGtBhj9gF7sJ+J00oPde6JU+p8xBjzQeh+HbADyMXB67qXOvek33V2YujnAoc6/F9E72/i6cwAfxeRTSKyJDQt2xhzBOwHCsgKW+kGV0/1dPr6/7aIbA11/7R1cziuziIyGpgFbCBC1vVxdYZBWtdODH3pZppTx6XOM8bMBhYA3xKR88JdoCHAyev/EWAcMBM4Avx3aLqj6iwiCcCzwJ3GmNreZu1m2mlZ727qPGjr2omhXwSM6PB/HlAcprIMKmNMcei2DHgeu5tXKiI5AKHbsvCVcFD1VE/Hrn9jTKkxJmCMCQK/o3233jF1FhEPNvyWG2OeC0129Lrurs6Dua6dGPrvAxNEZIyIRAOLgdVhLtOAE5F4EUlsuw9cAhRi63pDaLYbgFXhKeGg66meq4HFIuIVkTHABOC9MJRvwLUFX8g12PUNDqmziAjwB2CHMeb+Dg85dl33VOdBXdfhPno9SEfEL8ceBd8L/Djc5RmkOo7FHsXfAmxrqyeQDqwBdodu08Jd1gGo69PYXVw/tqVzc2/1BH4cWve7gAXhLv8A1vlPwEfA1tCXP8dhdT4H21WxFdgc+rvcyeu6lzoP2rrWyzAopVQEcWL3jlJKqR5o6CulVATR0FdKqQiioa+UUhFEQ18ppSKIhr5SSkUQDX2llIog/x/oU9MTLiOohgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "pca_preds = model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(metrics.mean_squared_error(y_test,pca_preds))\n",
    "mae = metrics.mean_absolute_error(y_test,pca_preds)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test,pca_preds)\n",
    "ex_var = metrics.explained_variance_score(y_test,pca_preds)\n",
    "r2_score = metrics.r2_score(y_test,pca_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated scoring metrics with reduced dimensions:\n",
      "\n",
      "Root Mean Squared Error: \t18.71 Kelvins\n",
      "Mean Absolute Error:\t\t8.87 Kelvins\n",
      "Mean Abs. Percent Error:\t8.0%\n",
      "Explained Variance Score:\t0.7056\n",
      "R2 Score:\t\t\t0.7048\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUpdated scoring metrics with reduced dimensions:\\n\")\n",
    "print(f\"Root Mean Squared Error: \t{np.round(rmse,2)} Kelvins\")\n",
    "print(f\"Mean Absolute Error:\t\t{np.round(mae,2)} Kelvins\")\n",
    "print(f\"Mean Abs. Percent Error:\t{np.round(mape,2)}%\")\n",
    "print(f\"Explained Variance Score:\t{np.round(ex_var,4)}\")\n",
    "print(f\"R2 Score:\t\t\t{np.round(r2_score,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
